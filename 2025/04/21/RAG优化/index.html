<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RAG优化 | 大潘子的文字角落</title><meta name="author" content="Pan"><meta name="copyright" content="Pan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="总结了一下当前RAG常见的优化方法">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG优化">
<meta property="og:url" content="https://flippy-bird.github.io/2025/04/21/RAG%E4%BC%98%E5%8C%96/index.html">
<meta property="og:site_name" content="大潘子的文字角落">
<meta property="og:description" content="总结了一下当前RAG常见的优化方法">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flippy-bird.github.io/covers/22.webp">
<meta property="article:published_time" content="2025-04-21T08:10:12.000Z">
<meta property="article:modified_time" content="2026-01-16T10:40:28.950Z">
<meta property="article:author" content="Pan">
<meta property="article:tag" content="Rag">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://flippy-bird.github.io/covers/22.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG优化",
  "url": "https://flippy-bird.github.io/2025/04/21/RAG%E4%BC%98%E5%8C%96/",
  "image": "https://flippy-bird.github.io/covers/22.webp",
  "datePublished": "2025-04-21T08:10:12.000Z",
  "dateModified": "2026-01-16T10:40:28.950Z",
  "author": [
    {
      "@type": "Person",
      "name": "Pan",
      "url": "https://flippy-bird.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favion.png"><link rel="canonical" href="https://flippy-bird.github.io/2025/04/21/RAG%E4%BC%98%E5%8C%96/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css?v=5.5.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RAG优化',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preload" as="image" href="/img/fengmian.webp" fetchpriority="high"><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/covers/22.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">大潘子的文字角落</span></a><a class="nav-page-title" href="/"><span class="site-name">RAG优化</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">RAG优化</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-21T08:10:12.000Z" title="发表于 2025-04-21 16:10:12">2025-04-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-16T10:40:28.950Z" title="更新于 2026-01-16 18:40:28">2026-01-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>25分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h3 id="1-基本的RAG流程-Native-RAG"><a href="#1-基本的RAG流程-Native-RAG" class="headerlink" title="1. 基本的RAG流程-Native RAG"></a>1. 基本的RAG流程-Native RAG</h3><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/2.png" alt="2" style="zoom:33%;" / loading='lazy'>

<h3 id="2-RAG优化"><a href="#2-RAG优化" class="headerlink" title="2. RAG优化"></a>2. RAG优化</h3><h4 id="2-1-优化chunk"><a href="#2-1-优化chunk" class="headerlink" title="2.1 优化chunk"></a>2.1 优化chunk</h4><p>传统的RAG在数据分块时采用的是固定分块，因为可能会破坏段落的连续性，因此这一方面可以改进</p>
<h5 id="2-1-1-拼接断裂的块"><a href="#2-1-1-拼接断裂的块" class="headerlink" title="2.1.1 拼接断裂的块"></a>2.1.1 拼接断裂的块</h5><ul>
<li>将固定分块的断裂部分找到，然后拼接起来；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_breakpoints</span>(<span class="params">similarities, method=<span class="string">&quot;percentile&quot;</span>, threshold=<span class="number">90</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes chunking breakpoints based on similarity drops.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">    similarities (List[float]): List of similarity scores between sentences.</span></span><br><span class="line"><span class="string">    method (str): &#x27;percentile&#x27;, &#x27;standard_deviation&#x27;, or &#x27;interquartile&#x27;.</span></span><br><span class="line"><span class="string">    threshold (float): Threshold value (percentile for &#x27;percentile&#x27;, std devs for &#x27;standard_deviation&#x27;).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    List[int]: Indices where chunk splits should occur.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Determine the threshold value based on the selected method</span></span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&quot;percentile&quot;</span>:</span><br><span class="line">        <span class="comment"># Calculate the Xth percentile of the similarity scores</span></span><br><span class="line">        threshold_value = np.percentile(similarities, threshold)</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&quot;standard_deviation&quot;</span>:</span><br><span class="line">        <span class="comment"># Calculate the mean and standard deviation of the similarity scores</span></span><br><span class="line">        mean = np.mean(similarities)</span><br><span class="line">        std_dev = np.std(similarities)</span><br><span class="line">        <span class="comment"># Set the threshold value to mean minus X standard deviations</span></span><br><span class="line">        threshold_value = mean - (threshold * std_dev)</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&quot;interquartile&quot;</span>:</span><br><span class="line">        <span class="comment"># Calculate the first and third quartiles (Q1 and Q3)</span></span><br><span class="line">        q1, q3 = np.percentile(similarities, [<span class="number">25</span>, <span class="number">75</span>])</span><br><span class="line">        <span class="comment"># Set the threshold value using the IQR rule for outliers</span></span><br><span class="line">        threshold_value = q1 - <span class="number">1.5</span> * (q3 - q1)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Raise an error if an invalid method is provided</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid method. Choose &#x27;percentile&#x27;, &#x27;standard_deviation&#x27;, or &#x27;interquartile&#x27;.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Identify indices where similarity drops below the threshold value</span></span><br><span class="line">    <span class="keyword">return</span> [i <span class="keyword">for</span> i, sim <span class="keyword">in</span> <span class="built_in">enumerate</span>(similarities) <span class="keyword">if</span> sim &lt; threshold_value]</span><br></pre></td></tr></table></figure>

<h5 id="2-1-2-使用不同的分块大小"><a href="#2-1-2-使用不同的分块大小" class="headerlink" title="2.1.2 使用不同的分块大小"></a>2.1.2 使用不同的分块大小</h5><ul>
<li>(例如原来是256， 现在试一试512， 1000等等)；</li>
</ul>
<h5 id="2-1-3-总结chunk"><a href="#2-1-3-总结chunk" class="headerlink" title="2.1.3 总结chunk"></a>2.1.3 总结chunk</h5><ul>
<li>chunk Embedding之后缺乏语义信息，在chunk Embedding之前 给每一个chunk添加一个meta data, 一般是对这段text的总结，如标题等(可以使用LLM来协助),  在查询时， 使用的是两个信息相似度的平均值 （这个demo）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">system_prompt = <span class="string">&quot;Generate a concise and informative title for the given text.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **************************** step 2 *********************************</span></span><br><span class="line">chunks = []  <span class="comment"># Initialize an empty list to store chunks</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate through the text with the specified chunk size and overlap</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(text), n - overlap):</span><br><span class="line">    chunk = text[i:i + n]  <span class="comment"># Extract a chunk of text</span></span><br><span class="line">    header = generate_chunk_header(chunk)  <span class="comment"># Generate a header for the chunk using LLM</span></span><br><span class="line">    chunks.append(&#123;<span class="string">&quot;header&quot;</span>: header, <span class="string">&quot;text&quot;</span>: chunk&#125;)  <span class="comment"># Append the header and chunk to the list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> chunks  <span class="comment"># Return the list of chunks with headers</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># *************************** step 3 **********************************</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> tqdm(text_chunks, desc=<span class="string">&quot;Generating embeddings&quot;</span>):</span><br><span class="line">    <span class="comment"># Create an embedding for the chunk&#x27;s text</span></span><br><span class="line">    text_embedding = create_embeddings(chunk[<span class="string">&quot;text&quot;</span>])</span><br><span class="line">    <span class="comment"># Create an embedding for the chunk&#x27;s header</span></span><br><span class="line">    header_embedding = create_embeddings(chunk[<span class="string">&quot;header&quot;</span>])</span><br><span class="line">    <span class="comment"># Append the chunk&#x27;s header, text, and their embeddings to the list</span></span><br><span class="line">    embeddings.append(&#123;<span class="string">&quot;header&quot;</span>: chunk[<span class="string">&quot;header&quot;</span>], <span class="string">&quot;text&quot;</span>: chunk[<span class="string">&quot;text&quot;</span>], <span class="string">&quot;embedding&quot;</span>: text_embedding, <span class="string">&quot;header_embedding&quot;</span>: header_embedding&#125;)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># ****************************** step 4**************************************</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate through each chunk to calculate similarity scores</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:</span><br><span class="line">    <span class="comment"># Compute cosine similarity between query embedding and chunk text embedding</span></span><br><span class="line">    sim_text = cosine_similarity(np.array(query_embedding), np.array(chunk[<span class="string">&quot;embedding&quot;</span>]))</span><br><span class="line">    <span class="comment"># Compute cosine similarity between query embedding and chunk header embedding</span></span><br><span class="line">    sim_header = cosine_similarity(np.array(query_embedding), np.array(chunk[<span class="string">&quot;header_embedding&quot;</span>]))</span><br><span class="line">    <span class="comment"># Calculate the average similarity score</span></span><br><span class="line">    avg_similarity = (sim_text + sim_header) / <span class="number">2</span></span><br><span class="line">    <span class="comment"># Append the chunk and its average similarity score to the list</span></span><br><span class="line">    similarities.append((chunk, avg_similarity))</span><br></pre></td></tr></table></figure>

<h5 id="2-1-4-提问chunk"><a href="#2-1-4-提问chunk" class="headerlink" title="2.1.4 提问chunk"></a>2.1.4 提问chunk</h5><ul>
<li>同上，不过这里改变了方向，是从chunk中提取问题，而不是总结，换汤不换药， 注意这里的是 问题 + chunk text 向量化之后一起 进行检索，然后找出top-k</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the system prompt to guide the AI&#x27;s behavior</span></span><br><span class="line">system_prompt = <span class="string">&quot;You are an expert at generating relevant questions from text. Create concise questions that can be answered using only the provided text. Focus on key information and concepts.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the text chunk and the number of questions to generate</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Based on the following text, generate <span class="subst">&#123;num_questions&#125;</span> different questions that can be answered using only this text:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="subst">&#123;text_chunk&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Format your response as a numbered list of questions only, with no additional text.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-1-5-提取chunk，不采用固定chunk-size"><a href="#2-1-5-提取chunk，不采用固定chunk-size" class="headerlink" title="2.1.5 提取chunk，不采用固定chunk size"></a>2.1.5 提取chunk，不采用固定chunk size</h5><ul>
<li><strong>Proposition Chunking</strong></li>
</ul>
<p>仅仅采用固定分块，问题太多，会破坏句子的语义，句子不完整时会产生歧义等, 因此这种方法是从每个chunk中提取有用的关键信息作为新的chunk (这里也是使用LLM来分句的)</p>
<p>主要是两步：分段 然后评估筛选出最符合的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############### 产生新的chunk</span></span><br><span class="line"><span class="comment"># System prompt to instruct the AI on how to generate propositions</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;Please break down the following text into simple, self-contained propositions. </span></span><br><span class="line"><span class="string">Ensure that each proposition meets the following criteria:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. Express a Single Fact: Each proposition should state one specific fact or claim.</span></span><br><span class="line"><span class="string">2. Be Understandable Without Context: The proposition should be self-contained, meaning it can be understood without needing additional context.</span></span><br><span class="line"><span class="string">3. Use Full Names, Not Pronouns: Avoid pronouns or ambiguous references; use full entity names.</span></span><br><span class="line"><span class="string">4. Include Relevant Dates/Qualifiers: If applicable, include necessary dates, times, and qualifiers to make the fact precise.</span></span><br><span class="line"><span class="string">5. Contain One Subject-Predicate Relationship: Focus on a single subject and its corresponding action or attribute, without conjunctions or multiple clauses.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Output ONLY the list of propositions without any additional text or explanations.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User prompt containing the text chunk to be converted into propositions</span></span><br><span class="line">user_prompt = <span class="string">f&quot;Text to convert into propositions:\n\n<span class="subst">&#123;chunk[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################# 评估新chunk的质量 (结合原始的chunk)</span></span><br><span class="line"><span class="comment"># System prompt to instruct the AI on how to evaluate the proposition</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at evaluating the quality of propositions extracted from text.</span></span><br><span class="line"><span class="string">Rate the given proposition on the following criteria (scale 1-10):</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- Accuracy: How well the proposition reflects information in the original text</span></span><br><span class="line"><span class="string">- Clarity: How easy it is to understand the proposition without additional context</span></span><br><span class="line"><span class="string">- Completeness: Whether the proposition includes necessary details (dates, qualifiers, etc.)</span></span><br><span class="line"><span class="string">- Conciseness: Whether the proposition is concise without losing important information</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The response must be in valid JSON format with numerical scores for each criterion:</span></span><br><span class="line"><span class="string">&#123;&quot;accuracy&quot;: X, &quot;clarity&quot;: X, &quot;completeness&quot;: X, &quot;conciseness&quot;: X&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># User prompt containing the proposition and the original text</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;Proposition: <span class="subst">&#123;proposition&#125;</span></span></span><br></pre></td></tr></table></figure>

<h4 id="2-2-优化处理过程"><a href="#2-2-优化处理过程" class="headerlink" title="2.2 优化处理过程"></a>2.2 优化处理过程</h4><h5 id="2-2-1-分层RAG"><a href="#2-2-1-分层RAG" class="headerlink" title="2.2.1 分层RAG"></a>2.2.1 分层RAG</h5><p>传统的RAG当 text很大时，chunk就很多，匹配chunk缺乏上下文，而且每一个chunk都做相似度计算，计算量大，效率低，因此分层RAG的思想是，先对每一页做一个总结，先在总结中找到相关信息，然后再在对应的页中去找相关的详细信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############## 总结的prompt</span></span><br><span class="line"><span class="comment"># Define the system prompt to instruct the summarization model</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert summarization system.</span></span><br><span class="line"><span class="string">Create a detailed summary of the provided text. </span></span><br><span class="line"><span class="string">Focus on capturing the main topics, key information, and important facts.</span></span><br><span class="line"><span class="string">Your summary should be comprehensive enough to understand what the page contains</span></span><br><span class="line"><span class="string">but more concise than the original.&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-2-2-GraphRAG"><a href="#2-2-2-GraphRAG" class="headerlink" title="2.2.2 GraphRAG"></a>2.2.2 GraphRAG</h5><p>可参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/13801755777">GraphRAG快速入门与原理详解</a></p>
<p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/asynccode" alt="img" loading='lazy'></p>
<ul>
<li>实体提取 (Node, 节点)：利用LLM进行实体的提取，这些实体通常是指文档中出现的人物、地点、组织、概念等信息。</li>
<li>关系提取(Edage， 边)：关系挖掘是从文本中识别出实体之间的 关系，例如：谁与谁有关联、某个实体与另一个实体之间的关系是“属于”、“合作”、“对立”等。</li>
<li>Community(中文翻译成社区，感觉真的很奇怪，直接使用英文就好) 构建： 感觉是为了将不同部分的信息联系起来 通过使用 图谱聚类算法（如 Leiden 算法），GraphRAG 会将不同的实体和关系分组，形成多个 社区（Community）。这些社区是根据实体之间的相似度或关系的密切程度进行划分的。这种分组帮助 GraphRAG 更好地理解不同知识领域的结构，</li>
</ul>
<h5 id="2-2-3-KAG"><a href="#2-2-3-KAG" class="headerlink" title="2.2.3 KAG"></a>2.2.3 KAG</h5><p><a target="_blank" rel="noopener" href="https://github.com/OpenSPG/KAG/blob/master/README_cn.md">https://github.com/OpenSPG/KAG/blob/master/README_cn.md</a></p>
<h4 id="2-3-后处理"><a href="#2-3-后处理" class="headerlink" title="2.3 后处理"></a>2.3 后处理</h4><p>由于固定分块会破坏句子的连续性</p>
<h5 id="2-3-1-增加相邻上下文"><a href="#2-3-1-增加相邻上下文" class="headerlink" title="2.3.1 增加相邻上下文"></a>2.3.1 增加相邻上下文</h5><ul>
<li>在检索这一步时，将检索到的相邻chunk也包含进来以增加上下文，减少信息的损失</li>
</ul>
<h5 id="2-3-2-ReRank"><a href="#2-3-2-ReRank" class="headerlink" title="2.3.2 ReRank"></a>2.3.2 ReRank</h5><ul>
<li>ReRank<ul>
<li>就是觉得通过计算余弦相似度的方式得到的相似度具有一定的可信度，但是不高，因此使用其它方法对得到的top-k进行重排序，然后选择相关度最高的几个答案(一般使用LLM来实现)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at evaluating document relevance for search queries.</span></span><br><span class="line"><span class="string">Your task is to rate documents on a scale from 0 to 10 based on how well they answer the given query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Guidelines:</span></span><br><span class="line"><span class="string">- Score 0-2: Document is completely irrelevant</span></span><br><span class="line"><span class="string">- Score 3-5: Document has some relevant information but doesn&#x27;t directly answer the query</span></span><br><span class="line"><span class="string">- Score 6-8: Document is relevant and partially answers the query</span></span><br><span class="line"><span class="string">- Score 9-10: Document is highly relevant and directly answers the query</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">You MUST respond with ONLY a single integer score between 0 and 10. Do not include ANY other text.&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>也可以使用关键词的方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extract important keywords from the query</span></span><br><span class="line">keywords = [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> query.split() <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt; <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">scored_results = []  <span class="comment"># Initialize a list to store scored results</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    document_text = result[<span class="string">&quot;text&quot;</span>].lower()  <span class="comment"># Convert document text to lowercase</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Base score starts with vector similarity</span></span><br><span class="line">    base_score = result[<span class="string">&quot;similarity&quot;</span>] * <span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize keyword score</span></span><br><span class="line">    keyword_score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> keyword <span class="keyword">in</span> keywords:</span><br><span class="line">        <span class="keyword">if</span> keyword <span class="keyword">in</span> document_text:</span><br><span class="line">            <span class="comment"># Add points for each keyword found</span></span><br><span class="line">            keyword_score += <span class="number">0.1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Add more points if keyword appears near the beginning</span></span><br><span class="line">            first_position = document_text.find(keyword)</span><br><span class="line">            <span class="keyword">if</span> first_position &lt; <span class="built_in">len</span>(document_text) / <span class="number">4</span>:  <span class="comment"># In the first quarter of the text</span></span><br><span class="line">                keyword_score += <span class="number">0.1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Add points for keyword frequency</span></span><br><span class="line">            frequency = document_text.count(keyword)</span><br><span class="line">            keyword_score += <span class="built_in">min</span>(<span class="number">0.05</span> * frequency, <span class="number">0.2</span>)  <span class="comment"># Cap at 0.2</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Calculate the final score by combining base score and keyword score</span></span><br><span class="line">    final_score = base_score + keyword_score</span><br></pre></td></tr></table></figure>

<h5 id="2-3-3-增加上下文-v2"><a href="#2-3-3-增加上下文-v2" class="headerlink" title="2.3.3 增加上下文-v2"></a>2.3.3 增加上下文-v2</h5><ul>
<li>计算连续chunk (分段)的总相关性，然后输出 top-k 个分段</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_best_segments</span>(<span class="params">chunk_values, max_segment_length=<span class="number">20</span>, total_max_length=<span class="number">30</span>, min_segment_value=<span class="number">0.2</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Find the best segments using a variant of the maximum sum subarray algorithm.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        chunk_values (List[float]): Values for each chunk</span></span><br><span class="line"><span class="string">        max_segment_length (int): Maximum length of a single segment</span></span><br><span class="line"><span class="string">        total_max_length (int): Maximum total length across all segments</span></span><br><span class="line"><span class="string">        min_segment_value (float): Minimum value for a segment to be considered</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        List[Tuple[int, int]]: List of (start, end) indices for best segments</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Finding optimal continuous text segments...&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    best_segments = []</span><br><span class="line">    segment_scores = []</span><br><span class="line">    total_included_chunks = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Keep finding segments until we hit our limits</span></span><br><span class="line">    <span class="keyword">while</span> total_included_chunks &lt; total_max_length:</span><br><span class="line">        best_score = min_segment_value  <span class="comment"># Minimum threshold for a segment</span></span><br><span class="line">        best_segment = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Try each possible starting position</span></span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(chunk_values)):</span><br><span class="line">            <span class="comment"># Skip if this start position is already in a selected segment</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">any</span>(start &gt;= s[<span class="number">0</span>] <span class="keyword">and</span> start &lt; s[<span class="number">1</span>] <span class="keyword">for</span> s <span class="keyword">in</span> best_segments):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Try each possible segment length</span></span><br><span class="line">            <span class="keyword">for</span> length <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">min</span>(max_segment_length, <span class="built_in">len</span>(chunk_values) - start) + <span class="number">1</span>):</span><br><span class="line">                end = start + length</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Skip if end position is already in a selected segment</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">any</span>(end &gt; s[<span class="number">0</span>] <span class="keyword">and</span> end &lt;= s[<span class="number">1</span>] <span class="keyword">for</span> s <span class="keyword">in</span> best_segments):</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Calculate segment value as sum of chunk values</span></span><br><span class="line">                segment_value = <span class="built_in">sum</span>(chunk_values[start:end])</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Update best segment if this one is better</span></span><br><span class="line">                <span class="keyword">if</span> segment_value &gt; best_score:</span><br><span class="line">                    best_score = segment_value</span><br><span class="line">                    best_segment = (start, end)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># If we found a good segment, add it</span></span><br><span class="line">        <span class="keyword">if</span> best_segment:</span><br><span class="line">            best_segments.append(best_segment)</span><br><span class="line">            segment_scores.append(best_score)</span><br><span class="line">            total_included_chunks += best_segment[<span class="number">1</span>] - best_segment[<span class="number">0</span>]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Found segment <span class="subst">&#123;best_segment&#125;</span> with score <span class="subst">&#123;best_score:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># No more good segments to find</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Sort segments by their starting position for readability</span></span><br><span class="line">    best_segments = <span class="built_in">sorted</span>(best_segments, key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_segments, segment_scores</span><br></pre></td></tr></table></figure>

<h5 id="2-3-4-使用LLM过滤无效信息"><a href="#2-3-4-使用LLM过滤无效信息" class="headerlink" title="2.3.4 使用LLM过滤无效信息"></a>2.3.4 使用LLM过滤无效信息</h5><ul>
<li>使用LLM对top-k的chunk text进行判断，过滤，然后帮助我们筛选出最符合的信息，下面是实现的三种方式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> compression_type == <span class="string">&quot;selective&quot;</span>:</span><br><span class="line">    system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at information filtering. </span></span><br><span class="line"><span class="string">    Your task is to analyze a document chunk and extract ONLY the sentences or paragraphs that are directly relevant to the user&#x27;s query. Remove all irrelevant content.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Your output should:</span></span><br><span class="line"><span class="string">    1. ONLY include text that helps answer the query</span></span><br><span class="line"><span class="string">    2. Preserve the exact wording of relevant sentences (do not paraphrase)</span></span><br><span class="line"><span class="string">    3. Maintain the original order of the text</span></span><br><span class="line"><span class="string">    4. Include ALL relevant content, even if it seems redundant</span></span><br><span class="line"><span class="string">    5. EXCLUDE any text that isn&#x27;t relevant to the query</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Format your response as plain text with no additional comments.&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">elif</span> compression_type == <span class="string">&quot;summary&quot;</span>:</span><br><span class="line">    system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at summarization. </span></span><br><span class="line"><span class="string">    Your task is to create a concise summary of the provided chunk that focuses ONLY on information relevant to the user&#x27;s query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Your output should:</span></span><br><span class="line"><span class="string">    1. Be brief but comprehensive regarding query-relevant information</span></span><br><span class="line"><span class="string">    2. Focus exclusively on information related to the query</span></span><br><span class="line"><span class="string">    3. Omit irrelevant details</span></span><br><span class="line"><span class="string">    4. Be written in a neutral, factual tone</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Format your response as plain text with no additional comments.&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># extraction</span></span><br><span class="line">    system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at information extraction.</span></span><br><span class="line"><span class="string">    Your task is to extract ONLY the exact sentences from the document chunk that contain information relevant to answering the user&#x27;s query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Your output should:</span></span><br><span class="line"><span class="string">    1. Include ONLY direct quotes of relevant sentences from the original text</span></span><br><span class="line"><span class="string">    2. Preserve the original wording (do not modify the text)</span></span><br><span class="line"><span class="string">    3. Include ONLY sentences that directly relate to the query</span></span><br><span class="line"><span class="string">    4. Separate extracted sentences with newlines</span></span><br><span class="line"><span class="string">    5. Do not add any commentary or additional text</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Format your response as plain text with no additional comments.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the query and document chunk</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Query: <span class="subst">&#123;query&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Document Chunk:</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;chunk&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Extract only the content relevant to answering this query.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-3-5-优化检索策略-Adaptive-Retrieval"><a href="#2-3-5-优化检索策略-Adaptive-Retrieval" class="headerlink" title="2.3.5 优化检索策略- Adaptive Retrieval"></a>2.3.5 优化检索策略- Adaptive Retrieval</h5><p>本质还是query的改写</p>
<p>RAG的效果差，也有可能是检索的策略有问题，对于所有的问题，全部采用向量相似度匹配，可能不太对，因此针对不同的用户问题，需要采取不同的策略</p>
<ul>
<li><strong>对查询类型进行分类: 事实、分析、观点或情境  （使用大模型来进行选择）</strong></li>
<li>然后 Query Transform （根据上面的类型进行改写）, 然后和之前一样进行相似度进行匹配</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the system prompt to guide the AI&#x27;s classification</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at classifying questions. </span></span><br><span class="line"><span class="string">    Classify the given query into exactly one of these categories:</span></span><br><span class="line"><span class="string">    - Factual: Queries seeking specific, verifiable information.</span></span><br><span class="line"><span class="string">    - Analytical: Queries requiring comprehensive analysis or explanation.</span></span><br><span class="line"><span class="string">    - Opinion: Queries about subjective matters or seeking diverse viewpoints.</span></span><br><span class="line"><span class="string">    - Contextual: Queries that depend on user-specific context.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return ONLY the category name, without any explanation or additional text.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>query 改写的部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##################### 基于事实 Factual </span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at enhancing search queries.</span></span><br><span class="line"><span class="string">    Your task is to reformulate the given factual query to make it more precise and </span></span><br><span class="line"><span class="string">    specific for information retrieval. Focus on key entities and their relationships.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Provide ONLY the enhanced query without any explanation.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">user_prompt = <span class="string">f&quot;Enhance this factual query: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##################### 基于事实 Factual </span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at enhancing search queries.</span></span><br><span class="line"><span class="string">    Your task is to reformulate the given factual query to make it more precise and </span></span><br><span class="line"><span class="string">    specific for information retrieval. Focus on key entities and their relationships.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Provide ONLY the enhanced query without any explanation.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">user_prompt = <span class="string">f&quot;Enhance this factual query: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 基于分析 Analytical </span></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI in generating sub-questions</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at breaking down complex questions.</span></span><br><span class="line"><span class="string">Generate sub-questions that explore different aspects of the main analytical query.</span></span><br><span class="line"><span class="string">These sub-questions should cover the breadth of the topic and help retrieve </span></span><br><span class="line"><span class="string">comprehensive information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Return a list of exactly 3 sub-questions, one per line.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the user prompt with the main query</span></span><br><span class="line">user_prompt = <span class="string">f&quot;Generate sub-questions for this analytical query: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##################  基于分析 Analytical </span></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI in generating sub-questions</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at breaking down complex questions.</span></span><br><span class="line"><span class="string">Generate sub-questions that explore different aspects of the main analytical query.</span></span><br><span class="line"><span class="string">These sub-questions should cover the breadth of the topic and help retrieve </span></span><br><span class="line"><span class="string">comprehensive information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Return a list of exactly 3 sub-questions, one per line.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the user prompt with the main query</span></span><br><span class="line">user_prompt = <span class="string">f&quot;Generate sub-questions for this analytical query: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">################## 基于观点 Opinion Strategy  </span></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI in identifying different perspectives</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at identifying different perspectives on a topic.</span></span><br><span class="line"><span class="string">    For the given query about opinions or viewpoints, identify different perspectives </span></span><br><span class="line"><span class="string">    that people might have on this topic.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return a list of exactly 3 different viewpoint angles, one per line.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the user prompt with the main query</span></span><br><span class="line">user_prompt = <span class="string">f&quot;Identify different perspectives on: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract and clean the viewpoints</span></span><br><span class="line">viewpoints = response.choices[<span class="number">0</span>].message.content.strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">viewpoints = [v.strip() <span class="keyword">for</span> v <span class="keyword">in</span> viewpoints <span class="keyword">if</span> v.strip()]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Identified viewpoints: <span class="subst">&#123;viewpoints&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve documents representing each viewpoint</span></span><br><span class="line">all_results = []</span><br><span class="line"><span class="keyword">for</span> viewpoint <span class="keyword">in</span> viewpoints:</span><br><span class="line">    <span class="comment"># 注意这里的做法</span></span><br><span class="line">    <span class="comment"># Combine the main query with the viewpoint</span></span><br><span class="line">    combined_query = <span class="string">f&quot;<span class="subst">&#123;query&#125;</span> <span class="subst">&#123;viewpoint&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># Create embeddings for the combined query</span></span><br><span class="line">    viewpoint_embedding = create_embeddings(combined_query)</span><br><span class="line">    <span class="comment"># Perform similarity search for the combined query</span></span><br><span class="line">    results = vector_store.similarity_search(viewpoint_embedding, k=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Mark results with the viewpoint they represent</span></span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        result[<span class="string">&quot;viewpoint&quot;</span>] = viewpoint</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Add the results to the list of all results</span></span><br><span class="line">    all_results.extend(results)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">  <span class="comment">################### 基于情境  Contextual Strategy</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> user_context:</span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at understanding implied context in questions.</span></span><br><span class="line"><span class="string">For the given query, infer what contextual information might be relevant or implied </span></span><br><span class="line"><span class="string">but not explicitly stated. Focus on what background would help answering this query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Return a brief description of the implied context.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">user_prompt = <span class="string">f&quot;Infer the implied context in this query: <span class="subst">&#123;query&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate the inferred context using the LLM</span></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;meta-llama/Llama-3.2-3B-Instruct&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_prompt&#125;</span><br><span class="line">    ],</span><br><span class="line">    temperature=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract and print the inferred context</span></span><br><span class="line">user_context = response.choices[<span class="number">0</span>].message.content.strip()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Inferred context: <span class="subst">&#123;user_context&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reformulate the query to incorporate context</span></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an expert at reformulating questions with context.</span></span><br><span class="line"><span class="string">Given a query and some contextual information, create a more specific query that </span></span><br><span class="line"><span class="string">incorporates the context to get more relevant information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Return ONLY the reformulated query without explanation.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Query: <span class="subst">&#123;query&#125;</span></span></span><br><span class="line"><span class="string">Context: <span class="subst">&#123;user_context&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Reformulate the query to incorporate this context:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate the contextualized query using the LLM</span></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=<span class="string">&quot;meta-llama/Llama-3.2-3B-Instruct&quot;</span>,</span><br><span class="line">messages=[</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_prompt&#125;</span><br><span class="line">],</span><br><span class="line">temperature=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<h5 id="2-3-6-CRAG"><a href="#2-3-6-CRAG" class="headerlink" title="2.3.6 CRAG"></a>2.3.6 CRAG</h5><p><strong>对检索的文件进行了修正</strong></p>
<p>校验检索得到的文档，如果文档相关性评分比较高(相关性分数还是使用LLM)，那么继续原先的步骤即可；如果相关性评分很低，那么采用外部的工具(如浏览器等)来搜索更多的资料，用以补充；如果相关性评分在中间，结合检索文本和搜索文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">crag_process</span>(<span class="params">query, vector_store, k=<span class="number">3</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n=== Processing query with CRAG: <span class="subst">&#123;query&#125;</span> ===\n&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Create query embedding and retrieve documents</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Retrieving initial documents...&quot;</span>)</span><br><span class="line">    query_embedding = create_embeddings(query)</span><br><span class="line">    retrieved_docs = vector_store.similarity_search(query_embedding, k=k)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Evaluate document relevance</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Evaluating document relevance...&quot;</span>)</span><br><span class="line">    relevance_scores = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> retrieved_docs:</span><br><span class="line">        score = evaluate_document_relevance(query, doc[<span class="string">&quot;text&quot;</span>])</span><br><span class="line">        relevance_scores.append(score)</span><br><span class="line">        doc[<span class="string">&quot;relevance&quot;</span>] = score</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Document scored <span class="subst">&#123;score:<span class="number">.2</span>f&#125;</span> relevance&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Determine action based on best relevance score</span></span><br><span class="line">    max_score = <span class="built_in">max</span>(relevance_scores) <span class="keyword">if</span> relevance_scores <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    best_doc_idx = relevance_scores.index(max_score) <span class="keyword">if</span> relevance_scores <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Track sources for attribution</span></span><br><span class="line">    sources = []</span><br><span class="line">    final_knowledge = <span class="string">&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 4: Execute the appropriate knowledge acquisition strategy</span></span><br><span class="line">    <span class="keyword">if</span> max_score &gt; <span class="number">0.7</span>:</span><br><span class="line">        <span class="comment"># Case 1: High relevance - Use document directly</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;High relevance (<span class="subst">&#123;max_score:<span class="number">.2</span>f&#125;</span>) - Using document directly&quot;</span>)</span><br><span class="line">        best_doc = retrieved_docs[best_doc_idx][<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        final_knowledge = best_doc</span><br><span class="line">        sources.append(&#123;</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: <span class="string">&quot;Document&quot;</span>,</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">        &#125;)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">elif</span> max_score &lt; <span class="number">0.3</span>:</span><br><span class="line">        <span class="comment"># Case 2: Low relevance - Use web search</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Low relevance (<span class="subst">&#123;max_score:<span class="number">.2</span>f&#125;</span>) - Performing web search&quot;</span>)</span><br><span class="line">        web_results, web_sources = perform_web_search(query)</span><br><span class="line">        final_knowledge = refine_knowledge(web_results)</span><br><span class="line">        sources.extend(web_sources)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Case 3: Medium relevance - Combine document with web search</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Medium relevance (<span class="subst">&#123;max_score:<span class="number">.2</span>f&#125;</span>) - Combining document with web search&quot;</span>)</span><br><span class="line">        best_doc = retrieved_docs[best_doc_idx][<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        refined_doc = refine_knowledge(best_doc)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get web results</span></span><br><span class="line">        web_results, web_sources = perform_web_search(query)</span><br><span class="line">        refined_web = refine_knowledge(web_results)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Combine knowledge</span></span><br><span class="line">        final_knowledge = <span class="string">f&quot;From document:\n<span class="subst">&#123;refined_doc&#125;</span>\n\nFrom web search:\n<span class="subst">&#123;refined_web&#125;</span>&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add sources</span></span><br><span class="line">        sources.append(&#123;</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: <span class="string">&quot;Document&quot;</span>,</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">        &#125;)</span><br><span class="line">        sources.extend(web_sources)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 5: Generate final response</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Generating final response...&quot;</span>)</span><br><span class="line">    response = generate_response(query, final_knowledge, sources)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Return comprehensive results</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;query&quot;</span>: query,</span><br><span class="line">        <span class="string">&quot;response&quot;</span>: response,</span><br><span class="line">        <span class="string">&quot;retrieved_docs&quot;</span>: retrieved_docs,</span><br><span class="line">        <span class="string">&quot;relevance_scores&quot;</span>: relevance_scores,</span><br><span class="line">        <span class="string">&quot;max_relevance&quot;</span>: max_score,</span><br><span class="line">        <span class="string">&quot;final_knowledge&quot;</span>: final_knowledge,</span><br><span class="line">        <span class="string">&quot;sources&quot;</span>: sources</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-4-输入部分"><a href="#2-4-输入部分" class="headerlink" title="2.4 输入部分"></a>2.4 输入部分</h4><h5 id="2-4-1-Query-Transform"><a href="#2-4-1-Query-Transform" class="headerlink" title="2.4.1 Query Transform"></a>2.4.1 Query Transform</h5><ul>
<li><p>Query改写</p>
<p>可能是觉得用户提的问题不够具体，导致搜索的时候找到对应的信息；亦或者是用户的问题太复杂了，包含了很多层级的问题；亦或者是用户的问题太细致了，以至匹配不到相关的信息，需要对信息step back；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############ 1.Query Rewriting </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI assistant&#x27;s behavior</span></span><br><span class="line">system_prompt = <span class="string">&quot;You are an AI assistant specialized in improving search queries. Your task is to rewrite user queries to be more specific, detailed, and likely to retrieve relevant information.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the original query to be rewritten</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Rewrite the following query to make it more specific and detailed. Include relevant terms and concepts that might help in retrieving accurate information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Original query: <span class="subst">&#123;original_query&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Rewritten query:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############ 2. Step-back Prompting</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI assistant&#x27;s behavior</span></span><br><span class="line">system_prompt = <span class="string">&quot;You are an AI assistant specialized in search strategies. Your task is to generate broader, more general versions of specific queries to retrieve relevant background information.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the original query to be generalized</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Generate a broader, more general version of the following query that could help retrieve useful background information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Original query: <span class="subst">&#123;original_query&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Step-back query:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############ 3. Sub-query Decomposition</span></span><br><span class="line"><span class="comment"># Define the system prompt to guide the AI assistant&#x27;s behavior</span></span><br><span class="line">system_prompt = <span class="string">&quot;You are an AI assistant specialized in breaking down complex questions. Your task is to decompose complex queries into simpler sub-questions that, when answered together, address the original query.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the original query to be decomposed</span></span><br><span class="line">user_prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Break down the following complex query into <span class="subst">&#123;num_subqueries&#125;</span> simpler sub-queries. Each sub-query should focus on a different aspect of the original question.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Original query: <span class="subst">&#123;original_query&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Generate <span class="subst">&#123;num_subqueries&#125;</span> sub-queries, one per line, in this format:</span></span><br><span class="line"><span class="string">1. [First sub-query]</span></span><br><span class="line"><span class="string">2. [Second sub-query]</span></span><br><span class="line"><span class="string">And so on...</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="2-4-2-HyDE-Hypothetical-Document-Embedding"><a href="#2-4-2-HyDE-Hypothetical-Document-Embedding" class="headerlink" title="2.4.2 HyDE (Hypothetical Document Embedding)"></a>2.4.2 HyDE (Hypothetical Document Embedding)</h5><p> 本质上还是Query改写的一种，具体操作方法如下：</p>
<ul>
<li>根据用户的问题，假想一个document，这个document可以解决用户的query； (这里使用的还是LLM)</li>
<li>然后使用这个document进行向量化和相似度的比较，继续后面的流程；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the system prompt to instruct the model on how to generate the document</span></span><br><span class="line">system_prompt = <span class="string">f&quot;&quot;&quot;You are an expert document creator. </span></span><br><span class="line"><span class="string">Given a question, generate a detailed document that would directly answer this question.</span></span><br><span class="line"><span class="string">The document should be approximately <span class="subst">&#123;desired_length&#125;</span> characters long and provide an in-depth, </span></span><br><span class="line"><span class="string">informative answer to the question. Write as if this document is from an authoritative source</span></span><br><span class="line"><span class="string">on the subject. Include specific details, facts, and explanations.</span></span><br><span class="line"><span class="string">Do not mention that this is a hypothetical document - just write the content directly.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the user prompt with the query</span></span><br><span class="line">user_prompt = <span class="string">f&quot;Question: <span class="subst">&#123;query&#125;</span>\n\nGenerate a document that fully answers this question:&quot;</span></span><br></pre></td></tr></table></figure>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Rag/">Rag</a></div><div class="post-share"><div class="social-share" data-image="/covers/22.webp" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-%E7%BB%84%E5%86%85%E5%88%86%E4%BA%AB/" title="大模型入门(组内分享)"><img class="cover" src="/covers/0.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">大模型入门(组内分享)</div></div><div class="info-2"><div class="info-item-1">组内LLM分享，从基础到入门</div></div></div></a><a class="pagination-related" href="/2025/04/08/langgraph%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0/" title="langgraph官方文档学习"><img class="cover" src="/covers/13.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">langgraph官方文档学习</div></div><div class="info-2"><div class="info-item-1">长期不使用langgraph，导致又忘记了，写个blog记录一下，方面快速回顾</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/13/GraphRAG/" title="GraphRAG"><img class="cover" src="/covers/11.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-13</div><div class="info-item-2">GraphRAG</div></div><div class="info-2"><div class="info-item-1">学习了解GraphRAG</div></div></div></a><a class="pagination-related" href="/2025/11/28/LightRAG/" title="LightRAG"><img class="cover" src="/covers/14.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-28</div><div class="info-item-2">LightRAG</div></div><div class="info-2"><div class="info-item-1">学习了解LightRAG</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">why join the navy if you can be a pirate</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E7%9A%84RAG%E6%B5%81%E7%A8%8B-Native-RAG"><span class="toc-text">1. 基本的RAG流程-Native RAG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-RAG%E4%BC%98%E5%8C%96"><span class="toc-text">2. RAG优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E4%BC%98%E5%8C%96chunk"><span class="toc-text">2.1 优化chunk</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-1-%E6%8B%BC%E6%8E%A5%E6%96%AD%E8%A3%82%E7%9A%84%E5%9D%97"><span class="toc-text">2.1.1 拼接断裂的块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-2-%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="toc-text">2.1.2 使用不同的分块大小</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-3-%E6%80%BB%E7%BB%93chunk"><span class="toc-text">2.1.3 总结chunk</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-4-%E6%8F%90%E9%97%AEchunk"><span class="toc-text">2.1.4 提问chunk</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-5-%E6%8F%90%E5%8F%96chunk%EF%BC%8C%E4%B8%8D%E9%87%87%E7%94%A8%E5%9B%BA%E5%AE%9Achunk-size"><span class="toc-text">2.1.5 提取chunk，不采用固定chunk size</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E4%BC%98%E5%8C%96%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B"><span class="toc-text">2.2 优化处理过程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-%E5%88%86%E5%B1%82RAG"><span class="toc-text">2.2.1 分层RAG</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-2-GraphRAG"><span class="toc-text">2.2.2 GraphRAG</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-3-KAG"><span class="toc-text">2.2.3 KAG</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E5%90%8E%E5%A4%84%E7%90%86"><span class="toc-text">2.3 后处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-1-%E5%A2%9E%E5%8A%A0%E7%9B%B8%E9%82%BB%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-text">2.3.1 增加相邻上下文</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-2-ReRank"><span class="toc-text">2.3.2 ReRank</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-3-%E5%A2%9E%E5%8A%A0%E4%B8%8A%E4%B8%8B%E6%96%87-v2"><span class="toc-text">2.3.3 增加上下文-v2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-4-%E4%BD%BF%E7%94%A8LLM%E8%BF%87%E6%BB%A4%E6%97%A0%E6%95%88%E4%BF%A1%E6%81%AF"><span class="toc-text">2.3.4 使用LLM过滤无效信息</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-5-%E4%BC%98%E5%8C%96%E6%A3%80%E7%B4%A2%E7%AD%96%E7%95%A5-Adaptive-Retrieval"><span class="toc-text">2.3.5 优化检索策略- Adaptive Retrieval</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-6-CRAG"><span class="toc-text">2.3.6 CRAG</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E8%BE%93%E5%85%A5%E9%83%A8%E5%88%86"><span class="toc-text">2.4 输入部分</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-1-Query-Transform"><span class="toc-text">2.4.1 Query Transform</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-2-HyDE-Hypothetical-Document-Embedding"><span class="toc-text">2.4.2 HyDE (Hypothetical Document Embedding)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/26/35-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2/" title="大模型推理部署">大模型推理部署</a><time datetime="2026-01-26T02:17:21.000Z" title="发表于 2026-01-26 10:17:21">2026-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/26/34-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-tensorRT/" title="模型推理基本知识-tensorRT">模型推理基本知识-tensorRT</a><time datetime="2026-01-26T02:14:09.000Z" title="发表于 2026-01-26 10:14:09">2026-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/26/33-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-CUDA/" title="模型推理基本知识-CUDA">模型推理基本知识-CUDA</a><time datetime="2026-01-26T02:13:33.000Z" title="发表于 2026-01-26 10:13:33">2026-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/26/32-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-%E9%87%8F%E5%8C%96/" title="模型推理基本知识-量化">模型推理基本知识-量化</a><time datetime="2026-01-26T02:06:59.000Z" title="发表于 2026-01-26 10:06:59">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/22/31-Agent-Sandbox/" title="Agent Sandbox"><img src="/covers/31.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Agent Sandbox"/></a><div class="content"><a class="title" href="/2026/01/22/31-Agent-Sandbox/" title="Agent Sandbox">Agent Sandbox</a><time datetime="2026-01-22T07:32:57.000Z" title="发表于 2026-01-22 15:32:57">2026-01-22</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.2"></script><script src="/js/main.js?v=5.5.2"></script><div class="js-pjax"></div><img src="/img/fengmian.webp" alt="" style="position:absolute;width:0;height:0;opacity:0;pointer-events:none;" loading="eager" fetchpriority="high" onload="this.style.display='none'"></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>