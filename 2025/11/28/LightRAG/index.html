<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LightRAG | 大潘子的文字角落</title><meta name="author" content="Pan"><meta name="copyright" content="Pan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="学习了解LightRAG">
<meta property="og:type" content="article">
<meta property="og:title" content="LightRAG">
<meta property="og:url" content="https://flippy-bird.github.io/2025/11/28/LightRAG/index.html">
<meta property="og:site_name" content="大潘子的文字角落">
<meta property="og:description" content="学习了解LightRAG">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flippy-bird.github.io/covers/14.webp">
<meta property="article:published_time" content="2025-11-28T07:06:12.000Z">
<meta property="article:modified_time" content="2026-02-05T05:51:25.335Z">
<meta property="article:author" content="Pan">
<meta property="article:tag" content="Rag">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://flippy-bird.github.io/covers/14.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LightRAG",
  "url": "https://flippy-bird.github.io/2025/11/28/LightRAG/",
  "image": "https://flippy-bird.github.io/covers/14.webp",
  "datePublished": "2025-11-28T07:06:12.000Z",
  "dateModified": "2026-02-05T05:51:25.335Z",
  "author": [
    {
      "@type": "Person",
      "name": "Pan",
      "url": "https://flippy-bird.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favion.png"><link rel="canonical" href="https://flippy-bird.github.io/2025/11/28/LightRAG/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css?v=5.5.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LightRAG',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preload" as="image" href="/img/fengmian.webp" fetchpriority="high"><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/covers/14.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">大潘子的文字角落</span></a><a class="nav-page-title" href="/"><span class="site-name">LightRAG</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LightRAG</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-28T07:06:12.000Z" title="发表于 2025-11-28 15:06:12">2025-11-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-05T05:51:25.335Z" title="更新于 2026-02-05 13:51:25">2026-02-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/RAG%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/">RAG框架学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h3><p>待详细看完完整论文后补充，大概就是GraphRag虽然效果比较好，但是速度慢，建立图的过程中消耗的token也很多，因此有了LightRag；</p>
<h3 id="2-LightRAG的原理"><a href="#2-LightRAG的原理" class="headerlink" title="2. LightRAG的原理"></a>2. LightRAG的原理</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/4821793882">深度解析比微软的GraphRAG简洁很多的LightRAG，一看就懂</a></p>
</blockquote>
<p>先看了知乎上的一些解读，感觉就是简化版本的GraphRAG，在索引阶段的处理方式是差不多的，只是LightRAG将GraphRAG中比较慢的部分去掉了(社区报告部分，因此也去掉了global search)，数据处理流程是：先分块，然后提取实体和关系，然后入库，index部分的工作就完成了；</p>
<img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20251128151441858.png" alt="image-20251128151441858" style="zoom: 67%;" / loading='lazy'>

<p>在查询阶段，提供了4中方式：</p>
<ul>
<li>最基本的向量相似度匹配</li>
<li>local search: 根据用户的query生成一些low-level 的关键词，然后根据生成的关键词去建立好的图谱查询；</li>
<li>global search: 根据用户的query生成一些high-level 的关键词，然后根据生成的关键词去建立好的图谱查询；</li>
<li>混合搜索：local search + global search</li>
</ul>
<p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20251128151926968.png" alt="image-20251128151926968" loading='lazy'></p>
<h3 id="3-源码解析"><a href="#3-源码解析" class="headerlink" title="3. 源码解析"></a>3. 源码解析</h3><ul>
<li><input disabled="" type="checkbox"> TODO</li>
</ul>
<p>看了源码之后，讲道理，lightRAG里面对于一些边界case处理真的不错，感觉是个工程级的项目，值得推敲学习一下，当然也导致了代码有点长了&#x3D;_&#x3D;#</p>
<h4 id="分段-chunks"><a href="#分段-chunks" class="headerlink" title="分段(chunks)"></a>分段(chunks)</h4><p>关于怎样切分，提取实体关系等等，都是放在了<code>lightrag/operate.py</code>文件里面</p>
<p>其实LightRag里面的切分逻辑还是比较简单，实现了按照特定字符切分和按照固定的token_size切分方式，具体的源码在<code>chunking_by_token_size()</code>函数里面,核心逻辑如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chunking_by_token_size</span>(<span class="params">tokenizer, content, split_by_character, </span></span><br><span class="line"><span class="params">                          chunk_overlap_token_size=<span class="number">100</span>, chunk_token_size=<span class="number">1200</span></span>):</span><br><span class="line">    tokens = tokenizer.encode(content)</span><br><span class="line">    results = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 方式1：按特定字符分割（如换行符）</span></span><br><span class="line">    <span class="keyword">if</span> split_by_character:</span><br><span class="line">        raw_chunks = content.split(split_by_character)</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> raw_chunks:</span><br><span class="line">            tokens = tokenizer.encode(chunk)</span><br><span class="line">            <span class="comment"># 如果超过限制，再按 token 大小切分</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(tokens) &gt; chunk_token_size:</span><br><span class="line">                <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(tokens), </span><br><span class="line">                                  chunk_token_size - chunk_overlap_token_size):</span><br><span class="line">                    chunk_content = tokenizer.decode(</span><br><span class="line">                        tokens[start:start + chunk_token_size]</span><br><span class="line">                    )</span><br><span class="line">                    results.append(&#123;<span class="string">&quot;tokens&quot;</span>: ..., <span class="string">&quot;content&quot;</span>: ..., <span class="string">&quot;chunk_order_index&quot;</span>: ...&#125;)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 方式2：直接按 token 大小切分</span></span><br><span class="line">        <span class="keyword">for</span> index, start <span class="keyword">in</span> <span class="built_in">enumerate</span>(</span><br><span class="line">            <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(tokens), chunk_token_size - chunk_overlap_token_size)</span><br><span class="line">        ):</span><br><span class="line">            chunk_content = tokenizer.decode(tokens[start:start + chunk_token_size])</span><br><span class="line">            results.append(...)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="实体-关系提取"><a href="#实体-关系提取" class="headerlink" title="实体&#x2F;关系提取"></a>实体&#x2F;关系提取</h4><p>实体&#x2F;关系的抽取是使用LLM来进行的，按照上面的流程图，在获取chunks之后，使用LLM获取chunk中的实体&#x2F;关系，项目使用prompt部分都在<code>lightrag/prompt.py</code>文件里面，功能函数在<code>extract_entities()</code>里面实现，核心流程如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">extract_entities</span>(<span class="params">chunks, global_config, ...</span>):</span><br><span class="line">    <span class="comment"># 1. 构建提示词</span></span><br><span class="line">    entity_extraction_system_prompt = PROMPTS[<span class="string">&quot;entity_extraction_system_prompt&quot;</span>].<span class="built_in">format</span>(...)</span><br><span class="line">    entity_extraction_user_prompt = PROMPTS[<span class="string">&quot;entity_extraction_user_prompt&quot;</span>].<span class="built_in">format</span>(...)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 并发处理 chunks（受 llm_model_max_async 限制）</span></span><br><span class="line">    semaphore = asyncio.Semaphore(chunk_max_async)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">_process_single_content</span>(<span class="params">chunk</span>):</span><br><span class="line">        <span class="comment"># 2.1 调用 LLM 提取</span></span><br><span class="line">        final_result, timestamp = <span class="keyword">await</span> use_llm_func_with_cache(</span><br><span class="line">            entity_extraction_user_prompt, use_llm_func, ...</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2.2 解析结果</span></span><br><span class="line">        maybe_nodes, maybe_edges = <span class="keyword">await</span> _process_extraction_result(final_result, ...)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2.3 【Gleaning】如果开启，再提取一次以捕获遗漏</span></span><br><span class="line">        <span class="keyword">if</span> entity_extract_max_gleaning &gt; <span class="number">0</span>:_summarize_descriptions</span><br><span class="line">            glean_result = <span class="keyword">await</span> use_llm_func_with_cache(</span><br><span class="line">                entity_continue_extraction_user_prompt, ..., </span><br><span class="line">                history_messages=[user_prompt, final_result]  <span class="comment"># 带历史</span></span><br><span class="line">            )</span><br><span class="line">            glean_nodes, glean_edges = <span class="keyword">await</span> _process_extraction_result(glean_result, ...)</span><br><span class="line">            <span class="comment"># 合并结果（选描述更长的）</span></span><br><span class="line">            maybe_nodes = merge_nodes(maybe_nodes, glean_nodes)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> maybe_nodes, maybe_edges</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 并发执行所有 chunks</span></span><br><span class="line">    tasks = [_process_with_semaphore(c) <span class="keyword">for</span> c <span class="keyword">in</span> chunks]</span><br><span class="line">    chunk_results = <span class="keyword">await</span> asyncio.gather(*tasks)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> chunk_results  <span class="comment"># [(nodes1, edges1), (nodes2, edges2), ...]</span></span><br></pre></td></tr></table></figure>

<p>可以看到，代码做了防御性变成，<code>_process_extraction_result</code>对llm可能得各种情形都进行了处理，<strong>同时考虑到chunks之前的处理互补干扰，因此这里还使用了<code>asyncio.Semaphore</code>来实现并发执行</strong></p>
<p>得到所有的实体和关系后，合并入库<code>merge_nodes_and_edges</code>, 这里函数里面有比较多的逻辑，可以在源码部分详细查看，这里只分析主要代码；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">merge_nodes_and_edges</span>(<span class="params">chunk_results, knowledge_graph_inst, </span></span><br><span class="line"><span class="params">                               entity_vdb, relationships_vdb, ...</span>):</span><br><span class="line">    <span class="comment"># 收集所有实体和关系</span></span><br><span class="line">    all_nodes = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    all_edges = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> maybe_nodes, maybe_edges <span class="keyword">in</span> chunk_results:</span><br><span class="line">        <span class="keyword">for</span> entity_name, entities <span class="keyword">in</span> maybe_nodes.items():</span><br><span class="line">            all_nodes[entity_name].extend(entities)</span><br><span class="line">        <span class="keyword">for</span> edge_key, edges <span class="keyword">in</span> maybe_edges.items():</span><br><span class="line">            sorted_edge_key = <span class="built_in">tuple</span>(<span class="built_in">sorted</span>(edge_key))  <span class="comment"># 统一排序，无向图</span></span><br><span class="line">            all_edges[sorted_edge_key].extend(edges)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Phase 1: 并发处理所有实体</span></span><br><span class="line">    entity_tasks = []</span><br><span class="line">    <span class="keyword">for</span> entity_name, entities <span class="keyword">in</span> all_nodes.items():</span><br><span class="line">        task = asyncio.create_task(_locked_process_entity_name(entity_name, entities))</span><br><span class="line">        entity_tasks.append(task)</span><br><span class="line">    </span><br><span class="line">    processed_entities = <span class="keyword">await</span> asyncio.gather(*entity_tasks, return_exceptions=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Phase 2: 并发处理所有关系</span></span><br><span class="line">    edge_tasks = []</span><br><span class="line">    <span class="keyword">for</span> edge_key, edges <span class="keyword">in</span> all_edges.items():</span><br><span class="line">        task = asyncio.create_task(_locked_process_edges(edge_key, edges))</span><br><span class="line">        edge_tasks.append(task)</span><br><span class="line">    </span><br><span class="line">    processed_edges = <span class="keyword">await</span> asyncio.gather(*edge_tasks, return_exceptions=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Phase 3: 更新文档级索引</span></span><br><span class="line">    <span class="keyword">await</span> full_entities_storage.upsert(&#123;</span><br><span class="line">        doc_id: &#123;<span class="string">&quot;entity_names&quot;</span>: [...], <span class="string">&quot;count&quot;</span>: ...&#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">await</span> full_relations_storage.upsert(&#123;</span><br><span class="line">        doc_id: &#123;<span class="string">&quot;relation_pairs&quot;</span>: [...], <span class="string">&quot;count&quot;</span>: ...&#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure>



<h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><p>查询的主要功能实现也在 <code>lightrag/operate.py</code>文件里面，主函数是<code>kg_query</code>,其主要流程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">kg_query</span>(<span class="params">query, knowledge_graph_inst, entities_vdb, </span></span><br><span class="line"><span class="params">                   relationships_vdb, text_chunks_db, query_param, ...</span>):</span><br><span class="line">    <span class="comment"># 1. 提取关键词</span></span><br><span class="line">    hl_keywords, ll_keywords = <span class="keyword">await</span> get_keywords_from_query(</span><br><span class="line">        query, query_param, global_config</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 构建查询上下文（4 阶段流水线）</span></span><br><span class="line">    context_result = <span class="keyword">await</span> _build_query_context(</span><br><span class="line">        query, ll_keywords, hl_keywords, </span><br><span class="line">        knowledge_graph_inst, entities_vdb, relationships_vdb, </span><br><span class="line">        text_chunks_db, query_param</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> query_param.only_need_context:</span><br><span class="line">        <span class="keyword">return</span> QueryResult(content=context_result.context, raw_data=context_result.raw_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 调用 LLM</span></span><br><span class="line">    sys_prompt = PROMPTS[<span class="string">&quot;rag_response&quot;</span>].<span class="built_in">format</span>(</span><br><span class="line">        response_type=query_param.response_type,</span><br><span class="line">        context_data=context_result.context</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    response = <span class="keyword">await</span> use_model_func(</span><br><span class="line">        query, system_prompt=sys_prompt, </span><br><span class="line">        stream=query_param.stream</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> QueryResult(content=response, raw_data=context_result.raw_data)</span><br></pre></td></tr></table></figure>

<p>提取关键词那一步就是上面第二张图里面的low-level keywords和high-level keywords,这一部分的prompt如下：从prompt里面可以看到区别如下：</p>
<ul>
<li><strong>high_level_keywords</strong>：用于表示总体概念或主题，捕捉用户的核心意图、所属领域或问题类型。</li>
<li><strong>low_level_keywords</strong>：用于表示具体实体或细节，识别特定实体、专有名词、技术术语、产品名称或具体项目。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PROMPTS[<span class="string">&quot;keywords_extraction&quot;</span>] = <span class="string">&quot;&quot;&quot;---Role---</span></span><br><span class="line"><span class="string">You are an expert keyword extractor, specializing in analyzing user queries for a Retrieval-Augmented Generation (RAG) system. Your purpose is to identify both high-level and low-level keywords in the user&#x27;s query that will be used for effective document retrieval.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---Goal---</span></span><br><span class="line"><span class="string">Given a user query, your task is to extract two distinct types of keywords:</span></span><br><span class="line"><span class="string">1. **high_level_keywords**: for overarching concepts or themes, capturing user&#x27;s core intent, the subject area, or the type of question being asked.</span></span><br><span class="line"><span class="string">2. **low_level_keywords**: for specific entities or details, identifying the specific entities, proper nouns, technical jargon, product names, or concrete items.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---Instructions &amp; Constraints---</span></span><br><span class="line"><span class="string">1. **Output Format**: Your output MUST be a valid JSON object and nothing else. Do not include any explanatory text, markdown code fences (like ```json), or any other text before or after the JSON. It will be parsed directly by a JSON parser.</span></span><br><span class="line"><span class="string">2. **Source of Truth**: All keywords must be explicitly derived from the user query, with both high-level and low-level keyword categories are required to contain content.</span></span><br><span class="line"><span class="string">3. **Concise &amp; Meaningful**: Keywords should be concise words or meaningful phrases. Prioritize multi-word phrases when they represent a single concept. For example, from &quot;latest financial report of Apple Inc.&quot;, you should extract &quot;latest financial report&quot; and &quot;Apple Inc.&quot; rather than &quot;latest&quot;, &quot;financial&quot;, &quot;report&quot;, and &quot;Apple&quot;.</span></span><br><span class="line"><span class="string">4. **Handle Edge Cases**: For queries that are too simple, vague, or nonsensical (e.g., &quot;hello&quot;, &quot;ok&quot;, &quot;asdfghjkl&quot;), you must return a JSON object with empty lists for both keyword types.</span></span><br><span class="line"><span class="string">5. **Language**: All extracted keywords MUST be in &#123;language&#125;. Proper nouns (e.g., personal names, place names, organization names) should be kept in their original language.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---Examples---</span></span><br><span class="line"><span class="string">&#123;examples&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---Real Data---</span></span><br><span class="line"><span class="string">User Query: &#123;query&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---Output---</span></span><br><span class="line"><span class="string">Output:&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>而<code>kg_query</code>中的第二步，则是查询中的核心，主要通过下面四个函数来实现 <code>_perform_kg_search</code>, <code>_apply_token_truncation</code>, <code>_merge_all_chunks</code>, <code>_build_context_str</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">_build_query_context</span>(<span class="params">query, ll_keywords, hl_keywords, ...</span>):</span><br><span class="line">    <span class="comment"># Stage 1: 纯检索</span></span><br><span class="line">    search_result = <span class="keyword">await</span> _perform_kg_search(</span><br><span class="line">        query, ll_keywords, hl_keywords,</span><br><span class="line">        knowledge_graph_inst, entities_vdb, relationships_vdb, </span><br><span class="line">        text_chunks_db, query_param</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 2: Token 截断</span></span><br><span class="line">    truncation_result = <span class="keyword">await</span> _apply_token_truncation(</span><br><span class="line">        search_result, query_param, global_config</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 3: 合并 Chunks</span></span><br><span class="line">    merged_chunks = <span class="keyword">await</span> _merge_all_chunks(</span><br><span class="line">        truncation_result[<span class="string">&quot;filtered_entities&quot;</span>],</span><br><span class="line">        truncation_result[<span class="string">&quot;filtered_relations&quot;</span>],</span><br><span class="line">        search_result[<span class="string">&quot;vector_chunks&quot;</span>],</span><br><span class="line">        query, knowledge_graph_inst, text_chunks_db, query_param</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 4: 构建最终上下文</span></span><br><span class="line">    context, raw_data = <span class="keyword">await</span> _build_context_str(</span><br><span class="line">        truncation_result[<span class="string">&quot;entities_context&quot;</span>],</span><br><span class="line">        truncation_result[<span class="string">&quot;relations_context&quot;</span>],</span><br><span class="line">        merged_chunks, query, query_param, global_config</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> QueryContextResult(context=context, raw_data=raw_data)</span><br></pre></td></tr></table></figure>

<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>其实在实体和关系提取之后，对实体&#x2F;关系进行合并的时候，会有一个总结(summary)的操作，这一步主要是将信息进行整合，以减少token，举个例子如下:  (主要的函数是<code>merge_nodes_and_edges()</code>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同一个实体从不同 chunks 提取到的描述列表</span></span><br><span class="line">description_list = [</span><br><span class="line">    <span class="string">&quot;OpenAI是一家人工智能研究公司&quot;</span>,</span><br><span class="line">    <span class="string">&quot;OpenAI开发了GPT系列模型&quot;</span>, </span><br><span class="line">    <span class="string">&quot;OpenAI成立于2015年&quot;</span>,</span><br><span class="line">    <span class="string">&quot;OpenAI的总部在旧金山&quot;</span>,</span><br><span class="line">    <span class="string">&quot;OpenAI由Sam Altman领导&quot;</span>,</span><br><span class="line">    <span class="comment"># ... 可能有几十个描述</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">第一次 Map：将<span class="number">10</span>个短描述 → <span class="number">3</span>个中描述</span><br><span class="line">第二次 Map：将<span class="number">3</span>个中描述 → <span class="number">1</span>个长描述</span><br><span class="line">最终结果：<span class="string">&quot;OpenAI是2015年成立于旧金山的人工智能研究公司，由Sam Altman领导，开发了GPT系列模型...&quot;</span></span><br></pre></td></tr></table></figure>

<p>合并的策略采取的是 map-reduce, 分而治之的方法, 具体的函数可以看<code>_summarize_descriptions</code></p>
<p><strong>为什么用 Map-Reduce？</strong></p>
<ul>
<li>单次 LLM 调用有 token 限制（<code>summary_context_size</code>）</li>
<li>大量描述无法一次处理完</li>
<li>分而治之：先局部摘要，再全局摘要</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 迭代直到满足条件</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    total_tokens = <span class="built_in">sum</span>(<span class="built_in">len</span>(tokenizer.encode(desc)) <span class="keyword">for</span> desc <span class="keyword">in</span> current_list)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 可以一次处理完？</span></span><br><span class="line">    <span class="keyword">if</span> total_tokens &lt;= summary_context_size:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> _summarize_descriptions(current_list)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 需要分批（Map 阶段）</span></span><br><span class="line">    chunks = split_into_chunks(current_list, summary_context_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 每批生成摘要（Reduce 阶段）</span></span><br><span class="line">    new_summaries = []</span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(chunk) == <span class="number">1</span>:</span><br><span class="line">            new_summaries.append(chunk[<span class="number">0</span>])  <span class="comment"># 优化：单条不调用 LLM</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            summary = <span class="keyword">await</span> _summarize_descriptions(chunk)</span><br><span class="line">            new_summaries.append(summary)</span><br><span class="line">    </span><br><span class="line">    current_list = new_summaries  <span class="comment"># 递归处理</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Rag/">Rag</a></div><div class="post-share"><div class="social-share" data-image="/covers/14.webp" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/12/01/LLM-memory/" title="LLM memory"><img class="cover" src="/covers/15.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LLM memory</div></div><div class="info-2"><div class="info-item-1">LLM memory 综合文档记录</div></div></div></a><a class="pagination-related" href="/2025/11/25/AgentScope%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/" title="AgentScope源码学习"><img class="cover" src="/covers/8.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">AgentScope源码学习</div></div><div class="info-2"><div class="info-item-1">开源项目AgentScope源码学习记录</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/13/GraphRAG/" title="GraphRAG"><img class="cover" src="/covers/11.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-13</div><div class="info-item-2">GraphRAG</div></div><div class="info-2"><div class="info-item-1">学习了解GraphRAG</div></div></div></a><a class="pagination-related" href="/2025/04/21/RAG%E4%BC%98%E5%8C%96/" title="RAG优化"><img class="cover" src="/covers/22.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-21</div><div class="info-item-2">RAG优化</div></div><div class="info-2"><div class="info-item-1">总结了一下当前RAG常见的优化方法</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">why join the navy if you can be a pirate</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%83%8C%E6%99%AF"><span class="toc-text">1. 背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-LightRAG%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-text">2. LightRAG的原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-text">3. 源码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%AE%B5-chunks"><span class="toc-text">分段(chunks)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E4%BD%93-%E5%85%B3%E7%B3%BB%E6%8F%90%E5%8F%96"><span class="toc-text">实体&#x2F;关系提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2"><span class="toc-text">查询</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/03/36-crewai%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/" title="crewai源码学习"><img src="/covers/36.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="crewai源码学习"/></a><div class="content"><a class="title" href="/2026/02/03/36-crewai%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/" title="crewai源码学习">crewai源码学习</a><time datetime="2026-02-03T03:07:51.000Z" title="发表于 2026-02-03 11:07:51">2026-02-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/35-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2/" title="大模型推理部署"><img src="/covers/35.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型推理部署"/></a><div class="content"><a class="title" href="/2026/01/26/35-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2/" title="大模型推理部署">大模型推理部署</a><time datetime="2026-01-26T02:17:21.000Z" title="发表于 2026-01-26 10:17:21">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/34-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-tensorRT/" title="模型推理基本知识-tensorRT"><img src="/covers/34.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="模型推理基本知识-tensorRT"/></a><div class="content"><a class="title" href="/2026/01/26/34-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-tensorRT/" title="模型推理基本知识-tensorRT">模型推理基本知识-tensorRT</a><time datetime="2026-01-26T02:14:09.000Z" title="发表于 2026-01-26 10:14:09">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/33-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-CUDA/" title="模型推理基本知识-CUDA"><img src="/covers/33.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="模型推理基本知识-CUDA"/></a><div class="content"><a class="title" href="/2026/01/26/33-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-CUDA/" title="模型推理基本知识-CUDA">模型推理基本知识-CUDA</a><time datetime="2026-01-26T02:13:33.000Z" title="发表于 2026-01-26 10:13:33">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/32-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-%E9%87%8F%E5%8C%96/" title="模型推理基本知识-量化"><img src="/covers/32.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="模型推理基本知识-量化"/></a><div class="content"><a class="title" href="/2026/01/26/32-%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-%E9%87%8F%E5%8C%96/" title="模型推理基本知识-量化">模型推理基本知识-量化</a><time datetime="2026-01-26T02:06:59.000Z" title="发表于 2026-01-26 10:06:59">2026-01-26</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.2"></script><script src="/js/main.js?v=5.5.2"></script><div class="js-pjax"></div><img src="/img/fengmian.webp" alt="" style="position:absolute;width:0;height:0;opacity:0;pointer-events:none;" loading="eager" fetchpriority="high" onload="this.style.display='none'"></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>