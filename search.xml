<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>AgentScope源码学习</title>
      <link href="/2025/11/25/AgentScope%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
      <url>/2025/11/25/AgentScope%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="AgentScope-阿里的"><a href="#AgentScope-阿里的" class="headerlink" title="AgentScope (阿里的)"></a>AgentScope (阿里的)</h3><blockquote><p><a href="https://github.com/agentscope-ai/agentscope">https://github.com/agentscope-ai/agentscope</a></p></blockquote><h4 id="记忆"><a href="#记忆" class="headerlink" title="记忆"></a>记忆</h4><p>长期记忆部分使用了mem0这个工具，当然，代码里面也提到了，可以使用阿里自家的ReMe这个记忆框架</p><h4 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h4><p>这一块儿使用的是基本的React模式，输出最后的回答，也成了一个工具；多了一个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### AgentBase</span></span><br><span class="line"><span class="comment"># 在AgentBase里面有一个虚函数 reply</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reply</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 在ReactAgentBase里面有基本的React框架</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_reasoning</span>()   <span class="comment"># 虚函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_acting</span>()      <span class="comment"># 虚函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 在ReactAgent里面</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reply</span>():           这里就类似OpenManus里面的step()函数的作用了，从源码来看，逻辑完全一样</span><br><span class="line">    <span class="variable language_">self</span>._reasoning()</span><br><span class="line">    ...</span><br><span class="line">    <span class="variable language_">self</span>._acting()</span><br></pre></td></tr></table></figure><p>在Agent里面有一个observe，感觉是为了观察到外界信息准备的接口(用于多Agent之间的信息互动)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">observe</span>(<span class="params">self, msg: Msg | <span class="built_in">list</span>[Msg] | <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Receive the given message(s) without generating a reply.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        msg (`Msg | list[Msg] | None`):</span></span><br><span class="line"><span class="string">            The message(s) to be observed.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(</span><br><span class="line">        <span class="string">f&quot;The observe function is not implemented in&quot;</span></span><br><span class="line">        <span class="string">f&quot; <span class="subst">&#123;self.__class__.__name__&#125;</span> class.&quot;</span>,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h4 id="多Agent互动"><a href="#多Agent互动" class="headerlink" title="多Agent互动"></a>多Agent互动</h4><p>在这个框架里面使用的是swarm模式，似乎比较简单，每个agent observe其它agent的输出，添加到自己的记忆里面去就好了</p><p>在src&#x2F;pipeline&#x2F;_msghub.py文件夹里面 （或者见类名时的说明）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">broadcast</span>(<span class="params">self, msg: <span class="built_in">list</span>[Msg] | Msg</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Broadcast the message to all participants.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        msg (`list[Msg] | Msg`):</span></span><br><span class="line"><span class="string">            Message(s) to be broadcast among all participants.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> agent <span class="keyword">in</span> <span class="variable language_">self</span>.participants:</span><br><span class="line">        <span class="keyword">await</span> agent.observe(msg)</span><br></pre></td></tr></table></figure><h4 id="Interrupt-中断介入"><a href="#Interrupt-中断介入" class="headerlink" title="Interrupt(中断介入)"></a>Interrupt(中断介入)</h4><p>这个好像还不错，可以看一下</p><h4 id="Plan的实现"><a href="#Plan的实现" class="headerlink" title="Plan的实现"></a>Plan的实现</h4><p>实现了一些plan的功能函数，然后让Agent去调用和更改当前的plan</p><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20251119115208155.png" alt="image-20251119115208155"></p>]]></content>
      
      
      <categories>
          
          <category> Agent开源项目学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Agent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>smolagents源码学习</title>
      <link href="/2025/11/25/smolagents%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
      <url>/2025/11/25/smolagents%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/huggingface/smolagents">https://github.com/huggingface/smolagents</a></p></blockquote><h4 id="memory-管理"><a href="#memory-管理" class="headerlink" title="memory 管理"></a>memory 管理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AgentMemory</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, system_prompt:<span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.system_prompt: SystemPromptStep = SystemPromptStep(system_prompt=system_prompt)</span><br><span class="line">        <span class="variable language_">self</span>.steps: <span class="built_in">list</span>[TaskStep | ActionStep | PlanningStep] = []</span><br></pre></td></tr></table></figure><p>将LLM执行过程的信息划分成了四个部分(主要，其它)：</p><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250926172929838.png" alt="image-20250926172929838"></p><ul><li>TaskStep: 与用户输入相关 (用户提问，上传图片等)</li><li>SystemPromptStep: 系统的prompt</li><li>PlanningStep: 与规划相关的记忆 (<strong>暂时还没遇到</strong>)</li><li>ActionStep：当前送到LLM进行执行的信息</li></ul><p><strong>历史信息的获取</strong></p><p>所以主要在于上面每种类型记忆数据 <code>to_messages</code>的实现 需要注意的是前后信息的完整性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># agents.py line:1256</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_step_stream</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, memory_step: ActionStep</span></span><br><span class="line"><span class="params">    </span>) -&gt; Generator[ChatMessageStreamDelta | ToolCall | ToolOutput | ActionOutput]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Perform one step in the ReAct framework: the agent thinks, acts, and observes the result.</span></span><br><span class="line"><span class="string">    Yields ChatMessageStreamDelta during the run if streaming is enabled.</span></span><br><span class="line"><span class="string">    At the end, yields either None if the step is not final, or the final answer.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    memory_messages = <span class="variable language_">self</span>.write_memory_to_messages()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># agents.py line:758</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_memory_to_messages</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        summary_mode: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">list</span>[ChatMessage]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Reads past llm_outputs, actions, and observations or errors from the memory into a series of messages   that can be used as input to the LLM. Adds a number of keywords (such as PLAN, error, etc) to help  the LLM.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    messages = <span class="variable language_">self</span>.memory.system_prompt.to_messages(summary_mode=summary_mode)</span><br><span class="line">    <span class="keyword">for</span> memory_step <span class="keyword">in</span> <span class="variable language_">self</span>.memory.steps:</span><br><span class="line">        messages.extend(memory_step.to_messages(summary_mode=summary_mode))</span><br><span class="line">    <span class="keyword">return</span> messages</span><br></pre></td></tr></table></figure><h4 id="边界处理"><a href="#边界处理" class="headerlink" title="边界处理"></a>边界处理</h4><p>当超过最大尝试次数（默认是20次）时，最后会总结19步的step，然后给出一个最终答案</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># agent.py  line:810</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">provide_final_answer</span>(<span class="params">self, task: <span class="built_in">str</span></span>) -&gt; ChatMessage:</span><br><span class="line">    </span><br><span class="line">    messages : 这里有一个专门针对这种情况的系统prompt</span><br><span class="line">    messages += <span class="variable language_">self</span>.write_memory_to_messages()[<span class="number">1</span>:]</span><br><span class="line">    messages : 需要组装的post_messages</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        chat_message: ChatMessage = <span class="variable language_">self</span>.model.generate(messages)</span><br><span class="line">        <span class="keyword">return</span> chat_message</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> ChatMessage(</span><br><span class="line">            role=MessageRole.ASSISTANT,</span><br><span class="line">            content=[&#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">f&quot;Error in generating final LLM output: <span class="subst">&#123;e&#125;</span>&quot;</span>&#125;],</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><h4 id="Agent-CodeAgent"><a href="#Agent-CodeAgent" class="headerlink" title="Agent: CodeAgent"></a>Agent: CodeAgent</h4><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250929112702011.png" alt="image-20250929112702011"></p><p>项目的CodeAgent模式算是这个项目里面比较新颖的一种方式了，调用工具的API是通过执行python代码的方式来执行的，但是感觉解析python的AST那部分，就感觉好复杂-_-#，没有FunctionCall的这种方式简洁了。</p><p>来源于<a href="https://link.zhihu.com/?target=https://huggingface.co/papers/2402.01030">Executable Code Actions Elicit Better LLM Agents</a>，这篇论文主要的出发动机是当前LLM Agent通常通过以预定义的格式生成 JSON 或文本来生成Action，这通常受到<strong>约束动作空间（例如，预定义工具的范围）和受限灵活性（例如，无法组合多个工具）的限制</strong>。</p><blockquote><p>链接：<a href="https://zhuanlan.zhihu.com/p/16341067315">https://zhuanlan.zhihu.com/p/16341067315</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Agent开源项目学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Agent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/11/25/hello-world/"/>
      <url>/2025/11/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>MCP</title>
      <link href="/2025/11/25/mcp%E4%BB%8B%E7%BB%8D/"/>
      <url>/2025/11/25/mcp%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="MCP"><a href="#MCP" class="headerlink" title="MCP"></a>MCP</h2><p>话不多说，直接上图即可</p><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250821171413971.png" alt="image-20250821171413971"></p><p>有MCP和没有MCP的区别，提升了效率</p><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250821171443789.png" alt="image-20250821171443789"></p><p>MCP的架构图：主要是由Host、Client和Server三部分组成</p><p><img src="https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250821171800487.png" alt="image-20250821171800487"></p><h2 id="个人demo"><a href="#个人demo" class="headerlink" title="个人demo"></a>个人demo</h2><blockquote><p><a href="https://github.com/flippy-bird/agent/tree/main/examples/mcp_demo">mcp demo</a></p></blockquote><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://zhuanlan.zhihu.com/p/29001189476">MCP (Model Context Protocol)，一篇就够了。</a></li><li><a href="https://github.com/modelcontextprotocol/python-sdk">python SDK的官方文档</a></li><li></li><li>测试MCP工具接入使用的地址：<a href="https://bailian.console.aliyun.com/?utm_content=se_1021227952&gclid=EAIaIQobChMI28G-yLObjwMV3JC5BR0zMijXEAAYASAAEgKc4_D_BwE&tab=mcp#/mcp-market">阿里MCP</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Agent </tag>
            
            <tag> MCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型入门(组内分享)</title>
      <link href="/2025/06/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-%E7%BB%84%E5%86%85%E5%88%86%E4%BA%AB/"/>
      <url>/2025/06/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-%E7%BB%84%E5%86%85%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><pre><code> 2025年开年以来，大家或多或少都听过下面这些词：deepseek， AI， 人工智能，Agent，具身智能；</code></pre><p>AI到底发展到哪一步了，利用AI可以做哪些事情，或者作为技术人员，想要使用AI做一些事情，应该学习那些东西，这篇将和大家一起探讨下。</p><p>备注声明：<strong>该分享定位轻科普向</strong>，不会涉及大模型相关的底层原理，有些结论属于个人的理解和感悟，如需要深入交流，欢迎大家和我深入探讨。</p><h2 id="大模型相关应用"><a href="#大模型相关应用" class="headerlink" title="大模型相关应用"></a>大模型相关应用</h2><h3 id="Prompt-Engineer-提示词"><a href="#Prompt-Engineer-提示词" class="headerlink" title="Prompt Engineer(提示词)"></a><strong>Prompt Engineer(提示词)</strong></h3><p><strong>Prompt 咒语 —-&gt; 激发LLM的潜能</strong></p><p>2023年的某一天，当你开始和ChatGpt互动的那一刻开始，你就是一个Prompt Engineer了！  </p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=MGIxMzNhZDIyMWY5OWM5ZDExMzA2ZDZmODE2Nzg4YWVfTkk2b1pXcDBCbVdCbUdXa2ZzMDl6T0psM09oa0dIaTFfVG9rZW46RmJiTmIyVjl2b3Nnbmh4SUdpYmNZbjVXblRmXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>当你不断试探GPT，使用各种策略，反问，试探，举个例子等等(专业一点就是few shot, zero-shot, cot等等)，最终得到正确答案时，你其实已经获得了一些prompt Engineer的训练，在下一次的问答中，你就能更快更好地得到你想要的答案；</p><p>当然啦，现在大模型也挺多的，确实有一些朴素的咒语框架可以让我们快速得到更好了的回答，你如果想了解一下，可以看看下面这个课程</p><p><a href="https://www.bilibili.com/video/BV1b4A6etEJu/?spm_id_from=333.337.search-card.all.click&vd_source=d46df11a3bf332ea68a6f3b7af79095d">(超爽中英!) 2025吴恩达最好的【提示词工程师】教程！附课件代码 DeepLearning.AI_大模型_LLM_Prompt_哔哩哔哩_bilibili</a></p><p>当然，上面说的咒语是GPT对话形式的，文生图，文生视频等等AIGC的应用，咒语可能需要另外习得(你芝麻开门可以开这个门，另外一个门可就不行了哦)</p><h3 id="SFT-微调"><a href="#SFT-微调" class="headerlink" title="SFT(微调)"></a>SFT(微调)</h3><ul><li>大模型训练的时候使用的是公开的数据集，prompt咒语念得再好，也没办法，巧妇难为无米之炊，对于特定领域的问题大模型会出现幻觉(瞎回答)</li><li>大模型的效果出现一些问题，需要纠正大模型的错误</li></ul><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDc4ODQ0YzNlZDNlMTJkYmY3MmUzM2U0OTI3MzA2OGZfdzVnUFRKeW5sdHZDRG9OZkJONlFiUWJIM2RTYXp6QjBfVG9rZW46QkJiVWJTYlhpb0RZZDF4MzRWdWNsNDd4bkx1XzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><ul><li>改变大模型回答的风格等等需要定制，就需要大模型微调</li></ul><p>如果大家想要进阶动手微调一下的话，可以使用下面的框架，按照格式准备好数据即可，然后一键启动，上机器开始炼丹即可！</p><p>目前主流的微调框架：</p><ol><li><a href="https://github.com/hiyouga/LLaMA-Factory">https://github.com/hiyouga/LLaMA-Factory</a></li><li><a href="https://github.com/unslothai/unsloth">https://github.com/unslothai/unsloth</a></li><li><a href="https://github.com/modelscope/ms-swift">https://github.com/modelscope/ms-swift</a></li></ol><h3 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a><strong>RAG</strong></h3><p><strong>RAG &#x3D; LLM + 外置数据库</strong></p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=NmJhOWRlYmQ0OTNiMzMzOGY2YjdlYjE0ZTM1ODY3NDBfcVFTWERpODZRZzBxWmRaTU1xdDJwaHIweE9kVFNwZXNfVG9rZW46UzI1TGJlMDJPb1Y5bHh4M1JFSmNHNll1bldkXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=NTMxZjhmYmRlZDYzOWMwYTcxNDhlZDhjYjM3ODllNzdfdVZyWmkwU1hDeXBUZGl5U051UlZyZmZjQXJJaDZ3c25fVG9rZW46QlBEUmJTbFFNbzdqVnZ4Sm1WaGNhYzZRbjZlXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>​                                                                   <strong>备注：这部分写于2025年4月16日</strong></p><p>用过GPT的同学可能会了解到，GPT的知识具有时效性，比如GPT-4发布时间在2023年，那么GPT-4绝对无法帮你回答2024年之后的事情；再者，你有一个本地知识库的时候，你需要大模型结合这个知识库来回答你的问题时，你可能就需要RAG了；</p><p>右边严格来说不是RAG的流程，但是广义来讲，也算RAG，llm在其中扮演的是嘴替(总结)的作用；左边这个图是标准的RAG的流程，主要包括两个部分：index(入库) 和 query(出库)</p><p>如果大家想要深入学习这一部分的话，下面是一些可以进阶的部分：</p><p>当前两个主流的RAG搭建框架(RAG企业级开发)：</p><p>langchain：<a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></p><p>llamaindex：<a href="https://github.com/run-llama/llama_index">https://github.com/run-llama/llama_index</a></p><p>可以学习的开源项目：</p><p>QAnything: <a href="https://github.com/netease-youdao/QAnything">https://github.com/netease-youdao/QAnything</a></p><p>RAGflow：<a href="https://github.com/infiniflow/ragflow/blob/main/README_zh.md">https://github.com/infiniflow/ragflow/blob/main/README_zh.md</a></p><p>关于RAG的优化：<a href="https://quvideo.feishu.cn/docx/EbMAde0dcoBe6ZxjbRecgaQ3ngg">RAG技术</a></p><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p><strong>Agent &#x3D; LLM + 外部工具</strong></p><p>上面的RAG是LLM和外部的知识(文档，图片等)打通了一条链路，相当于在数据层面建立了联系；但是不具备数据处理的能力，而处理数据的能力，一般是API是通过API的形式来展现的；**因此当LLM能够使用外部的 工具(API), LLM的能力将得到极大的扩展 ，**不多bb，展示！！！</p><blockquote><p><a href="https://strudel.cc/">https://strudel.cc/</a>  (下面Agent使用到的一个音乐工具)</p></blockquote><p>如果没有耐心看完前面Agent执行步骤的话，可直接拉到2：48秒，然后看后面的即可</p><p><video data-lark-video-uri="drivetoken://KSrPbAyRYo98nmx2MYucxGg9nbb" data-lark-video-mime="video/mp4" data-lark-video-size="15891280" data-lark-video-duration="0" data-lark-video-name="test.mp4" data-lark-video-width="1920" data-lark-video-height="1080"></video></p><p>如果给了LLM一台可以运行的电脑(环境)，那么这就是今年3月份爆火的AI智能体 <a href="https://manus.im/">Manus</a></p><p>为什么要叫Agent呢，可以看下面的图(没找到比较好的图，自己画的，见谅)，我们可以将用户比作boss，llm比作员工，boss发出一个问题之后，llm去规划并完成工作，llm是具体的执行者，因此叫做代理,Agent</p><p>暂时无法在飞书文档外展示此内容</p><p>目前智能Agent产品设计一般都是按照上面的思路去进行的，规划(Plan) + 执行(ReAct模型)</p><h2 id="Agent-1"><a href="#Agent-1" class="headerlink" title="Agent"></a>Agent</h2><p>通过上面的章节，对Agent进行了一些初步的了解，这个小节将通过代码进一步的带大家了解Agent相关的内容</p><h3 id="Agent-2"><a href="#Agent-2" class="headerlink" title="Agent"></a>Agent</h3><blockquote><p><a href="https://www.bilibili.com/video/BV1FCR3Y1EnJ/?spm_id_from=333.337.search-card.all.click">李宏毅讲Agent</a></p></blockquote><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=YzRmNmM1Y2M0YTJmY2VmMDQ5N2Y4YjBiZGE4MDdkZDZfUzZnOHN3VzFCajRmd2tLajZyTXFvSkNWNEpaRFVYMFRfVG9rZW46TTc2NmJzQmVMb3dyamx4NEhQN2NSVFA3bkFjXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>从上面的一些例子我们可以了解到，对于完成一个人类目标而言，Agent需要两个方面的能力，目标拆解的能力和分布执行的能力；对应的名词即plan和function call，有了分步的任务，之后，LLM Agent逐步分析，调用工具或者自身内部知识，然后将结果传给下一步的任务，如下图所示：</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=NTkyZTU0OTZkMDg5YmUyMmVjZWFmNjkxZWU1OGJmMTBfaW1CUU1iNDBWUUZlU0pITXhUY1pLZWMwMmNrZ25ZTmhfVG9rZW46RWpVRmI3cENEb2cyUnd4NlhKMmNuT0FFbmNlXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>通过上面的方式，可以有哪些运用呢？</p><ol><li>用模型训练模型：</li></ol><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=YjNiZDAwMmI5NDQ5ODFkZGNjMWQxMGRhZTA5MTU3NzJfallCNmE0MldDMnp2aWVEbFJHVFZyVEtNU00zbnBrZDVfVG9rZW46T1ZqbGJZYTFzb3lPRGJ4NUxFb2NJSzAxblJoXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><ol><li>使用Agent下围棋，使用电脑，浏览网页等等！</li></ol><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=ZWMzOTA3ZTQ3NTkzN2IyNTg4Y2E3Y2Q2MzAxZWQwMzFfRENLbXpqRHRBTmVTWlBBaGNYZDNlaWtpcUptcjk4bUhfVG9rZW46TWJDVWJoTUk0b2puY0J4MXl2eWNxTk9IbmZkXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>当然上面的例子也说明了，大模型在调用过程中，可能出现幻觉，这有可能导致任务执行的失败，比如上面的deepseek 改变了国际象棋的规则，然后赢得了AI届的国际象棋桂冠！因此对于复杂问题，选择其它方法或许更可靠。这里不再展开。</p><p>上面都提到了大模型要实现Agent，需要具备工具调用的能力，这个能力是怎么实现的呢？看图好像挺简单的一句话就说完了，其实实际呢，也挺简单的。下面通过一个Function Call的例子来简单说明一下。</p><h3 id="Function-call"><a href="#Function-call" class="headerlink" title="Function call"></a>Function call</h3><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=MzRkNWVhM2VlY2ViZTM2OThjMzMxOTYwNzdkYzA5MDdfbjNEVlpFZXc3M0pFbnJReFIyZXNmUDNzajdFa1BMVU1fVG9rZW46WjJrZmI1UVpqb0NJQmN4c05rSGN6MjFJbjhjXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>调用的实例代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 1: 定义工具</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>():</span><br><span class="line">    current_datetime = datetime.now()</span><br><span class="line">    formatted_time = current_datetime.strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;当前时间：<span class="subst">&#123;formatted_time&#125;</span>。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">arguments</span>):</span><br><span class="line">    a = arguments[<span class="string">&quot;num_1&quot;</span>]</span><br><span class="line">    b = arguments[<span class="string">&quot;num_2&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;计算的结果是：<span class="subst">&#123;a + b&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2: 创建tools数组</span></span><br><span class="line">tools = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_current_time&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;当你想知道现在的时间时非常有用。&quot;</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tool_name = [tool[<span class="string">&quot;function&quot;</span>][<span class="string">&quot;name&quot;</span>] <span class="keyword">for</span> tool <span class="keyword">in</span> tools]</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3：使用大模型调用函数</span></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;sk-389c222d8f304e6ba3bb10ad3589d340&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&quot;&quot;你是一个很有帮助的助手。如果用户提问关于时间的问题，请调用‘get_current_time’函数。</span></span><br><span class="line"><span class="string">     请以友好的语气回答问题。&quot;&quot;&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;现在是几点？&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">function_calling</span>():</span><br><span class="line">    completion = client.chat.completions.create(</span><br><span class="line">        model=<span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">        messages=messages,</span><br><span class="line">        tools=tools,</span><br><span class="line">    )</span><br><span class="line">    res = completion.choices[<span class="number">0</span>].message</span><br><span class="line">    <span class="built_in">print</span>(res.model_dump_json())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> completion</span><br><span class="line"></span><br><span class="line"><span class="comment"># step4: 运行工具函数</span></span><br><span class="line">completion = function_calling()</span><br><span class="line">function_name = completion.choices[<span class="number">0</span>].message.tool_calls[<span class="number">0</span>].function.name</span><br><span class="line">arguments_string = completion.choices[<span class="number">0</span>].message.tool_calls[<span class="number">0</span>].function.arguments</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用json模块解析参数字符串</span></span><br><span class="line">arguments = json.loads(arguments_string)</span><br><span class="line"><span class="comment"># 创建一个函数映射表</span></span><br><span class="line">function_mapper = &#123;</span><br><span class="line">    <span class="string">&quot;get_current_time&quot;</span>: get_current_time,</span><br><span class="line">    <span class="string">&quot;add&quot;</span>:add</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 获取函数实体</span></span><br><span class="line">function = function_mapper[function_name]</span><br><span class="line"><span class="comment"># 如果入参为空，则直接调用函数</span></span><br><span class="line"><span class="keyword">if</span> arguments == &#123;&#125;:</span><br><span class="line">    function_output = function()</span><br><span class="line"><span class="comment"># 否则，传入参数后调用函数</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    function_output = function(arguments)</span><br><span class="line"><span class="comment"># 打印工具的输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;工具函数输出：<span class="subst">&#123;function_output&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## step5： 将工具输出添加到messages中，继续进行下面的步骤</span></span><br><span class="line">messages.append(completion.choices[<span class="number">0</span>].message)</span><br><span class="line">messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>, <span class="string">&quot;content&quot;</span>: function_output, <span class="string">&quot;tool_call_id&quot;</span>: completion.choices[<span class="number">0</span>].message.tool_calls[<span class="number">0</span>].<span class="built_in">id</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;已添加tool message\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">completion = function_calling()</span><br></pre></td></tr></table></figure><h3 id="WorkFlow-编排的Agent"><a href="#WorkFlow-编排的Agent" class="headerlink" title="WorkFlow - 编排的Agent"></a>WorkFlow - 编排的Agent</h3><p>上面提到，对于复杂任务，完全让大模型去规划，去自由探索，可能出现很多不可预知的问题，这对于一些确定性的任务来说，是很致命的，既然这样，那么就别让大模型逞能，脚踏实地，只解决具体的单步问题，规划问题让人类来干就好了，这就是workflow，这就是截止到2025年4月20日来最主流的Agent 实现方式；</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=MTI4YjNlMzcwOThjOWMyNmUyNDZkYWFmNzU2M2U4ZDRfNGZWR3ZLY3JtRmNFWXpxOFV0VU5DSGZ5a3RPdFBZUGJfVG9rZW46WmhBamJVQmhYb2FPd2Z4eHVjTGNYdlpObkFjXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><h3 id="MCP"><a href="#MCP" class="headerlink" title="MCP"></a>MCP</h3><p>上面是通义千问的Function 调用方式，下次我们再添加一个新的工具的时候，是不是又要重复写一下这个流程(定义工具，定义工具描述，然后传给大模型)， 但是现在大模型这么多，大模型之间的Function Call的方式可能不相同，这里写的工具函数，换到GPT4，可能就要修改代码，这样很不符合程序员的复用规则，因此有了MCP</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=NTQxMDM4YjJhMDMyNGE4Yzg5YTYwY2IxMTc3NjlmMmRfdnhxMUJtNGhKMTBQTVJqQzdTUE1xc2lxeFM4Rk5aVmVfVG9rZW46WmNQS2JxR05Jb3FuTkR4UFgzamNpMGx0bmRjXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=YTZkMmJkMWU3N2NlMTc1NWNiYjEzMDFiNjUwZGNjMjNfRkNxVGc4U0U1a3UySGN2SjVBaTA2Q3RXMGx4QTBGanNfVG9rZW46VWZ5VmJvOU1Rb2lsN3d4SWFwYWNjM29UbmxiXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>MCP其实还是大模型选择需要调用的工具，<strong>因此MCP本质还是Function Call，</strong> 只是统一了一个标准之后，开发者通过MCP协议写的Function可以给别人复用了</p><p>如果想深入了解的话，大家可以对照着<a href="https://github.com/modelcontextprotocol">官方代码</a>写一遍，就会发现了MCP解决的是哪一方面的问题了；</p><h3 id="A2A，ANP等等"><a href="#A2A，ANP等等" class="headerlink" title="A2A，ANP等等"></a>A2A，ANP等等</h3><p><a href="https://github.com/google/A2A">A2A</a>：谷歌提出来的一种 Agent 和 Agent相互通信的协议， MCP协议统一了大模型与外界工具交互的方式，A2A是Agent与Agent间的，可以类比成公司里面部门，每个部门承担一部功能(如前端，后端，数据，算法，HR，财务，运维等)，然后相互协作，共同达成一个目标；</p><p><a href="https://github.com/agent-network-protocol/AgentNetworkProtocol">ANP</a>：国内提出的类似于A2A的，用于Agent2Agent的协议，目前是成为互联网界的http</p><p>. . . . .</p><p>无论是MCP，还是A2A，抑或者是其它协议，我觉得归根到底是今年自deepseek以来，**大模型的能力得到了较大的提升，**这个生态才慢慢火起来(2024年开年火了一阵就没声音了，因为Agent有点人工智障的味道)，至于Agent有多智能，我觉得还是让子弹飞一会儿，但是在小的方面，确实会影响我们的工作效率；恰当的使用llm来协助我们工作，能做到事半功倍；</p><h3 id="好物推荐"><a href="#好物推荐" class="headerlink" title="好物推荐"></a>好物推荐</h3><p>编程工具类：</p><ol><li><a href="https://www.cursor.com/">Cursor</a>  (目前最好的AI代码编辑器，就是有点小贵，我使用的是VScode通义灵码插件替代)</li><li><a href="https://www.cursor.com/">Trae</a> (字节出品， 国产第一个有知名度的AI代码编辑器(当然，投流，广告投入很大))</li></ol><p>开发框架类:（还是上面那两个）</p><p>langchain：<a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></p><p>llamaindex：<a href="https://github.com/run-llama/llama_index">https://github.com/run-llama/llama_index</a>  (个人常用这个，教程很友好， 但是目前langchain发展更好一些)</p><p>零代码类大模型编排工具(适合AI行业的所有人)</p><p>搞过comfyUI的同学应该知道节点编辑工具的概念，这个就是llm这边的节点编辑工具</p><ol><li><a href="https://github.com/langgenius/dify">dify</a> : 企业级的，目前大多数工具开发AI流程应用的首选</li><li><a href="https://github.com/n8n-io/n8n">n8n</a> ：同上，优势在集成了很多的工具</li><li><a href="https://www.coze.cn/home">扣子</a> ： 字节出品，和dify类似</li></ol><p>举个dify的例子：</p><p>本来想演示一个使用dify搭建小影知识库问答系统的demo，但是貌似飞书文档权限比较严格&#x3D;_&#x3D;#，因此这里简单介绍一下；</p><p>以翻译的任务举个例子(目前主流翻译的流程)：通过搭积木的方式，20分钟(2分钟搭建，18分钟的提示词) 即可快速完成一个任务的搭建</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=OWNhMzIxZWJhNjYwYjM4ZWQ1YmZmNmYzNjM2NThhZDJfS0Q0YU4zSUN3ZDBVdEloVVNsOE9ES2JUaVNGNEVRcmhfVG9rZW46SkplQmJzak5jb1RYcmF4eVdYZWNoU09Bbm1IXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p>另外，比较喜欢的一个功能是不同模型的对比，我觉得在验证阶段很实用</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=YWMzMzFjYTI0YjY3ZWJlYzRiMWZjNjE1NTk3M2M4OGJfR2xyb2lKQlpnR2xTN29vZ3dPZFJoTFVoT0xtcHdBUWpfVG9rZW46STRGWmJKaHFTb0VXaDR4NzQ1WmMweDY1bmFkXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><h2 id="现场演示"><a href="#现场演示" class="headerlink" title="现场演示"></a>现场演示</h2><h3 id="Agent-3"><a href="#Agent-3" class="headerlink" title="Agent"></a>Agent</h3><p>cline + MCP</p><p>MCP发展得如火如荼，开源社区上也有很多好玩的MCP工具了，大家可以尝试一下</p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=MzkzYTY3MTQwYTdjYWU5NWY2YTViNGZmOWQ5ZGE5NThfSk9DTlU1b2JYNUxBUDJ1V3VEZjRSNVJ6N25PMmhtR0lfVG9rZW46R0VadWI0SmI5b2E0aHZ4MlFQeWNoNGc1bmVnXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><p><strong>想一想：大家现在看到这个热点，大家觉得是通过什么实现的？</strong></p><p><img src="https://quvideo.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTkxODQxZjhjOTEzNDgzNzU3MTgzNjk0YzFjZTc5OTZfWVhIa3Q1ZTgxTzJkRk9sM09pczB5cFY3Y2x3UUlaOXVfVG9rZW46TmJKeWJvWHU0b2RkSFh4V21KZmNha0ZHbkRjXzE3NjQxNjE5NjQ6MTc2NDE2NTU2NF9WNA" alt="img"></p><h3 id="dify"><a href="#dify" class="headerlink" title="dify"></a>dify</h3><h3 id="ima-好用的结合RAG的文档工具"><a href="#ima-好用的结合RAG的文档工具" class="headerlink" title="ima (好用的结合RAG的文档工具)"></a>ima (好用的结合RAG的文档工具)</h3>]]></content>
      
      
      
        <tags>
            
            <tag> Agent </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
