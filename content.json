{"meta":{"title":"大潘子的文字角落","subtitle":"","description":"","author":"Pan","url":"https://flippy-bird.github.io","root":"/"},"pages":[{"title":"categories","date":"2025-11-26T05:54:56.000Z","updated":"2025-11-26T05:55:08.826Z","comments":true,"path":"categories/index.html","permalink":"https://flippy-bird.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-11-26T05:53:10.000Z","updated":"2025-11-26T12:54:36.650Z","comments":true,"path":"tags/index.html","permalink":"https://flippy-bird.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"AgentScope源码学习","slug":"AgentScope源码学习","date":"2025-11-25T11:47:53.000Z","updated":"2025-11-26T10:30:30.554Z","comments":true,"path":"2025/11/25/AgentScope源码学习/","permalink":"https://flippy-bird.github.io/2025/11/25/AgentScope%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"AgentScope (阿里的) https://github.com/agentscope-ai/agentscope 记忆长期记忆部分使用了mem0这个工具，当然，代码里面也提到了，可以使用阿里自家的ReMe这个记忆框架 Agent这一块儿使用的是基本的React模式，输出最后的回答，也成了一个工具；多了一个 1234567891011121314### AgentBase# 在AgentBase里面有一个虚函数 replydef reply()### 在ReactAgentBase里面有基本的React框架def _reasoning() # 虚函数def _acting() # 虚函数### 在ReactAgent里面def reply(): 这里就类似OpenManus里面的step()函数的作用了，从源码来看，逻辑完全一样 self._reasoning() ... self._acting() 在Agent里面有一个observe，感觉是为了观察到外界信息准备的接口(用于多Agent之间的信息互动) 1234567891011async def observe(self, msg: Msg | list[Msg] | None) -&gt; None: &quot;&quot;&quot;Receive the given message(s) without generating a reply. Args: msg (`Msg | list[Msg] | None`): The message(s) to be observed. &quot;&quot;&quot; raise NotImplementedError( f&quot;The observe function is not implemented in&quot; f&quot; &#123;self.__class__.__name__&#125; class.&quot;, ) 多Agent互动在这个框架里面使用的是swarm模式，似乎比较简单，每个agent observe其它agent的输出，添加到自己的记忆里面去就好了 在src&#x2F;pipeline&#x2F;_msghub.py文件夹里面 （或者见类名时的说明） 123456789async def broadcast(self, msg: list[Msg] | Msg) -&gt; None: &quot;&quot;&quot;Broadcast the message to all participants. Args: msg (`list[Msg] | Msg`): Message(s) to be broadcast among all participants. &quot;&quot;&quot; for agent in self.participants: await agent.observe(msg) Interrupt(中断介入)这个好像还不错，可以看一下 Plan的实现实现了一些plan的功能函数，然后让Agent去调用和更改当前的plan","categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"smolagents源码学习","slug":"smolagents源码学习","date":"2025-11-25T08:43:25.000Z","updated":"2025-11-26T12:53:27.394Z","comments":true,"path":"2025/11/25/smolagents源码学习/","permalink":"https://flippy-bird.github.io/2025/11/25/smolagents%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"https://github.com/huggingface/smolagents memory 管理1234class AgentMemory: def __init__(self, system_prompt:str): self.system_prompt: SystemPromptStep = SystemPromptStep(system_prompt=system_prompt) self.steps: list[TaskStep | ActionStep | PlanningStep] = [] 将LLM执行过程的信息划分成了四个部分(主要，其它)： TaskStep: 与用户输入相关 (用户提问，上传图片等) SystemPromptStep: 系统的prompt PlanningStep: 与规划相关的记忆 (暂时还没遇到) ActionStep：当前送到LLM进行执行的信息 历史信息的获取 所以主要在于上面每种类型记忆数据 to_messages的实现 需要注意的是前后信息的完整性 1234567891011121314151617181920212223# agents.py line:1256def _step_stream( self, memory_step: ActionStep ) -&gt; Generator[ChatMessageStreamDelta | ToolCall | ToolOutput | ActionOutput]: &quot;&quot;&quot; Perform one step in the ReAct framework: the agent thinks, acts, and observes the result. Yields ChatMessageStreamDelta during the run if streaming is enabled. At the end, yields either None if the step is not final, or the final answer. &quot;&quot;&quot; memory_messages = self.write_memory_to_messages() # agents.py line:758def write_memory_to_messages( self, summary_mode: bool = False, ) -&gt; list[ChatMessage]: &quot;&quot;&quot; Reads past llm_outputs, actions, and observations or errors from the memory into a series of messages that can be used as input to the LLM. Adds a number of keywords (such as PLAN, error, etc) to help the LLM. &quot;&quot;&quot; messages = self.memory.system_prompt.to_messages(summary_mode=summary_mode) for memory_step in self.memory.steps: messages.extend(memory_step.to_messages(summary_mode=summary_mode)) return messages 边界处理当超过最大尝试次数（默认是20次）时，最后会总结19步的step，然后给出一个最终答案 12345678910111213141516# agent.py line:810def provide_final_answer(self, task: str) -&gt; ChatMessage: messages : 这里有一个专门针对这种情况的系统prompt messages += self.write_memory_to_messages()[1:] messages : 需要组装的post_messages try: chat_message: ChatMessage = self.model.generate(messages) return chat_message except Exception as e: return ChatMessage( role=MessageRole.ASSISTANT, content=[&#123;&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: f&quot;Error in generating final LLM output: &#123;e&#125;&quot;&#125;], ) Agent: CodeAgent 项目的CodeAgent模式算是这个项目里面比较新颖的一种方式了，调用工具的API是通过执行python代码的方式来执行的，但是感觉解析python的AST那部分，就感觉好复杂-_-#，没有FunctionCall的这种方式简洁了。 来源于Executable Code Actions Elicit Better LLM Agents，这篇论文主要的出发动机是当前LLM Agent通常通过以预定义的格式生成 JSON 或文本来生成Action，这通常受到约束动作空间（例如，预定义工具的范围）和受限灵活性（例如，无法组合多个工具）的限制。 链接：https://zhuanlan.zhihu.com/p/16341067315","categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"Hello World","slug":"hello-world","date":"2025-11-25T07:59:06.847Z","updated":"2025-11-26T10:30:27.200Z","comments":true,"path":"2025/11/25/hello-world/","permalink":"https://flippy-bird.github.io/2025/11/25/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"MCP","slug":"mcp介绍","date":"2025-11-25T06:02:24.000Z","updated":"2025-11-25T08:40:56.342Z","comments":true,"path":"2025/11/25/mcp介绍/","permalink":"https://flippy-bird.github.io/2025/11/25/mcp%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"MCP话不多说，直接上图即可 有MCP和没有MCP的区别，提升了效率 MCP的架构图：主要是由Host、Client和Server三部分组成 个人demo mcp demo 参考资料 MCP (Model Context Protocol)，一篇就够了。 python SDK的官方文档 测试MCP工具接入使用的地址：阿里MCP","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"MCP","slug":"MCP","permalink":"https://flippy-bird.github.io/tags/MCP/"}]},{"title":"大模型入门(组内分享)","slug":"大模型入门-组内分享","date":"2025-06-24T13:01:18.000Z","updated":"2025-11-26T13:42:41.487Z","comments":true,"path":"2025/06/24/大模型入门-组内分享/","permalink":"https://flippy-bird.github.io/2025/06/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-%E7%BB%84%E5%86%85%E5%88%86%E4%BA%AB/","excerpt":"","text":"背景 2025年开年以来，大家或多或少都听过下面这些词：deepseek， AI， 人工智能，Agent，具身智能； AI到底发展到哪一步了，利用AI可以做哪些事情，或者作为技术人员，想要使用AI做一些事情，应该学习那些东西，这篇将和大家一起探讨下。 备注声明：该分享定位轻科普向，不会涉及大模型相关的底层原理，有些结论属于个人的理解和感悟，如需要深入交流，欢迎大家和我深入探讨。 大模型相关应用Prompt Engineer(提示词)Prompt 咒语 —-&gt; 激发LLM的潜能 2023年的某一天，当你开始和ChatGpt互动的那一刻开始，你就是一个Prompt Engineer了！ 当你不断试探GPT，使用各种策略，反问，试探，举个例子等等(专业一点就是few shot, zero-shot, cot等等)，最终得到正确答案时，你其实已经获得了一些prompt Engineer的训练，在下一次的问答中，你就能更快更好地得到你想要的答案； 当然啦，现在大模型也挺多的，确实有一些朴素的咒语框架可以让我们快速得到更好了的回答，你如果想了解一下，可以看看下面这个课程 (超爽中英!) 2025吴恩达最好的【提示词工程师】教程！附课件代码 DeepLearning.AI_大模型_LLM_Prompt_哔哩哔哩_bilibili 当然，上面说的咒语是GPT对话形式的，文生图，文生视频等等AIGC的应用，咒语可能需要另外习得(你芝麻开门可以开这个门，另外一个门可就不行了哦) SFT(微调) 大模型训练的时候使用的是公开的数据集，prompt咒语念得再好，也没办法，巧妇难为无米之炊，对于特定领域的问题大模型会出现幻觉(瞎回答) 大模型的效果出现一些问题，需要纠正大模型的错误 改变大模型回答的风格等等需要定制，就需要大模型微调 如果大家想要进阶动手微调一下的话，可以使用下面的框架，按照格式准备好数据即可，然后一键启动，上机器开始炼丹即可！ 目前主流的微调框架： https://github.com/hiyouga/LLaMA-Factory https://github.com/unslothai/unsloth https://github.com/modelscope/ms-swift RAGRAG &#x3D; LLM + 外置数据库 ​ 备注：这部分写于2025年4月16日 用过GPT的同学可能会了解到，GPT的知识具有时效性，比如GPT-4发布时间在2023年，那么GPT-4绝对无法帮你回答2024年之后的事情；再者，你有一个本地知识库的时候，你需要大模型结合这个知识库来回答你的问题时，你可能就需要RAG了； 右边严格来说不是RAG的流程，但是广义来讲，也算RAG，llm在其中扮演的是嘴替(总结)的作用；左边这个图是标准的RAG的流程，主要包括两个部分：index(入库) 和 query(出库) 如果大家想要深入学习这一部分的话，下面是一些可以进阶的部分： 当前两个主流的RAG搭建框架(RAG企业级开发)： langchain：https://github.com/langchain-ai/langchain llamaindex：https://github.com/run-llama/llama_index 可以学习的开源项目： QAnything: https://github.com/netease-youdao/QAnything RAGflow：https://github.com/infiniflow/ragflow/blob/main/README_zh.md 关于RAG的优化：RAG技术 AgentAgent &#x3D; LLM + 外部工具 上面的RAG是LLM和外部的知识(文档，图片等)打通了一条链路，相当于在数据层面建立了联系；但是不具备数据处理的能力，而处理数据的能力，一般是API是通过API的形式来展现的；**因此当LLM能够使用外部的 工具(API), LLM的能力将得到极大的扩展 ，**不多bb，展示！！！ https://strudel.cc/ (下面Agent使用到的一个音乐工具) 如果没有耐心看完前面Agent执行步骤的话，可直接拉到2：48秒，然后看后面的即可 如果给了LLM一台可以运行的电脑(环境)，那么这就是今年3月份爆火的AI智能体 Manus 为什么要叫Agent呢，可以看下面的图(没找到比较好的图，自己画的，见谅)，我们可以将用户比作boss，llm比作员工，boss发出一个问题之后，llm去规划并完成工作，llm是具体的执行者，因此叫做代理,Agent 暂时无法在飞书文档外展示此内容 目前智能Agent产品设计一般都是按照上面的思路去进行的，规划(Plan) + 执行(ReAct模型) Agent通过上面的章节，对Agent进行了一些初步的了解，这个小节将通过代码进一步的带大家了解Agent相关的内容 Agent 李宏毅讲Agent 从上面的一些例子我们可以了解到，对于完成一个人类目标而言，Agent需要两个方面的能力，目标拆解的能力和分布执行的能力；对应的名词即plan和function call，有了分步的任务，之后，LLM Agent逐步分析，调用工具或者自身内部知识，然后将结果传给下一步的任务，如下图所示： 通过上面的方式，可以有哪些运用呢？ 用模型训练模型： 使用Agent下围棋，使用电脑，浏览网页等等！ 当然上面的例子也说明了，大模型在调用过程中，可能出现幻觉，这有可能导致任务执行的失败，比如上面的deepseek 改变了国际象棋的规则，然后赢得了AI届的国际象棋桂冠！因此对于复杂问题，选择其它方法或许更可靠。这里不再展开。 上面都提到了大模型要实现Agent，需要具备工具调用的能力，这个能力是怎么实现的呢？看图好像挺简单的一句话就说完了，其实实际呢，也挺简单的。下面通过一个Function Call的例子来简单说明一下。 Function call 调用的实例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import randomfrom datetime import datetimeimport json# step 1: 定义工具def get_current_time(): current_datetime = datetime.now() formatted_time = current_datetime.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;) return f&quot;当前时间：&#123;formatted_time&#125;。&quot;def add(arguments): a = arguments[&quot;num_1&quot;] b = arguments[&quot;num_2&quot;] return f&quot;计算的结果是：&#123;a + b&#125;&quot;# step 2: 创建tools数组tools = [ &#123; &quot;type&quot;: &quot;function&quot;, &quot;function&quot;: &#123; &quot;name&quot;: &quot;get_current_time&quot;, &quot;description&quot;: &quot;当你想知道现在的时间时非常有用。&quot;, &#125; &#125;,]tool_name = [tool[&quot;function&quot;][&quot;name&quot;] for tool in tools]# step 3：使用大模型调用函数from openai import OpenAIimport osclient = OpenAI( api_key=&quot;sk-389c222d8f304e6ba3bb10ad3589d340&quot;, base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,)messages = [ &#123; &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;你是一个很有帮助的助手。如果用户提问关于时间的问题，请调用‘get_current_time’函数。 请以友好的语气回答问题。&quot;&quot;&quot;, &#125;, &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;现在是几点？&quot; &#125;]def function_calling(): completion = client.chat.completions.create( model=&quot;qwen-max&quot;, messages=messages, tools=tools, ) res = completion.choices[0].message print(res.model_dump_json()) return completion# step4: 运行工具函数completion = function_calling()function_name = completion.choices[0].message.tool_calls[0].function.namearguments_string = completion.choices[0].message.tool_calls[0].function.arguments# 使用json模块解析参数字符串arguments = json.loads(arguments_string)# 创建一个函数映射表function_mapper = &#123; &quot;get_current_time&quot;: get_current_time, &quot;add&quot;:add&#125;# 获取函数实体function = function_mapper[function_name]# 如果入参为空，则直接调用函数if arguments == &#123;&#125;: function_output = function()# 否则，传入参数后调用函数else: function_output = function(arguments)# 打印工具的输出print(f&quot;工具函数输出：&#123;function_output&#125;\\n&quot;)## step5： 将工具输出添加到messages中，继续进行下面的步骤messages.append(completion.choices[0].message)messages.append(&#123;&quot;role&quot;: &quot;tool&quot;, &quot;content&quot;: function_output, &quot;tool_call_id&quot;: completion.choices[0].message.tool_calls[0].id&#125;)print(&quot;已添加tool message\\n&quot;)completion = function_calling() WorkFlow - 编排的Agent上面提到，对于复杂任务，完全让大模型去规划，去自由探索，可能出现很多不可预知的问题，这对于一些确定性的任务来说，是很致命的，既然这样，那么就别让大模型逞能，脚踏实地，只解决具体的单步问题，规划问题让人类来干就好了，这就是workflow，这就是截止到2025年4月20日来最主流的Agent 实现方式； MCP上面是通义千问的Function 调用方式，下次我们再添加一个新的工具的时候，是不是又要重复写一下这个流程(定义工具，定义工具描述，然后传给大模型)， 但是现在大模型这么多，大模型之间的Function Call的方式可能不相同，这里写的工具函数，换到GPT4，可能就要修改代码，这样很不符合程序员的复用规则，因此有了MCP MCP其实还是大模型选择需要调用的工具，因此MCP本质还是Function Call， 只是统一了一个标准之后，开发者通过MCP协议写的Function可以给别人复用了 如果想深入了解的话，大家可以对照着官方代码写一遍，就会发现了MCP解决的是哪一方面的问题了； A2A，ANP等等A2A：谷歌提出来的一种 Agent 和 Agent相互通信的协议， MCP协议统一了大模型与外界工具交互的方式，A2A是Agent与Agent间的，可以类比成公司里面部门，每个部门承担一部功能(如前端，后端，数据，算法，HR，财务，运维等)，然后相互协作，共同达成一个目标； ANP：国内提出的类似于A2A的，用于Agent2Agent的协议，目前是成为互联网界的http . . . . . 无论是MCP，还是A2A，抑或者是其它协议，我觉得归根到底是今年自deepseek以来，**大模型的能力得到了较大的提升，**这个生态才慢慢火起来(2024年开年火了一阵就没声音了，因为Agent有点人工智障的味道)，至于Agent有多智能，我觉得还是让子弹飞一会儿，但是在小的方面，确实会影响我们的工作效率；恰当的使用llm来协助我们工作，能做到事半功倍； 好物推荐编程工具类： Cursor (目前最好的AI代码编辑器，就是有点小贵，我使用的是VScode通义灵码插件替代) Trae (字节出品， 国产第一个有知名度的AI代码编辑器(当然，投流，广告投入很大)) 开发框架类:（还是上面那两个） langchain：https://github.com/langchain-ai/langchain llamaindex：https://github.com/run-llama/llama_index (个人常用这个，教程很友好， 但是目前langchain发展更好一些) 零代码类大模型编排工具(适合AI行业的所有人) 搞过comfyUI的同学应该知道节点编辑工具的概念，这个就是llm这边的节点编辑工具 dify : 企业级的，目前大多数工具开发AI流程应用的首选 n8n ：同上，优势在集成了很多的工具 扣子 ： 字节出品，和dify类似 举个dify的例子： 本来想演示一个使用dify搭建小影知识库问答系统的demo，但是貌似飞书文档权限比较严格&#x3D;_&#x3D;#，因此这里简单介绍一下； 以翻译的任务举个例子(目前主流翻译的流程)：通过搭积木的方式，20分钟(2分钟搭建，18分钟的提示词) 即可快速完成一个任务的搭建 另外，比较喜欢的一个功能是不同模型的对比，我觉得在验证阶段很实用 现场演示Agentcline + MCP MCP发展得如火如荼，开源社区上也有很多好玩的MCP工具了，大家可以尝试一下 想一想：大家现在看到这个热点，大家觉得是通过什么实现的？ difyima (好用的结合RAG的文档工具)","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"}]}],"categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"MCP","slug":"MCP","permalink":"https://flippy-bird.github.io/tags/MCP/"},{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"}]}