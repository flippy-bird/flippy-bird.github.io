{"meta":{"title":"大潘子的文字角落","subtitle":"","description":"","author":"Pan","url":"https://flippy-bird.github.io","root":"/"},"pages":[{"title":"categories","date":"2025-11-26T05:54:56.000Z","updated":"2025-11-26T05:55:08.826Z","comments":true,"path":"categories/index.html","permalink":"https://flippy-bird.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-11-26T05:53:10.000Z","updated":"2025-11-26T12:54:36.650Z","comments":true,"path":"tags/index.html","permalink":"https://flippy-bird.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"python基础历练","slug":"30.Python基础历练","date":"2026-01-16T08:10:43.000Z","updated":"2026-01-16T10:25:27.462Z","comments":true,"path":"2026/01/16/30.Python基础历练/","permalink":"https://flippy-bird.github.io/2026/01/16/30.Python%E5%9F%BA%E7%A1%80%E5%8E%86%E7%BB%83/","excerpt":"","text":"元类 具体的项目实践可参考：AgentScope 中的 src&#x2F;agentscope&#x2F;agent&#x2F;_agent_meta.py文件 元类(Metaclass)是用来”创建类”的类 123# 类 ---&gt; 对象# 元类 ---&gt; 类 ---&gt; 对象 元类的作用，主要用于在”类创建阶段”做事情，常见用途： 自动修改类： 自动给类添加属性 自动给方法打日志 统一规范(如方法必须以do_开头) 注册&#x2F;收集类： 子类自动注册到某个地方 (AgentScope 就是用来做这个的) 常用于工厂模式、插件系统 最基本的元类结构 1234567891011class MyMeta(type): def __new__(mls, name, bases, attrs): print(f&quot;创建类：&#123;name&#125;) return super().__new__(mls, name, bases, attrs) &#x27;&#x27;&#x27; 参数说明mls:元类本身name: 类名bases: 父类attrs: 类属性字典 (注意也是包含函数的哦！)&#x27;&#x27;&#x27;","categories":[{"name":"基础知识","slug":"基础知识","permalink":"https://flippy-bird.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://flippy-bird.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Vibe Coding 相关","slug":"29-Vibe-Coding","date":"2026-01-14T08:10:43.000Z","updated":"2026-01-16T10:24:46.934Z","comments":true,"path":"2026/01/14/29-Vibe-Coding/","permalink":"https://flippy-bird.github.io/2026/01/14/29-Vibe-Coding/","excerpt":"","text":"Cursor使用 参考cursor官方文档：https://cursor.com/cn/docs 规则规则的工作原理：规则在提示级别提供持久、可重用的上下文。应用后，规则内容会被加入到模型上下文的开头。这为 AI 在生成代码、理解编辑或协助处理工作流时提供一致的指导。 cursor提供了四种规则：项目规则、用户规则、团队规则、AGENTS.MD 项目规则项目规则以 markdown 文件形式存放在 .cursor/rules 中，并纳入版本控制。规则可以通过路径模式限定作用范围，主要有以下的作用： 沉淀与你代码库相关的领域知识 自动化项目特定的工作流或模板 统一风格或架构决策 12345.cursor/rules/ react-patterns.mdc # 带前置元数据的规则(描述、globs) api-guidelines.md # 简单 markdown 规则 frontend/ # 在文件夹中组织规则 components.md 而对于每个markdown的内容，如下 123456---description: &quot;This rule provides standards for frontend components and API validation&quot;alwaysApply: false---...rest of the rule content 用户规则应用于全局的，将在所有项目上应用，这个在settings –&gt; Rules 里面，如下面的例子： 可以看到，因为我设置了这个规则，我和cursor交互时(chat时候)，返回给我的都是中文回复； AGENTS.MDAGENTS.md 是一个用于定义 agent 指令的简单 markdown 文件。将它放在项目根目录中，作为 .cursor/rules 的替代选项，适用于简单直接的用例。AGENTS.md 是一个没有元数据或复杂配置的纯 markdown 文件。对于只需要简单、易读指令，而不想引入结构化规则额外负担的项目来说，它是理想选择。 官方的一个简单例子如下： 123456789101112# Project Instructions## Code Style- Use TypeScript for all new files- Prefer functional components in React- Use snake_case for database columns## Architecture- Follow the repository pattern- Keep business logic in service layers 当然也是支持嵌套的 12345678project/ AGENTS.md # 全局指令 frontend/ AGENTS.md # 前端专用指令 components/ AGENTS.md # 组件专用指令 backend/ AGENTS.md # 后端专用指令 skills 支持技能何时工作？Cursor 启动时会自动从技能目录中发现技能，并将它们提供给 Agent。Agent 会查看可用的技能，并根据上下文决定何时使用。 技能加载目录 每个技能都应是一个包含 SKILL.md 文件的文件夹： 1234.cursor/└── skills/ └── my-skill/ └── SKILL.md 关于SKILL.md的格式，下面是一个简单的例子,当然在my-skill文件夹可以添加一些资源，脚本等等文件夹，这个可以查看claude的标准来创建自己的skills 12345678910111213141516171819---name: my-skilldescription: Short description of what this skill does and when to use it.---# My SkillDetailed instructions for the agent.## When to Use- Use this skill when...- This skill is helpful for...## Instructions- Step-by-step guidance for the agent- Domain-specific conventions- Best practices and patterns 参考资料 认知重建：Speckit 用了三个月，我放弃了——走出工具很强但用不好的困境","categories":[{"name":"工具使用","slug":"工具使用","permalink":"https://flippy-bird.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"vibe coding","slug":"vibe-coding","permalink":"https://flippy-bird.github.io/tags/vibe-coding/"}]},{"title":"大模型基本知识","slug":"28.大模型基本知识","date":"2025-12-30T13:01:18.000Z","updated":"2025-12-30T09:34:12.166Z","comments":true,"path":"2025/12/30/28.大模型基本知识/","permalink":"https://flippy-bird.github.io/2025/12/30/28.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/","excerpt":"","text":"参考资料 教你从零“手搓”一个大模型，别再只会调用API了 简单的Agentic-RAG流程","categories":[],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"}]},{"title":"Agent","slug":"27.Agent","date":"2025-12-11T13:01:18.000Z","updated":"2026-01-16T10:21:52.963Z","comments":true,"path":"2025/12/11/27.Agent/","permalink":"https://flippy-bird.github.io/2025/12/11/27.Agent/","excerpt":"","text":"Youtu-LLM-2B (26.01.06) 仓库地址：https://modelscope.cn/models/Tencent-YouTu-Research/Youtu-LLM-2B 特点：端侧Agent模型，此外在tokenizer这一步也进行了优化() 看了一下paper，paper中提到了数据构建的过程，主要按照下面的结构去构建 学习资料基础理论 https://github.com/datawhalechina/hello-agents https://github.com/huggingface/agents-course 具体实践 https://github.com/NirDiamant/GenAI_Agents 参考资料Multi-Agent Choosing the Right Multi-Agent Architecture","categories":[],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"},{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"mobile-agent","slug":"mobile-agent","date":"2025-12-09T02:10:52.000Z","updated":"2026-01-16T05:47:19.063Z","comments":true,"path":"2025/12/09/mobile-agent/","permalink":"https://flippy-bird.github.io/2025/12/09/mobile-agent/","excerpt":"","text":"AgentCPM https://github.com/OpenBMB/AgentCPM 参考资料 MobileAgent Open-AutoGLM A2UI - 智能体自动生成 UI 界面的全新协议 MAI-UI：面向真实世界的通用 GUI 智能体","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"端侧","slug":"端侧","permalink":"https://flippy-bird.github.io/tags/%E7%AB%AF%E4%BE%A7/"}]},{"title":"Agent是如何做Plan的？","slug":"LLM的plan调研","date":"2025-12-08T06:58:33.000Z","updated":"2026-01-15T07:08:46.969Z","comments":true,"path":"2025/12/08/LLM的plan调研/","permalink":"https://flippy-bird.github.io/2025/12/08/LLM%E7%9A%84plan%E8%B0%83%E7%A0%94/","excerpt":"","text":"1. langchain&#x2F;langgraph 参考资料： https://docs.langchain.com/oss/python/langchain/middleware/built-in#to-do-list langchain的思想是通过middleware的形式来添加plan的能力，可以参考源码部分：langchain&#x2F;libs&#x2F;langchain_v1&#x2F;langchain&#x2F;agents&#x2F;middleware&#x2F;todo.py （12月8日，后续不知道会不会变化）其本质仍然是一个工具函数的调用，内部的一个工具是write_todos, 相关的middleware是 TodoListMiddleware 这个工具的具体定义是：关于write_todos这个工具的描述，这个描述写的很长，具体可以去源码查看； 123456789@tool(description=WRITE_TODOS_TOOL_DESCRIPTION)def write_todos(todos: list[Todo], tool_call_id: Annotated[str, InjectedToolCallId]) -&gt; Command: &quot;&quot;&quot;Create and manage a structured task list for your current work session.&quot;&quot;&quot; return Command( update=&#123; &quot;todos&quot;: todos, &quot;messages&quot;: [ToolMessage(f&quot;Updated todo list to &#123;todos&#125;&quot;, tool_call_id=tool_call_id)], &#125; ) system prompt是： 12345678910111213WRITE_TODOS_SYSTEM_PROMPT = &quot;&quot;&quot;## `write_todos`You have access to the `write_todos` tool to help you manage and plan complex objectives.Use this tool for complex objectives to ensure that you are tracking each necessary step and giving the user visibility into your progress.This tool is very helpful for planning complex objectives, and for breaking down these larger complex objectives into smaller steps.It is critical that you mark todos as completed as soon as you are done with a step. Do not batch up multiple steps before marking them as completed.For simple objectives that only require a few steps, it is better to just complete the objective directly and NOT use this tool.Writing todos takes time and tokens, use it when it is helpful for managing complex many-step problems! But not for simple few-step requests.## Important To-Do List Usage Notes to Remember- The `write_todos` tool should never be called multiple times in parallel.- Don&#x27;t be afraid to revise the To-Do list as you go. New information may reveal new tasks that need to be done, or old tasks that are irrelevant.&quot;&quot;&quot; 2. Qwen code https://github.com/QwenLM/qwen-code 采用的是内置工具的方式来实现agent的plan能力，源代码部分可参考：qwen-code&#x2F;packages&#x2F;core&#x2F;src&#x2F;tools&#x2F;todoWrite.ts 具体的提供了下面的todo工具类： 12345678910class TodoWriteToolInvocation extends BaseToolInvocation&lt; TodoWriteParams, ToolResult&gt; &#123;&#125;// 暴露给外面的todo工具类export class TodoWriteTool extends BaseDeclarativeTool&lt; TodoWriteParams, ToolResult&gt; &#123;&#125; 关于工具的描述，截取一部分prompt如下： 1234567891011121314151617181920212223242526272829const todoWriteToolDescription = `Use this tool to create and manage a structured task list for your current coding session. This helps you track progress, organize complex tasks, and demonstrate thoroughness to the user.It also helps the user understand the progress of the task and overall progress of their requests.## When to Use This ToolUse this tool proactively in these scenarios:1. Complex multi-step tasks - When a task requires 3 or more distinct steps or actions2. Non-trivial and complex tasks - Tasks that require careful planning or multiple operations3. User explicitly requests todo list - When the user directly asks you to use the todo list4. User provides multiple tasks - When users provide a list of things to be done (numbered or comma-separated)5. After receiving new instructions - Immediately capture user requirements as todos6. When you start working on a task - Mark it as in_progress BEFORE beginning work. Ideally you should only have one todo as in_progress at a time7. After completing a task - Mark it as completed and add any new follow-up tasks discovered during implementation## When NOT to Use This ToolSkip using this tool when:1. There is only a single, straightforward task2. The task is trivial and tracking it provides no organizational benefit3. The task can be completed in less than 3 trivial steps4. The task is purely conversational or informationalNOTE that you should not use this tool if there is only one trivial task to do. In this case you are better off just doing the task directly.## Examples of When to Use the Todo List ...`; 3. gemini cli和qwen code 类似，源码部分在：gemini-cli&#x2F;packages&#x2F;core&#x2F;src&#x2F;tools&#x2F;write-todos.ts 1234export class WriteTodosTool extends BaseDeclarativeTool&lt; WriteTodosToolParams, ToolResult&gt; &#123;&#125; 工具说明的prompt截取如下： 123456789101112131415161718192021222324252627282930export const WRITE_TODOS_DESCRIPTION = `This tool can help you list out the current subtasks that are required to be completed for a given user request. The list of subtasks helps you keep track of the current task, organize complex queries and help ensure that you don&#x27;t miss any steps. With this list, the user can also see the current progress you are making in executing a given task.Depending on the task complexity, you should first divide a given task into subtasks and then use this tool to list out the subtasks that are required to be completed for a given user request.Each of the subtasks should be clear and distinct. Use this tool for complex queries that require multiple steps. If you find that the request is actually complex after you have started executing the user task, create a todo list and use it. If execution of the user task requires multiple steps, planning and generally is higher complexity than a simple Q&amp;A, use this tool.DO NOT use this tool for simple tasks that can be completed in less than 2 steps. If the user query is simple and straightforward, do not use the tool. If you can respond with an answer in a single turn then this tool is not required.## Task state definitions- pending: Work has not begun on a given subtask.- in_progress: Marked just prior to beginning work on a given subtask. You should only have one subtask as in_progress at a time.- completed: Subtask was successfully completed with no errors or issues. If the subtask required more steps to complete, update the todo list with the subtasks. All steps should be identified as completed only when they are completed.- cancelled: As you update the todo list, some tasks are not required anymore due to the dynamic nature of the task. In this case, mark the subtasks as cancelled.## Methodology for using this tool1. Use this todo list as soon as you receive a user request based on the complexity of the task.2. Keep track of every subtask that you update the list with.3. Mark a subtask as in_progress before you begin working on it. You should only have one subtask as in_progress at a time.4. Update the subtask list as you proceed in executing the task. The subtask list is not static and should reflect your progress and current plans, which may evolve as you acquire new information.5. Mark a subtask as completed when you have completed it.6. Mark a subtask as cancelled if the subtask is no longer needed.7. You must update the todo list as soon as you start, stop or cancel a subtask. Don&#x27;t batch or wait to update the todo list.## Examples of When to Use the Todo List ...`; 4. AgentScope https://github.com/agentscope-ai/agentscope 也是通过工具调用的方式来实现的，可以参考我之前的文档 AgentScope源码学习 5.cline https://github.com/cline/cline 应该也是通过调用的工具的方式让Agent具备了plan的能力，相关的提示词源码是：cline&#x2F;src&#x2F;core&#x2F;prompts&#x2F;system-prompt&#x2F;components&#x2F;task_progress.ts 对应的prompt如下：可以看到， 12345678910111213141516171819202122232425const UPDATING_TASK_PROGRESS = `UPDATING TASK PROGRESSYou can track and communicate your progress on the overall task using the task_progress parameter supported by every tool call. Using task_progress ensures you remain on task, and stay focused on completing the user&#x27;s objective. This parameter can be used in any mode, and with any tool call.- When switching from PLAN MODE to ACT MODE, you must create a comprehensive todo list for the task using the task_progress parameter- Todo list updates should be done silently using the task_progress parameter - do not announce these updates to the user- Use standard Markdown checklist format: &quot;- [ ]&quot; for incomplete items and &quot;- [x]&quot; for completed items- Keep items focused on meaningful progress milestones rather than minor technical details. The checklist should not be so granular that minor implementation details clutter the progress tracking.- For simple tasks, short checklists with even a single item are acceptable. For complex tasks, avoid making the checklist too long or verbose.- If you are creating this checklist for the first time, and the tool use completes the first step in the checklist, make sure to mark it as completed in your task_progress parameter.- Provide the whole checklist of steps you intend to complete in the task, and keep the checkboxes updated as you make progress. It&#x27;s okay to rewrite this checklist as needed if it becomes invalid due to scope changes or new information.- If a checklist is being used, be sure to update it any time a step has been completed.- The system will automatically include todo list context in your prompts when appropriate - these reminders are important.Example:&lt;execute_command&gt;&lt;command&gt;npm install react&lt;/command&gt;&lt;requires_approval&gt;false&lt;/requires_approval&gt;&lt;task_progress&gt;- [x] Set up project structure- [x] Install dependencies- [ ] Create components- [ ] Test application&lt;/task_progress&gt;&lt;/execute_command&gt;` 对于Vscode中ide部分，貌似是通过一个focus chain模块来实现的，具体部分可参考源代码文件： cline&#x2F;src&#x2F;core&#x2F;task&#x2F;focus-chain&#x2F; cline&#x2F;src&#x2F;shared&#x2F;tools.ts cline&#x2F;src&#x2F;shared&#x2F;tools.ts里面是cline的默认工具，其中 TODO指向的是focus_chain 这个工具 123456789101112131415161718192021222324252627export enum ClineDefaultTool &#123; ASK = &quot;ask_followup_question&quot;, ATTEMPT = &quot;attempt_completion&quot;, BASH = &quot;execute_command&quot;, FILE_EDIT = &quot;replace_in_file&quot;, FILE_READ = &quot;read_file&quot;, FILE_NEW = &quot;write_to_file&quot;, SEARCH = &quot;search_files&quot;, LIST_FILES = &quot;list_files&quot;, LIST_CODE_DEF = &quot;list_code_definition_names&quot;, BROWSER = &quot;browser_action&quot;, MCP_USE = &quot;use_mcp_tool&quot;, MCP_ACCESS = &quot;access_mcp_resource&quot;, MCP_DOCS = &quot;load_mcp_documentation&quot;, NEW_TASK = &quot;new_task&quot;, PLAN_MODE = &quot;plan_mode_respond&quot;, ACT_MODE = &quot;act_mode_respond&quot;, TODO = &quot;focus_chain&quot;, // 这个地方，应该就是cline里面用来规划的工具了 WEB_FETCH = &quot;web_fetch&quot;, WEB_SEARCH = &quot;web_search&quot;, CONDENSE = &quot;condense&quot;, SUMMARIZE_TASK = &quot;summarize_task&quot;, REPORT_BUG = &quot;report_bug&quot;, NEW_RULE = &quot;new_rule&quot;, APPLY_PATCH = &quot;apply_patch&quot;, GENERATE_EXPLANATION = &quot;generate_explanation&quot;,&#125; 再按照cline&#x2F;src&#x2F;core 里面的README的结构说明 工具类相关的实现应该是在task文件目录下，因此在task目录，可以找到focus-chain这个文件夹 在index.ts 文件里面可以看到，是通过FocusChainManager 这个类来实现todo list的检查和更新的；在prompts.ts这个文件夹里面可以看到涉及到todo list操作相关的prompt，下面展示一个初始化任务时的提示词 12345678910111213141516171819202122232425262728// Prompt for initial list creationconst initial = `# task_progress CREATION REQUIRED - ACT MODE ACTIVATED**You&#x27;ve just switched from PLAN MODE to ACT MODE!**** IMMEDIATE ACTION REQUIRED:**1. Create a comprehensive todo list in your NEXT tool call2. Use the task_progress parameter to provide the list3. Format each item using markdown checklist syntax: - [ ] For tasks to be done - [x] For any tasks already completed**Your todo/task_progress list should include:** - All major implementation steps - Testing and validation tasks - Documentation updates if needed - Final verification steps**Example format:**\\ - [ ] Set up project structure - [ ] Implement core functionality - [ ] Add error handling - [ ] Write tests - [ ] Test implementation - [ ] Document changes**Remember:** Keeping the task_progress list updated helps track progress and ensures nothing is missed.` 从使用上来看，cline似乎也是使用的ReAct模式，当然，可能会有一些变化，核心逻辑是在 cline&#x2F;src&#x2F;core&#x2F;task&#x2F;index.ts这个文件里面，这个文件里面有一些循环,如下面的initiateTaskLoop函数，大概可以判断应该是存在ReAct模式的(从下面这个函数的注释也可以看出来)，逻辑太长，后面有时间可以仔细研究一下，主要看recursivelyMakeClineRequests的逻辑； 1234567891011121314151617181920212223242526272829private async initiateTaskLoop(userContent: ClineContent[]): Promise&lt;void&gt; &#123; let nextUserContent = userContent let includeFileDetails = true while (!this.taskState.abort) &#123; const didEndLoop = await this.recursivelyMakeClineRequests(nextUserContent, includeFileDetails) includeFileDetails = false // we only need file details the first time // The way this agentic loop works is that cline will be given a task that he then calls tools to complete. unless there&#x27;s an attempt_completion call, we keep responding back to him with his tool&#x27;s responses until he either attempt_completion or does not use anymore tools. If he does not use anymore tools, we ask him to consider if he&#x27;s completed the task and then call attempt_completion, otherwise proceed with completing the task. //const totalCost = this.calculateApiCost(totalInputTokens, totalOutputTokens) if (didEndLoop) &#123; // For now a task never &#x27;completes&#x27;. This will only happen if the user hits max requests and denies resetting the count. //this.say(&quot;task_completed&quot;, `Task completed. Total API usage cost: $&#123;totalCost&#125;`) break &#125; else &#123; // this.say( // &quot;tool&quot;, // &quot;Cline responded with only text blocks but has not called attempt_completion yet. Forcing him to continue with task...&quot; // ) nextUserContent = [ &#123; type: &quot;text&quot;, text: formatResponse.noToolsUsed(this.useNativeToolCalls), &#125;, ] this.taskState.consecutiveMistakeCount++ &#125; &#125;&#125;","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"plan","slug":"plan","permalink":"https://flippy-bird.github.io/tags/plan/"}]},{"title":"Mem0源码学习","slug":"Mem0源码学习","date":"2025-12-01T05:54:24.000Z","updated":"2025-12-11T06:06:32.590Z","comments":true,"path":"2025/12/01/Mem0源码学习/","permalink":"https://flippy-bird.github.io/2025/12/01/Mem0%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"https://github.com/mem0ai/mem0 1. 项目的核心代码从memory&#x2F;base.py 里面的基类可以看到，记忆功能主要实现了下面的功能 123456789101112131415class MemoryBase(ABC) @abstractmethod def get(self, memory_id): # 根据id获取对应id的memory @abstractmethod def get_all(self): # 列出所有的memory @abstractmethod def update(self, memory_id, data): # 更新id的memory @abstractmethod def delete(self, memory_id): # 删除id的memory @abstractmethod def history(self, memory_id): # Get the history of changes for a memory by ID. mem0的核心实现在memory&#x2F;main.py 文件中 123456class Memory(MemoryBase): # 这里除了实现上面base定义的基本功能外，有一个search的核心功能实现 def search(self, query, ...): # 这里会根据用户的query去寻找最相关的memory class AsyncMemory(MemoryBase): # 异步的接口不用再使用另外一个基类，直接使用了MemoryBase，但是在实现时使用了异步 async def get(self, memory_id): 1.1 search看search里面的实现，就是标准的RAG流程，embedding query, 然后从向量数据库或者图数据库召回，做一个ReRank重排序 123456789101112131415# 是通过下面的函数来实现向量召回的def _search_vector_store(self, query, filters, limit, threshold: Optional[float] = None): embeddings = self.embedding_model.embed(query, &quot;search&quot;) # 这一步就是向量检索了 memories = self.vector_store.search(query=query, vectors=embeddings, limit=limit, filters=filters) ... def search(self, query, ...): ... with concurrent.futures.ThreadPoolExecutor() as executor: future_memories = executor.submit(self._search_vector_store, query, effective_filters, limit, threshold) ## 这里的self.graph就是图关系库 future_graph_entities = (executor.submit(self.graph.search, query, effective_filters, limit) if self.enable_graph else None) 关于Memory类中使用到的LLM，embedding, graph,rerank模型等等都是使用工厂模式来初始化的 12345678910111213141516171819202122class Memory(MemoryBase): self.embedding_model = EmbedderFactory.create( self.config.embedder.provider, self.config.embedder.config, self.config.vector_store.config, ) self.vector_store = VectorStoreFactory.create( self.config.vector_store.provider, self.config.vector_store.config ) self.llm = LlmFactory.create(self.config.llm.provider, self.config.llm.config) if config.reranker: self.reranker = RerankerFactory.create( config.reranker.provider, config.reranker.config ) if self.config.graph_store.config: provider = self.config.graph_store.provider self.graph = GraphStoreFactory.create(provider, self.config) self.enable_graph = True else: self.graph = None 工厂函数里面对应的就是各个可以支持的实现，这个实现是在 mem0&#x2F;utils&#x2F;factory.py 文件中，下面的是图关系数据库的支持代码 12345678910111213141516171819202122class GraphStoreFactory: &quot;&quot;&quot; Factory for creating MemoryGraph instances for different graph store providers. Usage: GraphStoreFactory.create(provider_name, config) &quot;&quot;&quot; provider_to_class = &#123; &quot;memgraph&quot;: &quot;mem0.memory.memgraph_memory.MemoryGraph&quot;, &quot;neptune&quot;: &quot;mem0.graphs.neptune.neptunegraph.MemoryGraph&quot;, &quot;neptunedb&quot;: &quot;mem0.graphs.neptune.neptunedb.MemoryGraph&quot;, &quot;kuzu&quot;: &quot;mem0.memory.kuzu_memory.MemoryGraph&quot;, &quot;default&quot;: &quot;mem0.memory.graph_memory.MemoryGraph&quot;, &#125; @classmethod def create(cls, provider_name, config): class_type = cls.provider_to_class.get(provider_name, cls.provider_to_class[&quot;default&quot;]) try: GraphClass = load_class(class_type) except (ImportError, AttributeError) as e: raise ImportError(f&quot;Could not import MemoryGraph for provider &#x27;&#123;provider_name&#125;&#x27;: &#123;e&#125;&quot;) return GraphClass(config) 可以看到mem0支持4中图关系数据库memgraph、neptune、neptunedb、kuzu(为什么会放在两个不同文件夹下面呢？这个暂时还没看明白)，其它的LLM，embedding等等类似； 1.2 add这个函数是mem0的核心,主要通过两个子函数来实现 1234567891011121314151617181920def add(self, messages, *, user_id: Optional[str] = None, agent_id: Optional[str] = None, run_id: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None, infer: bool = True, memory_type: Optional[str] = None, prompt: Optional[str] = None,): with concurrent.futures.ThreadPoolExecutor() as executor: # 处理embedding相关的 future1 = executor.submit(self._add_to_vector_store, messages, processed_metadata, effective_filters, infer) # 图关系数据库 future2 = executor.submit(self._add_to_graph, messages, effective_filters) concurrent.futures.wait([future1, future2]) vector_store_result = future1.result() graph_result = future2.result() 而核心中的核心是_add_to_vector_store 这个函数 1234567891011121314151617181920212223242526# 当 infer 为false时，是常规的记忆存储，embedding,入库 (直接入库的模式)def _add_to_vector_store(self, messages, metadata, filters, infer): # 当infer 为true时，将会使用LLM分析对话内容，提取有意义的事实，并智能地决定如何处理这些记忆（添加、更新、删除或保持不变） ### 这里是提取实体关系的逻辑 parsed_messages = parse_messages(messages) if self.config.custom_fact_extraction_prompt: system_prompt = self.config.custom_fact_extraction_prompt user_prompt = f&quot;Input:\\n&#123;parsed_messages&#125;&quot; else: # Determine if this should use agent memory extraction based on agent_id presence # and role types in messages is_agent_memory = self._should_use_agent_memory_extraction(messages, metadata) system_prompt, user_prompt = get_fact_retrieval_messages(parsed_messages, is_agent_memory) response = self.llm.generate_response( messages=[ &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt&#125;, &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt&#125;, ], response_format=&#123;&quot;type&quot;: &quot;json_object&quot;&#125;, ) # 抽取实体后，开始进行判断下一步对记忆进行 增删改查的逻辑了，也是借助了大模型来实现 # 这部分太长省略了 可以观察一下mem0中抽取用户或者Agent 特性的提示词 (太长，只展示一部分，具体文件在：mem0&#x2F;configs&#x2F;prompts.py 里面的USER_MEMORY_EXTRACTION_PROMPT和AGENT_MEMORY_EXTRACTION_PROMPT) 首先，LLM主要任务是： 123456789101112131415161718AGENT_MEMORY_EXTRACTION_PROMPT = f&#x27;&#x27;&#x27;You are a Personal Information Organizer, specialized in accurately storing facts, user memories, and preferences. Your primary role is to extract relevant pieces of information from conversations and organize them into distinct, manageable facts. This allows for easy retrieval and personalization in future interactions. Below are the types of information you need to focus on and the detailed instructions on how to handle the input data.# [IMPORTANT]: GENERATE FACTS SOLELY BASED ON THE USER&#x27;S MESSAGES. DO NOT INCLUDE INFORMATION FROM ASSISTANT OR SYSTEM MESSAGES.# [IMPORTANT]: YOU WILL BE PENALIZED IF YOU INCLUDE INFORMATION FROM ASSISTANT OR SYSTEM MESSAGES.Types of Information to Remember:1. Store Personal Preferences: Keep track of likes, dislikes, and specific preferences in various categories such as food, products, activities, and entertainment.2. Maintain Important Personal Details: Remember significant personal information like names, relationships, and important dates.3. Track Plans and Intentions: Note upcoming events, trips, goals, and any plans the user has shared.4. Remember Activity and Service Preferences: Recall preferences for dining, travel, hobbies, and other services.5. Monitor Health and Wellness Preferences: Keep a record of dietary restrictions, fitness routines, and other wellness-related information.6. Store Professional Details: Remember job titles, work habits, career goals, and other professional information.7. Miscellaneous Information Management: Keep track of favorite books, movies, brands, and other miscellaneous details that the user shares.&#x27;&#x27;&#x27; 具体的few shot例子如下：给了一些正例和反例(不用提取的例子) 12345678910111213141516171819202122AGENT_MEMORY_EXTRACTION_PROMPT = f&#x27;&#x27;&#x27;User: Hi.Assistant: Hello! I enjoy assisting you. How can I help today?Output: &#123;&#123;&quot;facts&quot; : []&#125;&#125;User: There are branches in trees.Assistant: That&#x27;s an interesting observation. I love discussing nature.Output: &#123;&#123;&quot;facts&quot; : []&#125;&#125;User: Hi, I am looking for a restaurant in San Francisco.Assistant: Sure, I can help with that. Any particular cuisine you&#x27;re interested in?Output: &#123;&#123;&quot;facts&quot; : [&quot;Looking for a restaurant in San Francisco&quot;]&#125;&#125;User: Yesterday, I had a meeting with John at 3pm. We discussed the new project.Assistant: Sounds like a productive meeting. I&#x27;m always eager to hear about new projects.Output: &#123;&#123;&quot;facts&quot; : [&quot;Had a meeting with John at 3pm and discussed the new project&quot;]&#125;&#125;User: Hi, my name is John. I am a software engineer.Assistant: Nice to meet you, John! My name is Alex and I admire software engineering. How can I help?Output: &#123;&#123;&quot;facts&quot; : [&quot;Name is John&quot;, &quot;Is a Software engineer&quot;]&#125;&#125;&#x27;&#x27;&#x27; 不知道这种写法会不会限制LLM输出用户不想要的，prompt里面存在类似下面的句子： 12# [IMPORTANT]: GENERATE FACTS SOLELY BASED ON THE USER&#x27;S MESSAGES. DO NOT INCLUDE INFORMATION FROM ASSISTANT OR SYSTEM MESSAGES.# [IMPORTANT]: YOU WILL BE PENALIZED IF YOU INCLUDE INFORMATION FROM ASSISTANT OR SYSTEM MESSAGES. 获取到哪些用户的习惯或者其它一些与用户相关信息之后，然后使用embedding匹配从memory中召回一些与这些信息相关的信息；具体的代码如下： 12345678910111213# new_retrieved_facts 即是从这条消息中获取到的用户偏好for new_mem in new_retrieved_facts: messages_embeddings = self.embedding_model.embed(new_mem, &quot;add&quot;) new_message_embeddings[new_mem] = messages_embeddings existing_memories = self.vector_store.search( query=new_mem, vectors=messages_embeddings, limit=5, filters=search_filters, ) for mem in existing_memories: retrieved_old_memory.append(&#123;&quot;id&quot;: mem.id, &quot;text&quot;: mem.payload.get(&quot;data&quot;, &quot;&quot;)&#125;) 回溯到相关的历史memory之后，然后使用LLM确定是否添加新的记忆，还是删除更新旧的记忆，具体的职责相关prompt如下 12345678910111213DEFAULT_UPDATE_MEMORY_PROMPT = &quot;&quot;&quot;You are a smart memory manager which controls the memory of a system.You can perform four operations: (1) add into the memory, (2) update the memory, (3) delete from the memory, and (4) no change.Based on the above four operations, the memory will change.Compare newly retrieved facts with the existing memory. For each new fact, decide whether to:- ADD: Add it to the memory as a new element- UPDATE: Update an existing memory element- DELETE: Delete an existing memory element- NONE: Make no change (if the fact is already present or irrelevant)&quot;&quot;&quot; few shot 的例子如下：展示的是删除这个操作的例子，完整的可以看mem0&#x2F;configs&#x2F;prompts.py 文件中的DEFAULT_UPDATE_MEMORY_PROMPT 12345678910111213141516171819202122232425262728293031323334353637DEFAULT_UPDATE_MEMORY_PROMPT = &quot;&quot;&quot;There are specific guidelines to select which operation to perform:3. **Delete**: If the retrieved facts contain information that contradicts the information present in the memory, then you have to delete it. Or if the direction is to delete the memory, then you have to delete it.Please note to return the IDs in the output from the input IDs only and do not generate any new ID.- **Example**: - Old Memory: [ &#123; &quot;id&quot; : &quot;0&quot;, &quot;text&quot; : &quot;Name is John&quot; &#125;, &#123; &quot;id&quot; : &quot;1&quot;, &quot;text&quot; : &quot;Loves cheese pizza&quot; &#125; ] - Retrieved facts: [&quot;Dislikes cheese pizza&quot;] - New Memory: &#123; &quot;memory&quot; : [ &#123; &quot;id&quot; : &quot;0&quot;, &quot;text&quot; : &quot;Name is John&quot;, &quot;event&quot; : &quot;NONE&quot; &#125;, &#123; &quot;id&quot; : &quot;1&quot;, &quot;text&quot; : &quot;Loves cheese pizza&quot;, &quot;event&quot; : &quot;DELETE&quot; &#125; ] &#125;&quot;&quot;&quot; 1.3 其它memory&#x2F;telemetry.py 文件，这个文件的作用类似埋点，用来记录用户使用mem0的数据情况（在gemini cli， qwen code中看到同样的文件）","categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"memory","slug":"memory","permalink":"https://flippy-bird.github.io/tags/memory/"}]},{"title":"LLM memory","slug":"LLM-memory","date":"2025-12-01T05:47:10.000Z","updated":"2025-12-30T09:01:58.990Z","comments":true,"path":"2025/12/01/LLM-memory/","permalink":"https://flippy-bird.github.io/2025/12/01/LLM-memory/","excerpt":"","text":"参考资料 LLM memory evaluation EverMemos MemOS zep memu letta 北大出品，最火、最全的Agent记忆综述！！ 相关微信公众号地址","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"memory","slug":"memory","permalink":"https://flippy-bird.github.io/tags/memory/"}]},{"title":"LightRAG","slug":"LightRAG","date":"2025-11-28T07:06:12.000Z","updated":"2025-12-11T06:01:49.290Z","comments":true,"path":"2025/11/28/LightRAG/","permalink":"https://flippy-bird.github.io/2025/11/28/LightRAG/","excerpt":"","text":"1. 背景待详细看完完整论文后补充，大概就是GraphRag虽然效果比较好，但是速度慢，建立图的过程中消耗的token也很多，因此有了LightRag； 2. LightRAG的原理 深度解析比微软的GraphRAG简洁很多的LightRAG，一看就懂 先看了知乎上的一些解读，感觉就是简化版本的GraphRAG，在索引阶段的处理方式是差不多的，只是LightRAG将GraphRAG中比较慢的部分去掉了(社区报告部分，因此也去掉了global search)，数据处理流程是：先分块，然后提取实体和关系，然后入库，index部分的工作就完成了； 在查询阶段，提供了4中方式： 最基本的向量相似度匹配 local search: 根据用户的query生成一些low-level 的关键词，然后根据生成的关键词去建立好的图谱查询； global search: 根据用户的query生成一些high-level 的关键词，然后根据生成的关键词去建立好的图谱查询； 混合搜索：local search + global search 3. 源码解析 TODO","categories":[{"name":"RAG框架学习","slug":"RAG框架学习","permalink":"https://flippy-bird.github.io/categories/RAG%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Rag","slug":"Rag","permalink":"https://flippy-bird.github.io/tags/Rag/"}]},{"title":"AgentScope源码学习","slug":"AgentScope源码学习","date":"2025-11-25T11:47:53.000Z","updated":"2026-01-15T02:29:24.972Z","comments":true,"path":"2025/11/25/AgentScope源码学习/","permalink":"https://flippy-bird.github.io/2025/11/25/AgentScope%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"AgentScope (阿里的) https://github.com/agentscope-ai/agentscope 记忆长期记忆部分使用了mem0这个工具，当然，代码里面也提到了，可以使用阿里自家的ReMe这个记忆框架； 在26年1月份的更新中，添加了数据库的支持(使用Redis和Sql)，使用Redis应该是保存临时的对话历史信息，Sql是为了保存长期记忆； Agent这一块儿使用的是基本的React模式，输出最后的回答，也成了一个工具；多了一个 1234567891011121314### AgentBase# 在AgentBase里面有一个虚函数 replydef reply()### 在ReactAgentBase里面有基本的React框架def _reasoning() # 虚函数def _acting() # 虚函数### 在ReactAgent里面def reply(): 这里就类似OpenManus里面的step()函数的作用了，从源码来看，逻辑完全一样 self._reasoning() ... self._acting() 在Agent里面有一个observe，感觉是为了观察到外界信息准备的接口(用于多Agent之间的信息互动) 1234567891011async def observe(self, msg: Msg | list[Msg] | None) -&gt; None: &quot;&quot;&quot;Receive the given message(s) without generating a reply. Args: msg (`Msg | list[Msg] | None`): The message(s) to be observed. &quot;&quot;&quot; raise NotImplementedError( f&quot;The observe function is not implemented in&quot; f&quot; &#123;self.__class__.__name__&#125; class.&quot;, ) 多Agent互动在这个框架里面使用的是swarm模式，似乎比较简单，每个agent observe其它agent的输出，添加到自己的记忆里面去就好了 在src&#x2F;pipeline&#x2F;_msghub.py文件夹里面 （或者见类名时的说明） 123456789async def broadcast(self, msg: list[Msg] | Msg) -&gt; None: &quot;&quot;&quot;Broadcast the message to all participants. Args: msg (`list[Msg] | Msg`): Message(s) to be broadcast among all participants. &quot;&quot;&quot; for agent in self.participants: await agent.observe(msg) Interrupt(中断介入)这个好像还不错，可以看一下，文档在https://doc.agentscope.io/tutorial/task_tool.html#interrupting-tool-execution， 对于工具执行的取消，是利用了asyncio的取消机制来实现的 Hooks使用了python元编程来实现，在元类中添加一些 Plan的实现实现了一些plan的功能函数，然后让Agent去调用和更改当前的plan 其它字节也出了一个类似框架：veadk-python","categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"smolagents源码学习","slug":"smolagents源码学习","date":"2025-11-25T08:43:25.000Z","updated":"2025-12-11T06:08:40.485Z","comments":true,"path":"2025/11/25/smolagents源码学习/","permalink":"https://flippy-bird.github.io/2025/11/25/smolagents%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"https://github.com/huggingface/smolagents memory 管理1234class AgentMemory: def __init__(self, system_prompt:str): self.system_prompt: SystemPromptStep = SystemPromptStep(system_prompt=system_prompt) self.steps: list[TaskStep | ActionStep | PlanningStep] = [] 将LLM执行过程的信息划分成了四个部分(主要，其它)： TaskStep: 与用户输入相关 (用户提问，上传图片等) SystemPromptStep: 系统的prompt PlanningStep: 与规划相关的记忆 (暂时还没遇到) ActionStep：当前送到LLM进行执行的信息 历史信息的获取 所以主要在于上面每种类型记忆数据 to_messages的实现 需要注意的是前后信息的完整性 1234567891011121314151617181920212223# agents.py line:1256def _step_stream( self, memory_step: ActionStep ) -&gt; Generator[ChatMessageStreamDelta | ToolCall | ToolOutput | ActionOutput]: &quot;&quot;&quot; Perform one step in the ReAct framework: the agent thinks, acts, and observes the result. Yields ChatMessageStreamDelta during the run if streaming is enabled. At the end, yields either None if the step is not final, or the final answer. &quot;&quot;&quot; memory_messages = self.write_memory_to_messages() # agents.py line:758def write_memory_to_messages( self, summary_mode: bool = False, ) -&gt; list[ChatMessage]: &quot;&quot;&quot; Reads past llm_outputs, actions, and observations or errors from the memory into a series of messages that can be used as input to the LLM. Adds a number of keywords (such as PLAN, error, etc) to help the LLM. &quot;&quot;&quot; messages = self.memory.system_prompt.to_messages(summary_mode=summary_mode) for memory_step in self.memory.steps: messages.extend(memory_step.to_messages(summary_mode=summary_mode)) return messages 边界处理当超过最大尝试次数（默认是20次）时，最后会总结19步的step，然后给出一个最终答案 12345678910111213141516# agent.py line:810def provide_final_answer(self, task: str) -&gt; ChatMessage: messages : 这里有一个专门针对这种情况的系统prompt messages += self.write_memory_to_messages()[1:] messages : 需要组装的post_messages try: chat_message: ChatMessage = self.model.generate(messages) return chat_message except Exception as e: return ChatMessage( role=MessageRole.ASSISTANT, content=[&#123;&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: f&quot;Error in generating final LLM output: &#123;e&#125;&quot;&#125;], ) Agent: CodeAgent 项目的CodeAgent模式算是这个项目里面比较新颖的一种方式了，调用工具的API是通过执行python代码的方式来执行的，但是感觉解析python的AST那部分，就感觉好复杂-_-#，没有FunctionCall的这种方式简洁了。 来源于Executable Code Actions Elicit Better LLM Agents，这篇论文主要的出发动机是当前LLM Agent通常通过以预定义的格式生成 JSON 或文本来生成Action，这通常受到约束动作空间（例如，预定义工具的范围）和受限灵活性（例如，无法组合多个工具）的限制。 链接：https://zhuanlan.zhihu.com/p/16341067315","categories":[{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"MCP","slug":"mcp介绍","date":"2025-11-25T06:02:24.000Z","updated":"2025-12-11T06:06:17.461Z","comments":true,"path":"2025/11/25/mcp介绍/","permalink":"https://flippy-bird.github.io/2025/11/25/mcp%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"MCP话不多说，直接上图即可 有MCP和没有MCP的区别，提升了效率 MCP的架构图：主要是由Host、Client和Server三部分组成 个人demo mcp demo 参考资料 MCP (Model Context Protocol)，一篇就够了。 python SDK的官方文档 测试MCP工具接入使用的地址：阿里MCP","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"MCP","slug":"MCP","permalink":"https://flippy-bird.github.io/tags/MCP/"}]},{"title":"大模型入门(组内分享)","slug":"大模型入门-组内分享","date":"2025-06-24T13:01:18.000Z","updated":"2025-12-30T09:35:22.707Z","comments":true,"path":"2025/06/24/大模型入门-组内分享/","permalink":"https://flippy-bird.github.io/2025/06/24/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-%E7%BB%84%E5%86%85%E5%88%86%E4%BA%AB/","excerpt":"","text":"背景 2025年开年以来，大家或多或少都听过下面这些词：deepseek， AI， 人工智能，Agent，具身智能； AI到底发展到哪一步了，利用AI可以做哪些事情，或者作为技术人员，想要使用AI做一些事情，应该学习那些东西，这篇将和大家一起探讨下。 备注声明：该分享定位轻科普向，不会涉及大模型相关的底层原理，有些结论属于个人的理解和感悟，如需要深入交流，欢迎大家和我深入探讨。 大模型相关应用Prompt Engineer(提示词)Prompt 咒语 —-&gt; 激发LLM的潜能 2023年的某一天，当你开始和ChatGpt互动的那一刻开始，你就是一个Prompt Engineer了！ 当你不断试探GPT，使用各种策略，反问，试探，举个例子等等(专业一点就是few shot, zero-shot, cot等等)，最终得到正确答案时，你其实已经获得了一些prompt Engineer的训练，在下一次的问答中，你就能更快更好地得到你想要的答案； 当然啦，现在大模型也挺多的，确实有一些朴素的咒语框架可以让我们快速得到更好了的回答，你如果想了解一下，可以看看下面这个课程 (超爽中英!) 2025吴恩达最好的【提示词工程师】教程！附课件代码 DeepLearning.AI_大模型_LLM_Prompt_哔哩哔哩_bilibili 当然，上面说的咒语是GPT对话形式的，文生图，文生视频等等AIGC的应用，咒语可能需要另外习得(你芝麻开门可以开这个门，另外一个门可就不行了哦) SFT(微调) 大模型训练的时候使用的是公开的数据集，prompt咒语念得再好，也没办法，巧妇难为无米之炊，对于特定领域的问题大模型会出现幻觉(瞎回答) 大模型的效果出现一些问题，需要纠正大模型的错误 改变大模型回答的风格等等需要定制，就需要大模型微调 如果大家想要进阶动手微调一下的话，可以使用下面的框架，按照格式准备好数据即可，然后一键启动，上机器开始炼丹即可！ 目前主流的微调框架： https://github.com/hiyouga/LLaMA-Factory https://github.com/unslothai/unsloth https://github.com/modelscope/ms-swift RAGRAG &#x3D; LLM + 外置数据库 ​ 备注：这部分写于2025年4月16日 用过GPT的同学可能会了解到，GPT的知识具有时效性，比如GPT-4发布时间在2023年，那么GPT-4绝对无法帮你回答2024年之后的事情；再者，你有一个本地知识库的时候，你需要大模型结合这个知识库来回答你的问题时，你可能就需要RAG了； 右边严格来说不是RAG的流程，但是广义来讲，也算RAG，llm在其中扮演的是嘴替(总结)的作用；左边这个图是标准的RAG的流程，主要包括两个部分：index(入库) 和 query(出库) 如果大家想要深入学习这一部分的话，下面是一些可以进阶的部分： 当前两个主流的RAG搭建框架(RAG企业级开发)： langchain：https://github.com/langchain-ai/langchain llamaindex：https://github.com/run-llama/llama_index 可以学习的开源项目： QAnything: https://github.com/netease-youdao/QAnything RAGflow：https://github.com/infiniflow/ragflow/blob/main/README_zh.md 关于RAG的优化：RAG技术 AgentAgent &#x3D; LLM + 外部工具 上面的RAG是LLM和外部的知识(文档，图片等)打通了一条链路，相当于在数据层面建立了联系；但是不具备数据处理的能力，而处理数据的能力，一般是API是通过API的形式来展现的；**因此当LLM能够使用外部的 工具(API), LLM的能力将得到极大的扩展 ，**不多bb，展示！！！ https://strudel.cc/ (下面Agent使用到的一个音乐工具) 如果没有耐心看完前面Agent执行步骤的话，可直接拉到2：48秒，然后看后面的即可 如果给了LLM一台可以运行的电脑(环境)，那么这就是今年3月份爆火的AI智能体 Manus 为什么要叫Agent呢，可以看下面的图(没找到比较好的图，自己画的，见谅)，我们可以将用户比作boss，llm比作员工，boss发出一个问题之后，llm去规划并完成工作，llm是具体的执行者，因此叫做代理,Agent 暂时无法在飞书文档外展示此内容 目前智能Agent产品设计一般都是按照上面的思路去进行的，规划(Plan) + 执行(ReAct模型) Agent通过上面的章节，对Agent进行了一些初步的了解，这个小节将通过代码进一步的带大家了解Agent相关的内容 Agent 李宏毅讲Agent 从上面的一些例子我们可以了解到，对于完成一个人类目标而言，Agent需要两个方面的能力，目标拆解的能力和分布执行的能力；对应的名词即plan和function call，有了分步的任务，之后，LLM Agent逐步分析，调用工具或者自身内部知识，然后将结果传给下一步的任务，如下图所示： 通过上面的方式，可以有哪些运用呢？ 用模型训练模型： 使用Agent下围棋，使用电脑，浏览网页等等！ 当然上面的例子也说明了，大模型在调用过程中，可能出现幻觉，这有可能导致任务执行的失败，比如上面的deepseek 改变了国际象棋的规则，然后赢得了AI届的国际象棋桂冠！因此对于复杂问题，选择其它方法或许更可靠。这里不再展开。 上面都提到了大模型要实现Agent，需要具备工具调用的能力，这个能力是怎么实现的呢？看图好像挺简单的一句话就说完了，其实实际呢，也挺简单的。下面通过一个Function Call的例子来简单说明一下。 Function call 调用的实例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import randomfrom datetime import datetimeimport json# step 1: 定义工具def get_current_time(): current_datetime = datetime.now() formatted_time = current_datetime.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;) return f&quot;当前时间：&#123;formatted_time&#125;。&quot;def add(arguments): a = arguments[&quot;num_1&quot;] b = arguments[&quot;num_2&quot;] return f&quot;计算的结果是：&#123;a + b&#125;&quot;# step 2: 创建tools数组tools = [ &#123; &quot;type&quot;: &quot;function&quot;, &quot;function&quot;: &#123; &quot;name&quot;: &quot;get_current_time&quot;, &quot;description&quot;: &quot;当你想知道现在的时间时非常有用。&quot;, &#125; &#125;,]tool_name = [tool[&quot;function&quot;][&quot;name&quot;] for tool in tools]# step 3：使用大模型调用函数from openai import OpenAIimport osclient = OpenAI( api_key=&quot;sk-389c222d8f304e6ba3bb10ad3589d340&quot;, base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,)messages = [ &#123; &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;你是一个很有帮助的助手。如果用户提问关于时间的问题，请调用‘get_current_time’函数。 请以友好的语气回答问题。&quot;&quot;&quot;, &#125;, &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;现在是几点？&quot; &#125;]def function_calling(): completion = client.chat.completions.create( model=&quot;qwen-max&quot;, messages=messages, tools=tools, ) res = completion.choices[0].message print(res.model_dump_json()) return completion# step4: 运行工具函数completion = function_calling()function_name = completion.choices[0].message.tool_calls[0].function.namearguments_string = completion.choices[0].message.tool_calls[0].function.arguments# 使用json模块解析参数字符串arguments = json.loads(arguments_string)# 创建一个函数映射表function_mapper = &#123; &quot;get_current_time&quot;: get_current_time, &quot;add&quot;:add&#125;# 获取函数实体function = function_mapper[function_name]# 如果入参为空，则直接调用函数if arguments == &#123;&#125;: function_output = function()# 否则，传入参数后调用函数else: function_output = function(arguments)# 打印工具的输出print(f&quot;工具函数输出：&#123;function_output&#125;\\n&quot;)## step5： 将工具输出添加到messages中，继续进行下面的步骤messages.append(completion.choices[0].message)messages.append(&#123;&quot;role&quot;: &quot;tool&quot;, &quot;content&quot;: function_output, &quot;tool_call_id&quot;: completion.choices[0].message.tool_calls[0].id&#125;)print(&quot;已添加tool message\\n&quot;)completion = function_calling() WorkFlow - 编排的Agent上面提到，对于复杂任务，完全让大模型去规划，去自由探索，可能出现很多不可预知的问题，这对于一些确定性的任务来说，是很致命的，既然这样，那么就别让大模型逞能，脚踏实地，只解决具体的单步问题，规划问题让人类来干就好了，这就是workflow，这就是截止到2025年4月20日来最主流的Agent 实现方式； MCP上面是通义千问的Function 调用方式，下次我们再添加一个新的工具的时候，是不是又要重复写一下这个流程(定义工具，定义工具描述，然后传给大模型)， 但是现在大模型这么多，大模型之间的Function Call的方式可能不相同，这里写的工具函数，换到GPT4，可能就要修改代码，这样很不符合程序员的复用规则，因此有了MCP MCP其实还是大模型选择需要调用的工具，因此MCP本质还是Function Call， 只是统一了一个标准之后，开发者通过MCP协议写的Function可以给别人复用了 如果想深入了解的话，大家可以对照着官方代码写一遍，就会发现了MCP解决的是哪一方面的问题了； A2A，ANP等等A2A：谷歌提出来的一种 Agent 和 Agent相互通信的协议， MCP协议统一了大模型与外界工具交互的方式，A2A是Agent与Agent间的，可以类比成公司里面部门，每个部门承担一部功能(如前端，后端，数据，算法，HR，财务，运维等)，然后相互协作，共同达成一个目标； ANP：国内提出的类似于A2A的，用于Agent2Agent的协议，目前是成为互联网界的http . . . . . 无论是MCP，还是A2A，抑或者是其它协议，我觉得归根到底是今年自deepseek以来，**大模型的能力得到了较大的提升，**这个生态才慢慢火起来(2024年开年火了一阵就没声音了，因为Agent有点人工智障的味道)，至于Agent有多智能，我觉得还是让子弹飞一会儿，但是在小的方面，确实会影响我们的工作效率；恰当的使用llm来协助我们工作，能做到事半功倍； 好物推荐编程工具类： Cursor (目前最好的AI代码编辑器，就是有点小贵，我使用的是VScode通义灵码插件替代) Trae (字节出品， 国产第一个有知名度的AI代码编辑器(当然，投流，广告投入很大)) 开发框架类:（还是上面那两个） langchain：https://github.com/langchain-ai/langchain llamaindex：https://github.com/run-llama/llama_index (个人常用这个，教程很友好， 但是目前langchain发展更好一些) 零代码类大模型编排工具(适合AI行业的所有人) 搞过comfyUI的同学应该知道节点编辑工具的概念，这个就是llm这边的节点编辑工具 dify : 企业级的，目前大多数工具开发AI流程应用的首选 n8n ：同上，优势在集成了很多的工具 扣子 ： 字节出品，和dify类似 举个dify的例子： 本来想演示一个使用dify搭建小影知识库问答系统的demo，但是貌似飞书文档权限比较严格&#x3D;_&#x3D;#，因此这里简单介绍一下； 以翻译的任务举个例子(目前主流翻译的流程)：通过搭积木的方式，20分钟(2分钟搭建，18分钟的提示词) 即可快速完成一个任务的搭建 另外，比较喜欢的一个功能是不同模型的对比，我觉得在验证阶段很实用 现场演示Agentcline + MCP MCP发展得如火如荼，开源社区上也有很多好玩的MCP工具了，大家可以尝试一下 想一想：大家现在看到这个热点，大家觉得是通过什么实现的？ difyima (好用的结合RAG的文档工具)","categories":[],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"},{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"}]},{"title":"RAG优化","slug":"RAG优化","date":"2025-04-21T08:10:12.000Z","updated":"2025-12-11T06:07:38.209Z","comments":true,"path":"2025/04/21/RAG优化/","permalink":"https://flippy-bird.github.io/2025/04/21/RAG%E4%BC%98%E5%8C%96/","excerpt":"","text":"1. 基本的RAG流程-Native RAG 2. RAG优化2.1 优化chunk传统的RAG在数据分块时采用的是固定分块，因为可能会破坏段落的连续性，因此这一方面可以改进 2.1.1 拼接断裂的块 将固定分块的断裂部分找到，然后拼接起来； 123456789101112131415161718192021222324252627282930313233def compute_breakpoints(similarities, method=&quot;percentile&quot;, threshold=90): &quot;&quot;&quot; Computes chunking breakpoints based on similarity drops. Args: similarities (List[float]): List of similarity scores between sentences. method (str): &#x27;percentile&#x27;, &#x27;standard_deviation&#x27;, or &#x27;interquartile&#x27;. threshold (float): Threshold value (percentile for &#x27;percentile&#x27;, std devs for &#x27;standard_deviation&#x27;). Returns: List[int]: Indices where chunk splits should occur. &quot;&quot;&quot; # Determine the threshold value based on the selected method if method == &quot;percentile&quot;: # Calculate the Xth percentile of the similarity scores threshold_value = np.percentile(similarities, threshold) elif method == &quot;standard_deviation&quot;: # Calculate the mean and standard deviation of the similarity scores mean = np.mean(similarities) std_dev = np.std(similarities) # Set the threshold value to mean minus X standard deviations threshold_value = mean - (threshold * std_dev) elif method == &quot;interquartile&quot;: # Calculate the first and third quartiles (Q1 and Q3) q1, q3 = np.percentile(similarities, [25, 75]) # Set the threshold value using the IQR rule for outliers threshold_value = q1 - 1.5 * (q3 - q1) else: # Raise an error if an invalid method is provided raise ValueError(&quot;Invalid method. Choose &#x27;percentile&#x27;, &#x27;standard_deviation&#x27;, or &#x27;interquartile&#x27;.&quot;) # Identify indices where similarity drops below the threshold value return [i for i, sim in enumerate(similarities) if sim &lt; threshold_value] 2.1.2 使用不同的分块大小 (例如原来是256， 现在试一试512， 1000等等)； 2.1.3 总结chunk chunk Embedding之后缺乏语义信息，在chunk Embedding之前 给每一个chunk添加一个meta data, 一般是对这段text的总结，如标题等(可以使用LLM来协助), 在查询时， 使用的是两个信息相似度的平均值 （这个demo） 1234567891011121314151617181920212223242526272829303132333435system_prompt = &quot;Generate a concise and informative title for the given text.&quot;# **************************** step 2 *********************************chunks = [] # Initialize an empty list to store chunks# Iterate through the text with the specified chunk size and overlapfor i in range(0, len(text), n - overlap): chunk = text[i:i + n] # Extract a chunk of text header = generate_chunk_header(chunk) # Generate a header for the chunk using LLM chunks.append(&#123;&quot;header&quot;: header, &quot;text&quot;: chunk&#125;) # Append the header and chunk to the listreturn chunks # Return the list of chunks with headers# *************************** step 3 **********************************for chunk in tqdm(text_chunks, desc=&quot;Generating embeddings&quot;): # Create an embedding for the chunk&#x27;s text text_embedding = create_embeddings(chunk[&quot;text&quot;]) # Create an embedding for the chunk&#x27;s header header_embedding = create_embeddings(chunk[&quot;header&quot;]) # Append the chunk&#x27;s header, text, and their embeddings to the list embeddings.append(&#123;&quot;header&quot;: chunk[&quot;header&quot;], &quot;text&quot;: chunk[&quot;text&quot;], &quot;embedding&quot;: text_embedding, &quot;header_embedding&quot;: header_embedding&#125;) # ****************************** step 4**************************************# Iterate through each chunk to calculate similarity scoresfor chunk in chunks: # Compute cosine similarity between query embedding and chunk text embedding sim_text = cosine_similarity(np.array(query_embedding), np.array(chunk[&quot;embedding&quot;])) # Compute cosine similarity between query embedding and chunk header embedding sim_header = cosine_similarity(np.array(query_embedding), np.array(chunk[&quot;header_embedding&quot;])) # Calculate the average similarity score avg_similarity = (sim_text + sim_header) / 2 # Append the chunk and its average similarity score to the list similarities.append((chunk, avg_similarity)) 2.1.4 提问chunk 同上，不过这里改变了方向，是从chunk中提取问题，而不是总结，换汤不换药， 注意这里的是 问题 + chunk text 向量化之后一起 进行检索，然后找出top-k 1234567891011# Define the system prompt to guide the AI&#x27;s behaviorsystem_prompt = &quot;You are an expert at generating relevant questions from text. Create concise questions that can be answered using only the provided text. Focus on key information and concepts.&quot;# Define the user prompt with the text chunk and the number of questions to generateuser_prompt = f&quot;&quot;&quot;Based on the following text, generate &#123;num_questions&#125; different questions that can be answered using only this text:&#123;text_chunk&#125;Format your response as a numbered list of questions only, with no additional text.&quot;&quot;&quot; 2.1.5 提取chunk，不采用固定chunk size Proposition Chunking 仅仅采用固定分块，问题太多，会破坏句子的语义，句子不完整时会产生歧义等, 因此这种方法是从每个chunk中提取有用的关键信息作为新的chunk (这里也是使用LLM来分句的) 主要是两步：分段 然后评估筛选出最符合的 123456789101112131415161718192021222324252627282930313233############### 产生新的chunk# System prompt to instruct the AI on how to generate propositionssystem_prompt = &quot;&quot;&quot;Please break down the following text into simple, self-contained propositions. Ensure that each proposition meets the following criteria:1. Express a Single Fact: Each proposition should state one specific fact or claim.2. Be Understandable Without Context: The proposition should be self-contained, meaning it can be understood without needing additional context.3. Use Full Names, Not Pronouns: Avoid pronouns or ambiguous references; use full entity names.4. Include Relevant Dates/Qualifiers: If applicable, include necessary dates, times, and qualifiers to make the fact precise.5. Contain One Subject-Predicate Relationship: Focus on a single subject and its corresponding action or attribute, without conjunctions or multiple clauses.Output ONLY the list of propositions without any additional text or explanations.&quot;&quot;&quot;# User prompt containing the text chunk to be converted into propositionsuser_prompt = f&quot;Text to convert into propositions:\\n\\n&#123;chunk[&#x27;text&#x27;]&#125;&quot;################# 评估新chunk的质量 (结合原始的chunk)# System prompt to instruct the AI on how to evaluate the propositionsystem_prompt = &quot;&quot;&quot;You are an expert at evaluating the quality of propositions extracted from text.Rate the given proposition on the following criteria (scale 1-10):- Accuracy: How well the proposition reflects information in the original text- Clarity: How easy it is to understand the proposition without additional context- Completeness: Whether the proposition includes necessary details (dates, qualifiers, etc.)- Conciseness: Whether the proposition is concise without losing important informationThe response must be in valid JSON format with numerical scores for each criterion:&#123;&quot;accuracy&quot;: X, &quot;clarity&quot;: X, &quot;completeness&quot;: X, &quot;conciseness&quot;: X&#125;&quot;&quot;&quot;# User prompt containing the proposition and the original textuser_prompt = f&quot;&quot;&quot;Proposition: &#123;proposition&#125; 2.2 优化处理过程2.2.1 分层RAG传统的RAG当 text很大时，chunk就很多，匹配chunk缺乏上下文，而且每一个chunk都做相似度计算，计算量大，效率低，因此分层RAG的思想是，先对每一页做一个总结，先在总结中找到相关信息，然后再在对应的页中去找相关的详细信息 1234567############## 总结的prompt# Define the system prompt to instruct the summarization modelsystem_prompt = &quot;&quot;&quot;You are an expert summarization system.Create a detailed summary of the provided text. Focus on capturing the main topics, key information, and important facts.Your summary should be comprehensive enough to understand what the page containsbut more concise than the original.&quot;&quot;&quot; 2.2.2 GraphRAG可参考：GraphRAG快速入门与原理详解 实体提取 (Node, 节点)：利用LLM进行实体的提取，这些实体通常是指文档中出现的人物、地点、组织、概念等信息。 关系提取(Edage， 边)：关系挖掘是从文本中识别出实体之间的 关系，例如：谁与谁有关联、某个实体与另一个实体之间的关系是“属于”、“合作”、“对立”等。 Community(中文翻译成社区，感觉真的很奇怪，直接使用英文就好) 构建： 感觉是为了将不同部分的信息联系起来 通过使用 图谱聚类算法（如 Leiden 算法），GraphRAG 会将不同的实体和关系分组，形成多个 社区（Community）。这些社区是根据实体之间的相似度或关系的密切程度进行划分的。这种分组帮助 GraphRAG 更好地理解不同知识领域的结构， 2.2.3 KAGhttps://github.com/OpenSPG/KAG/blob/master/README_cn.md 2.3 后处理由于固定分块会破坏句子的连续性 2.3.1 增加相邻上下文 在检索这一步时，将检索到的相邻chunk也包含进来以增加上下文，减少信息的损失 2.3.2 ReRank ReRank 就是觉得通过计算余弦相似度的方式得到的相似度具有一定的可信度，但是不高，因此使用其它方法对得到的top-k进行重排序，然后选择相关度最高的几个答案(一般使用LLM来实现) 12345678910system_prompt = &quot;&quot;&quot;You are an expert at evaluating document relevance for search queries.Your task is to rate documents on a scale from 0 to 10 based on how well they answer the given query.Guidelines:- Score 0-2: Document is completely irrelevant- Score 3-5: Document has some relevant information but doesn&#x27;t directly answer the query- Score 6-8: Document is relevant and partially answers the query- Score 9-10: Document is highly relevant and directly answers the queryYou MUST respond with ONLY a single integer score between 0 and 10. Do not include ANY other text.&quot;&quot;&quot; 也可以使用关键词的方式 1234567891011121314151617181920212223242526272829# Extract important keywords from the querykeywords = [word.lower() for word in query.split() if len(word) &gt; 3]scored_results = [] # Initialize a list to store scored resultsfor result in results: document_text = result[&quot;text&quot;].lower() # Convert document text to lowercase # Base score starts with vector similarity base_score = result[&quot;similarity&quot;] * 0.5 # Initialize keyword score keyword_score = 0 for keyword in keywords: if keyword in document_text: # Add points for each keyword found keyword_score += 0.1 # Add more points if keyword appears near the beginning first_position = document_text.find(keyword) if first_position &lt; len(document_text) / 4: # In the first quarter of the text keyword_score += 0.1 # Add points for keyword frequency frequency = document_text.count(keyword) keyword_score += min(0.05 * frequency, 0.2) # Cap at 0.2 # Calculate the final score by combining base score and keyword score final_score = base_score + keyword_score 2.3.3 增加上下文-v2 计算连续chunk (分段)的总相关性，然后输出 top-k 个分段 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def find_best_segments(chunk_values, max_segment_length=20, total_max_length=30, min_segment_value=0.2): &quot;&quot;&quot; Find the best segments using a variant of the maximum sum subarray algorithm. Args: chunk_values (List[float]): Values for each chunk max_segment_length (int): Maximum length of a single segment total_max_length (int): Maximum total length across all segments min_segment_value (float): Minimum value for a segment to be considered Returns: List[Tuple[int, int]]: List of (start, end) indices for best segments &quot;&quot;&quot; print(&quot;Finding optimal continuous text segments...&quot;) best_segments = [] segment_scores = [] total_included_chunks = 0 # Keep finding segments until we hit our limits while total_included_chunks &lt; total_max_length: best_score = min_segment_value # Minimum threshold for a segment best_segment = None # Try each possible starting position for start in range(len(chunk_values)): # Skip if this start position is already in a selected segment if any(start &gt;= s[0] and start &lt; s[1] for s in best_segments): continue # Try each possible segment length for length in range(1, min(max_segment_length, len(chunk_values) - start) + 1): end = start + length # Skip if end position is already in a selected segment if any(end &gt; s[0] and end &lt;= s[1] for s in best_segments): continue # Calculate segment value as sum of chunk values segment_value = sum(chunk_values[start:end]) # Update best segment if this one is better if segment_value &gt; best_score: best_score = segment_value best_segment = (start, end) # If we found a good segment, add it if best_segment: best_segments.append(best_segment) segment_scores.append(best_score) total_included_chunks += best_segment[1] - best_segment[0] print(f&quot;Found segment &#123;best_segment&#125; with score &#123;best_score:.4f&#125;&quot;) else: # No more good segments to find break # Sort segments by their starting position for readability best_segments = sorted(best_segments, key=lambda x: x[0]) return best_segments, segment_scores 2.3.4 使用LLM过滤无效信息 使用LLM对top-k的chunk text进行判断，过滤，然后帮助我们筛选出最符合的信息，下面是实现的三种方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445if compression_type == &quot;selective&quot;: system_prompt = &quot;&quot;&quot;You are an expert at information filtering. Your task is to analyze a document chunk and extract ONLY the sentences or paragraphs that are directly relevant to the user&#x27;s query. Remove all irrelevant content. Your output should: 1. ONLY include text that helps answer the query 2. Preserve the exact wording of relevant sentences (do not paraphrase) 3. Maintain the original order of the text 4. Include ALL relevant content, even if it seems redundant 5. EXCLUDE any text that isn&#x27;t relevant to the query Format your response as plain text with no additional comments.&quot;&quot;&quot;elif compression_type == &quot;summary&quot;: system_prompt = &quot;&quot;&quot;You are an expert at summarization. Your task is to create a concise summary of the provided chunk that focuses ONLY on information relevant to the user&#x27;s query. Your output should: 1. Be brief but comprehensive regarding query-relevant information 2. Focus exclusively on information related to the query 3. Omit irrelevant details 4. Be written in a neutral, factual tone Format your response as plain text with no additional comments.&quot;&quot;&quot;else: # extraction system_prompt = &quot;&quot;&quot;You are an expert at information extraction. Your task is to extract ONLY the exact sentences from the document chunk that contain information relevant to answering the user&#x27;s query. Your output should: 1. Include ONLY direct quotes of relevant sentences from the original text 2. Preserve the original wording (do not modify the text) 3. Include ONLY sentences that directly relate to the query 4. Separate extracted sentences with newlines 5. Do not add any commentary or additional text Format your response as plain text with no additional comments.&quot;&quot;&quot;# Define the user prompt with the query and document chunkuser_prompt = f&quot;&quot;&quot; Query: &#123;query&#125; Document Chunk: &#123;chunk&#125; Extract only the content relevant to answering this query.&quot;&quot;&quot; 2.3.5 优化检索策略- Adaptive Retrieval本质还是query的改写 RAG的效果差，也有可能是检索的策略有问题，对于所有的问题，全部采用向量相似度匹配，可能不太对，因此针对不同的用户问题，需要采取不同的策略 对查询类型进行分类: 事实、分析、观点或情境 （使用大模型来进行选择） 然后 Query Transform （根据上面的类型进行改写）, 然后和之前一样进行相似度进行匹配 12345678910# Define the system prompt to guide the AI&#x27;s classificationsystem_prompt = &quot;&quot;&quot;You are an expert at classifying questions. Classify the given query into exactly one of these categories: - Factual: Queries seeking specific, verifiable information. - Analytical: Queries requiring comprehensive analysis or explanation. - Opinion: Queries about subjective matters or seeking diverse viewpoints. - Contextual: Queries that depend on user-specific context. Return ONLY the category name, without any explanation or additional text.&quot;&quot;&quot; query 改写的部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131##################### 基于事实 Factual system_prompt = &quot;&quot;&quot;You are an expert at enhancing search queries. Your task is to reformulate the given factual query to make it more precise and specific for information retrieval. Focus on key entities and their relationships. Provide ONLY the enhanced query without any explanation.&quot;&quot;&quot;user_prompt = f&quot;Enhance this factual query: &#123;query&#125;&quot;##################### 基于事实 Factual system_prompt = &quot;&quot;&quot;You are an expert at enhancing search queries. Your task is to reformulate the given factual query to make it more precise and specific for information retrieval. Focus on key entities and their relationships. Provide ONLY the enhanced query without any explanation.&quot;&quot;&quot;user_prompt = f&quot;Enhance this factual query: &#123;query&#125;&quot;### 基于分析 Analytical # Define the system prompt to guide the AI in generating sub-questionssystem_prompt = &quot;&quot;&quot;You are an expert at breaking down complex questions.Generate sub-questions that explore different aspects of the main analytical query.These sub-questions should cover the breadth of the topic and help retrieve comprehensive information.Return a list of exactly 3 sub-questions, one per line.&quot;&quot;&quot;# Create the user prompt with the main queryuser_prompt = f&quot;Generate sub-questions for this analytical query: &#123;query&#125;&quot;################## 基于分析 Analytical # Define the system prompt to guide the AI in generating sub-questionssystem_prompt = &quot;&quot;&quot;You are an expert at breaking down complex questions.Generate sub-questions that explore different aspects of the main analytical query.These sub-questions should cover the breadth of the topic and help retrieve comprehensive information.Return a list of exactly 3 sub-questions, one per line.&quot;&quot;&quot;# Create the user prompt with the main queryuser_prompt = f&quot;Generate sub-questions for this analytical query: &#123;query&#125;&quot;################## 基于观点 Opinion Strategy # Define the system prompt to guide the AI in identifying different perspectivessystem_prompt = &quot;&quot;&quot;You are an expert at identifying different perspectives on a topic. For the given query about opinions or viewpoints, identify different perspectives that people might have on this topic. Return a list of exactly 3 different viewpoint angles, one per line.&quot;&quot;&quot;# Create the user prompt with the main queryuser_prompt = f&quot;Identify different perspectives on: &#123;query&#125;&quot;# Extract and clean the viewpointsviewpoints = response.choices[0].message.content.strip().split(&#x27;\\n&#x27;)viewpoints = [v.strip() for v in viewpoints if v.strip()]print(f&quot;Identified viewpoints: &#123;viewpoints&#125;&quot;)# Retrieve documents representing each viewpointall_results = []for viewpoint in viewpoints: # 注意这里的做法 # Combine the main query with the viewpoint combined_query = f&quot;&#123;query&#125; &#123;viewpoint&#125;&quot; # Create embeddings for the combined query viewpoint_embedding = create_embeddings(combined_query) # Perform similarity search for the combined query results = vector_store.similarity_search(viewpoint_embedding, k=2) # Mark results with the viewpoint they represent for result in results: result[&quot;viewpoint&quot;] = viewpoint # Add the results to the list of all results all_results.extend(results) ################### 基于情境 Contextual Strategyif not user_context:system_prompt = &quot;&quot;&quot;You are an expert at understanding implied context in questions.For the given query, infer what contextual information might be relevant or implied but not explicitly stated. Focus on what background would help answering this query.Return a brief description of the implied context.&quot;&quot;&quot;user_prompt = f&quot;Infer the implied context in this query: &#123;query&#125;&quot;# Generate the inferred context using the LLMresponse = client.chat.completions.create( model=&quot;meta-llama/Llama-3.2-3B-Instruct&quot;, messages=[ &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt&#125;, &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt&#125; ], temperature=0.1)# Extract and print the inferred contextuser_context = response.choices[0].message.content.strip()print(f&quot;Inferred context: &#123;user_context&#125;&quot;)# Reformulate the query to incorporate contextsystem_prompt = &quot;&quot;&quot;You are an expert at reformulating questions with context.Given a query and some contextual information, create a more specific query that incorporates the context to get more relevant information.Return ONLY the reformulated query without explanation.&quot;&quot;&quot;user_prompt = f&quot;&quot;&quot;Query: &#123;query&#125;Context: &#123;user_context&#125;Reformulate the query to incorporate this context:&quot;&quot;&quot;# Generate the contextualized query using the LLMresponse = client.chat.completions.create(model=&quot;meta-llama/Llama-3.2-3B-Instruct&quot;,messages=[ &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt&#125;, &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt&#125;],temperature=0) 2.3.6 CRAG对检索的文件进行了修正 校验检索得到的文档，如果文档相关性评分比较高(相关性分数还是使用LLM)，那么继续原先的步骤即可；如果相关性评分很低，那么采用外部的工具(如浏览器等)来搜索更多的资料，用以补充；如果相关性评分在中间，结合检索文本和搜索文本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677def crag_process(query, vector_store, k=3): print(f&quot;\\n=== Processing query with CRAG: &#123;query&#125; ===\\n&quot;) # Step 1: Create query embedding and retrieve documents print(&quot;Retrieving initial documents...&quot;) query_embedding = create_embeddings(query) retrieved_docs = vector_store.similarity_search(query_embedding, k=k) # Step 2: Evaluate document relevance print(&quot;Evaluating document relevance...&quot;) relevance_scores = [] for doc in retrieved_docs: score = evaluate_document_relevance(query, doc[&quot;text&quot;]) relevance_scores.append(score) doc[&quot;relevance&quot;] = score print(f&quot;Document scored &#123;score:.2f&#125; relevance&quot;) # Step 3: Determine action based on best relevance score max_score = max(relevance_scores) if relevance_scores else 0 best_doc_idx = relevance_scores.index(max_score) if relevance_scores else -1 # Track sources for attribution sources = [] final_knowledge = &quot;&quot; # Step 4: Execute the appropriate knowledge acquisition strategy if max_score &gt; 0.7: # Case 1: High relevance - Use document directly print(f&quot;High relevance (&#123;max_score:.2f&#125;) - Using document directly&quot;) best_doc = retrieved_docs[best_doc_idx][&quot;text&quot;] final_knowledge = best_doc sources.append(&#123; &quot;title&quot;: &quot;Document&quot;, &quot;url&quot;: &quot;&quot; &#125;) elif max_score &lt; 0.3: # Case 2: Low relevance - Use web search print(f&quot;Low relevance (&#123;max_score:.2f&#125;) - Performing web search&quot;) web_results, web_sources = perform_web_search(query) final_knowledge = refine_knowledge(web_results) sources.extend(web_sources) else: # Case 3: Medium relevance - Combine document with web search print(f&quot;Medium relevance (&#123;max_score:.2f&#125;) - Combining document with web search&quot;) best_doc = retrieved_docs[best_doc_idx][&quot;text&quot;] refined_doc = refine_knowledge(best_doc) # Get web results web_results, web_sources = perform_web_search(query) refined_web = refine_knowledge(web_results) # Combine knowledge final_knowledge = f&quot;From document:\\n&#123;refined_doc&#125;\\n\\nFrom web search:\\n&#123;refined_web&#125;&quot; # Add sources sources.append(&#123; &quot;title&quot;: &quot;Document&quot;, &quot;url&quot;: &quot;&quot; &#125;) sources.extend(web_sources) # Step 5: Generate final response print(&quot;Generating final response...&quot;) response = generate_response(query, final_knowledge, sources) # Return comprehensive results return &#123; &quot;query&quot;: query, &quot;response&quot;: response, &quot;retrieved_docs&quot;: retrieved_docs, &quot;relevance_scores&quot;: relevance_scores, &quot;max_relevance&quot;: max_score, &quot;final_knowledge&quot;: final_knowledge, &quot;sources&quot;: sources &#125; 2.4 输入部分2.4.1 Query Transform Query改写 可能是觉得用户提的问题不够具体，导致搜索的时候找到对应的信息；亦或者是用户的问题太复杂了，包含了很多层级的问题；亦或者是用户的问题太细致了，以至匹配不到相关的信息，需要对信息step back； 12345678910111213141516171819202122232425262728293031323334353637383940414243############ 1.Query Rewriting # Define the system prompt to guide the AI assistant&#x27;s behaviorsystem_prompt = &quot;You are an AI assistant specialized in improving search queries. Your task is to rewrite user queries to be more specific, detailed, and likely to retrieve relevant information.&quot;# Define the user prompt with the original query to be rewrittenuser_prompt = f&quot;&quot;&quot;Rewrite the following query to make it more specific and detailed. Include relevant terms and concepts that might help in retrieving accurate information.Original query: &#123;original_query&#125;Rewritten query:&quot;&quot;&quot;############ 2. Step-back Prompting# Define the system prompt to guide the AI assistant&#x27;s behaviorsystem_prompt = &quot;You are an AI assistant specialized in search strategies. Your task is to generate broader, more general versions of specific queries to retrieve relevant background information.&quot;# Define the user prompt with the original query to be generalizeduser_prompt = f&quot;&quot;&quot;Generate a broader, more general version of the following query that could help retrieve useful background information.Original query: &#123;original_query&#125;Step-back query:&quot;&quot;&quot;############ 3. Sub-query Decomposition# Define the system prompt to guide the AI assistant&#x27;s behaviorsystem_prompt = &quot;You are an AI assistant specialized in breaking down complex questions. Your task is to decompose complex queries into simpler sub-questions that, when answered together, address the original query.&quot;# Define the user prompt with the original query to be decomposeduser_prompt = f&quot;&quot;&quot;Break down the following complex query into &#123;num_subqueries&#125; simpler sub-queries. Each sub-query should focus on a different aspect of the original question.Original query: &#123;original_query&#125;Generate &#123;num_subqueries&#125; sub-queries, one per line, in this format:1. [First sub-query]2. [Second sub-query]And so on...&quot;&quot;&quot; 2.4.2 HyDE (Hypothetical Document Embedding) 本质上还是Query改写的一种，具体操作方法如下： 根据用户的问题，假想一个document，这个document可以解决用户的query； (这里使用的还是LLM) 然后使用这个document进行向量化和相似度的比较，继续后面的流程； 12345678910# Define the system prompt to instruct the model on how to generate the documentsystem_prompt = f&quot;&quot;&quot;You are an expert document creator. Given a question, generate a detailed document that would directly answer this question.The document should be approximately &#123;desired_length&#125; characters long and provide an in-depth, informative answer to the question. Write as if this document is from an authoritative sourceon the subject. Include specific details, facts, and explanations.Do not mention that this is a hypothetical document - just write the content directly.&quot;&quot;&quot;# Define the user prompt with the queryuser_prompt = f&quot;Question: &#123;query&#125;\\n\\nGenerate a document that fully answers this question:&quot;","categories":[],"tags":[{"name":"Rag","slug":"Rag","permalink":"https://flippy-bird.github.io/tags/Rag/"}]},{"title":"langgraph官方文档学习","slug":"langgraph官方文档学习","date":"2025-04-08T06:58:33.000Z","updated":"2025-12-23T09:55:18.885Z","comments":true,"path":"2025/04/08/langgraph官方文档学习/","permalink":"https://flippy-bird.github.io/2025/04/08/langgraph%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"顺序可能不按照官方文档的顺序，按照自己感兴趣的模块，然后通过demo 代码的方式来理解这个模块的用法 subgraph在langgraph里面，可以通过两种方式将subgraph添加到 流程中 通过工具调用的方式引入 (invoke a graph from a node) 例如下面的官方例子中，subgraph通过主流程中call_subgraph这个tools函数来触发subgraph的调用 12345678910111213141516171819202122232425262728293031from typing_extensions import TypedDictfrom langgraph.graph.state import StateGraph, STARTclass SubgraphState(TypedDict): bar: str# Subgraphdef subgraph_node_1(state: SubgraphState): return &#123;&quot;bar&quot;: &quot;hi! &quot; + state[&quot;bar&quot;]&#125;subgraph_builder = StateGraph(SubgraphState)subgraph_builder.add_node(subgraph_node_1)subgraph_builder.add_edge(START, &quot;subgraph_node_1&quot;)subgraph = subgraph_builder.compile()# Parent graphclass State(TypedDict): foo: strdef call_subgraph(state: State): # Transform the state to the subgraph state subgraph_output = subgraph.invoke(&#123;&quot;bar&quot;: state[&quot;foo&quot;]&#125;) # Transform response back to the parent state return &#123;&quot;foo&quot;: subgraph_output[&quot;bar&quot;]&#125;builder = StateGraph(State)builder.add_node(&quot;node_1&quot;, call_subgraph)builder.add_edge(START, &quot;node_1&quot;)graph = builder.compile() 直接以子节点的方式添加到流程中 12345678910111213141516171819202122from typing_extensions import TypedDictfrom langgraph.graph.state import StateGraph, STARTclass State(TypedDict): foo: str# Subgraphdef subgraph_node_1(state: State): return &#123;&quot;foo&quot;: &quot;hi! &quot; + state[&quot;foo&quot;]&#125;subgraph_builder = StateGraph(State)subgraph_builder.add_node(subgraph_node_1)subgraph_builder.add_edge(START, &quot;subgraph_node_1&quot;)subgraph = subgraph_builder.compile()# Parent graphbuilder = StateGraph(State)builder.add_node(&quot;node_1&quot;, subgraph) builder.add_edge(START, &quot;node_1&quot;)graph = builder.compile() 通过传参也可以看到，子节点的方式，subgraph共享主graph的State human in loop可学习资料1.Multi-Agent全面爆发！一文详解多智能体核心架构及LangGraph框架2.破除AI Agent自主操控风险：万字解读LangGraph“人工干预”机制 ，附零基础实战","categories":[],"tags":[{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"langgraph","slug":"langgraph","permalink":"https://flippy-bird.github.io/tags/langgraph/"}]},{"title":"GraphRAG","slug":"GraphRAG","date":"2025-03-13T02:14:50.000Z","updated":"2025-12-11T05:45:43.223Z","comments":true,"path":"2025/03/13/GraphRAG/","permalink":"https://flippy-bird.github.io/2025/03/13/GraphRAG/","excerpt":"","text":"1. why we need GraphRAG? https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/ 基本的RAG 难以建立信息关联。当回答某个问题需要遍历不同信息片段并通过其共享属性来提供新的综合见解时，就会出现这种情况。 基本RAG 在被要求整体理解大型数据集合甚至单个大型文档中的汇总语义概念时表现不佳。 我想到的一个例子是：假设我有一个介绍 LLM的文章，然后分段式介绍了LLM的一些特点(假设每一段不显式的包含LLM信息，用它，他或者其他代词指代)，然后这些信息被分别分块，然后embedding，在query (问LLM的优点， 需要根据LLM的特点来总结)，search的时候，应该就不会查到这些信息。 2. GraphRAG的原理2.1 构建阶段在建立索引(index)这一步，主要按照下面的步骤进行： 将输入语料库分割为一系列的文本单元（TextUnits），这些单元作为处理以下步骤的可分析单元，并在我们的输出中提供细粒度的引用。 使用 LLM 从文本单元中提取所有实体、关系和关键声明。并且对每个实体，关系，文本生成embedding向量 使用 Leiden 技术 对知识图谱进行层次聚类。 GraphRAG通过计算实体之间的关系，填充关系表，并生成关于实体的社区报告来总结不同实体之间的关系与上下文，自下而上地生成每个社区层级及其组成部分的摘要。这有助于对数据集的整体理解。 具体的例子可以参考这篇知乎文章的例子: GraphRAG快速入门与原理详解 2.1 查询阶段在查询这一步，又分为两种方式： 全局搜索，用于通过利用社区层级摘要来推理有关语料库的整体问题。 局部搜索，用于通过扩展到其邻居和相关概念来推理特定实体的情况。 局部搜索 有点类似BM25关键词搜索，然后找到一些相关的实体关系之后，然后再利用图谱的节点关系再在领近查找更多信息，然后再汇总 全局搜索 根据用户的问题，全局搜索会搜索相关的社区报告 ，并且给每一个社区报告打分(使用LLM来进行)，根据打分的高低，然后将最相关的社区报告给到大模型的上下文中； 3. 项目源码学习 TODO","categories":[{"name":"RAG框架学习","slug":"RAG框架学习","permalink":"https://flippy-bird.github.io/categories/RAG%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Rag","slug":"Rag","permalink":"https://flippy-bird.github.io/tags/Rag/"}]},{"title":"shader介绍","slug":"shader介绍","date":"2023-05-14T09:48:35.000Z","updated":"2025-12-11T06:07:55.272Z","comments":true,"path":"2023/05/14/shader介绍/","permalink":"https://flippy-bird.github.io/2023/05/14/shader%E4%BB%8B%E7%BB%8D/","excerpt":"shader基本用法总结","text":"shader基本用法总结 1. Shader 基本介绍首先需要认识到的一点是，shader是运行在GPU上的，天然的并行处理 我们通过编写代码(即shader），来‘点亮’下面画布中的每个像素！ 右边列出这么长的公式不是为了劝退大家，它都是由基本图形公式组合而来（后面我会给大家进行讲解），理解了就容易，但是一下子放在这里就很难理解，所以大家在写shader复合效果代码时，一定要写注释说明，不然后面优化维护的同学是真的难受😭 12345678910111213141516171819202122void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; // create 100x100 cell sheet float c = floor(100.0*(0.5+(fragCoord.x-0.5*iResolution.x)/iResolution.y)); float r = floor(100.0*(1.0-fragCoord.y/iResolution.y)); // paint flower float f = min(max(20.0+20.0*(pow(0.5+0.5*cos(5.0*atan(r-50.5,c-50.5)),0.3))-sqrt((c-50.5)*(c-50.5)+(r-50.5)*(r-50.5)),0.0),1.0); f += min(max(19.0-sqrt((c-50.5)*(c-50.5)+(r-50.5)*(r-50.5)),0.0),1.0); f -= 2.0*min(max(46.0-r,0.0),1.0)*min(max(2.0-abs(4.0-sqrt( pow(abs(r-45.0),2.0)+pow(abs(abs(c-50.5)-6.0),2.0))),0.0),1.0); f -= 2.0*min(max(r-50. 0,0.0),1.0)*min(max(2.0-abs(8.0-sqrt((c-50.5)*(c-50.5)+(r-50.5)*(r-50.5))),0.0),1.0); // colorize vec3 h = (f&lt;1.0) ? mix(vec3(0.44,0.66,0.86),vec3(1),f) : mix(vec3(1), vec3(1,0.85,0.4),f-1.0); // output fragColor = vec4(h,1.0);&#125; 1.1 how to write a shader ? 我们在哪儿作画？ https://www.shadertoy.com/new VS Code 插件shadertoy, 使用方法也比较简单 一些基本知识介绍 从哪儿开始呢？画一个三角形貌似有点难(PS：图形学中的hello world就是绘制一个三角形🔼)，那就从点亮屏幕开始吧 ！ 123456789101112131415161718192021// shader具有一些内置函数：// iResolution : 画布的精度，宽高参数// iTime : 时间参数，让效果动起来// iMouse : 鼠标操作，交互设计// 工具函数 : sin, cos, pow, mod, smoothstep, floor等 void mainImage(out vec4 fragColor, in vec2 fragCoord)&#123; // 将画布归一化到0.0到1.0之间 vec2 uv = fragCoord.xy / iResolution.xy; // 输出颜色，即对应uv下的颜色值 // r g b a fragColor = vec4(1.0, 0.0, 0.0, 1.0); // 对应图2 // fragColor = vec4(uv.x, 0.0, 0.0, 1.0); // 对应图3 // vec3 color = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4)); // fragColor = vec4(color, 1.0);&#125; ​ 图一 图二 图三 1.2 generative art1.2.1 形状 善于使用step 和smoothstep函数 ​ step 函数：一般用来作截断处理 ​ smoothstep函数：一般用来做平滑处理，smoothstep函数可以替代step函数（参数1等于参数2，或者接近时，可以理解为step函数） 123456789101112131415161718192021222324void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord/iResolution.xy; uv = uv - 0.5; vec3 color = vec3(0.7, 0.4, 0.6); if (uv.x &lt; -.3 &amp;&amp; uv.y &gt;0.1) color = vec3(0.7, 0.0, .0); if (uv.x &gt; 0.2 &amp;&amp; uv.y &lt; -0.4) color = vec3(0.0, 0.0, 0.5); if (uv.x &gt; 0.4 &amp;&amp; uv.y &gt; 0.1) color = vec3(0.0, 0.5, 0.6); float r = 0.01; color *= step(r, abs(uv.x + 0.3)); color *= step(r, abs(uv.x - 0.2)); color *= step(r, abs(uv.x - 0.4)); color *= 1.0 -(1.0 - step(r, abs(uv.x + 0.4))) * (smoothstep(0.1, 0.1, uv.y)); color *= step(r * 2., abs(uv.y - 0.1)); color *= step(r * 2., abs(uv.y - 0.3)); color *= 1.0 - (1.0 - step(r * 2., abs(uv.y + 0.4))) * smoothstep(-0.3, -0.3, uv.x); fragColor = vec4(color,1.0);&#125; ​ 参考示意图 运行代码图 SDF(符号距离场） 详细可参考文档Signed Distance Field 在这一部分，使用最频繁的函数是 length(), 其它具有同样功能的有sqrt(),distance() 这里主要是掌握距离场这种思想！！！ 123456789101112131415161718void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord.xy / iResolution.xy; // 将坐标原点移到中心 uv = uv - 0.5; // 保持原来的长宽比 uv.x *= iResolution.x / iResolution.y; vec3 color = vec3(0.5, 0.5, 0.5); // 计算当前像素到原点的距离 float d = length(uv); // 设置比较对象，这里即圆的半径 float r = 0.3; color *= smoothstep(r, r + 0.01, d); fragColor = vec4(color, 1.0);&#125; 如果没有保持长宽比的话，可能显示的是一个椭圆，因为图形被拉伸了！ 这里的smoothstep这一行可以理解为：小于r，返回0.0值，color乘以0.0等于0.0，显示黑色；大于r，则返回1.0.保持color值，既保持背景色 ​ 结果图 极坐标 ​ 这一方面主要用来生成齿轮，花瓣等沿着圆周变化的形状，因为是以角度为自变量，所以atan()函数基本上一定会用到(当我们看到别人的shader里面有atan函数时，可以往角度方向去想一下) 12345678910111213141516171819202122232425262728void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord.xy / iResolution.xy; // 将坐标原点移到中心 uv = uv - 0.5; // 保持原来的长宽比 uv.x *= iResolution.x / iResolution.y; vec3 color = vec3(0.5, 0.5, 0.5); // 计算当前像素到原点的距离 float d = length(uv); float r = 0.0; // **************** added ************* // 设置比较对象，这里添加角度的变化项 r = 0.3 + 0.1 * cos(6.0 * atan(uv.y, uv.x)); // 对应第二个图 // r = 0.3 + 0.1 * abs(cos(6.0 * atan(uv.y, uv.x))); // 对应第三个图 // r = 0.3 + 0.1 * smoothstep(-.5, 0.4, cos(8.0 * atan(uv.y, uv.x))); // **************** added ************* color *= smoothstep(r, r + 0.01, d); fragColor = vec4(color, 1.0);&#125; ​ 图一 图二 图三 1.2.2 图形的基本操作主要包括平移，旋转，缩放 旋转矩阵 注意： ​ 缩放，旋转是有参考点的，下面的两个矩阵都是针对原点进行计算的，如果不在原点，需要先平移到原点，然后进行旋转，缩放操作，然后再平移到原先的位置。 1234567891011121314151617181920212223242526272829303132333435363738394041#define PI 3.14159265359// 旋转矩阵mat2 rotate2d(float _angle)&#123; return mat2(cos(_angle),-sin(_angle), sin(_angle),cos(_angle));&#125;// 缩放矩阵mat2 scale(vec2 _scale)&#123; return mat2(_scale.x,0.0, 0.0,_scale.y);&#125; void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord.xy / iResolution.xy; // 将坐标原点移到中心 uv = uv - 0.5; // 保持原来的长宽比 uv.x *= iResolution.x / iResolution.y; // **************** added ************* // 平移 uv += (sin(iTime), cos(iTime)) * 0.2; // 旋转 // uv *= rotate2d( sin(iTime)*PI ); // 缩放 // uv *= scale( vec2(0.8 + abs(sin(iTime)) * 0.5) ); // **************** added ************* vec3 color = vec3(0.5, 0.5, 0.5); // 计算当前像素到原点的距离 float d = length(uv); float r = 0.0; r = 0.3 + 0.1 * smoothstep(-.5, 0.4, cos(8.0 * atan(uv.y, uv.x))); color *= smoothstep(r, r + 0.01, d); fragColor = vec4(color, 1.0);&#125; ​ 图一 图二 图三 1.2.3 重复，分形 重复 ​ 如果我们绘制多个相同的图案，那么可以采取下面的想法：我们的画布是归一化到0.0到1.0，如果我们将画布划分若干份，然后将每一部分的坐标重新映射到0.0到1.0，那么我们在一个画布上绘制的图案就会被同步到其它区域上，从而实现了重复图形的绘制。 123456789101112131415161718192021222324252627void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord.xy / iResolution.xy; // **************** added ************* // 实现重复部分的代码 uv = uv * 3.0; uv = fract(uv); // **************** added ************* // 将坐标原点移到中心 uv = uv - 0.5; // 保持原来的长宽比 uv.x *= iResolution.x / iResolution.y; vec3 color = vec3(0.5, 0.5, 0.5); // 计算当前像素到原点的距离 float d = length(uv); float r = 0.0; r = 0.3 + 0.1 * smoothstep(-.5, 0.4, cos(8.0 * atan(uv.y, uv.x))); color *= smoothstep(r, r + 0.01, d); fragColor = vec4(color, 1.0);&#125; 分形 主要用于模拟树木，山脉，树叶等等具有自相似的物体 12345678910111213141516171819202122 vec2 complex_sqr(vec2 pos)&#123; return vec2(pow(pos.x, 2.0) - pow(pos.y, 2.0), pos.x * pos.y * 2.0);&#125;void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord/iResolution.xy; vec2 c = vec2(-0.8, cos(iTime) * 0.2); vec2 z = vec2(uv.x * 2.0 - 1.0, uv.y - 0.5) * 2.0; float iterations = 0.0; while (length(z) &lt; 20. &amp;&amp; iterations &lt; 50.) &#123; z = complex_sqr(z) + c; iterations += 1.; &#125; vec3 col = vec3(1. - iterations * 0.02); fragColor = vec4(col,1.0);&#125; 1.1.4 随机​ 通过上面的一些方法，我们可以生成一些规则的图形，如齿轮，花瓣等等；规则代表着一种美，数学之美，而无序则代表着自由，有无限的想象空间，比如天上的云朵，跳动的火苗，海平面溅起的浪花等，这些自然之物无法用数学公式来把它们限制在一个方程式之下。那只能用魔法去打败魔法了，是随机去模拟大自然的随机，noise就是这门艺术。 shader noise 1.3 image1.3.1 贴图这个比较简单，就是将现有的图片 导入到 我们的画布中，使用函数texture2D即可 12345678910111213// 导入你的图片，下面的路径是我的文件路径#iChannel0 &#x27;file://pictures/46.jpg&#x27;void main()&#123; vec2 uv = gl_FragCoord.xy / iResolution.xy; // 对你的纹理进行采样，获取对应像素处的颜色 vec4 color = texture2D(iChannel0, uv); // 输出到屏幕，即为原图 gl_FragColor = color;&#125; ​ 原图 运行代码图 1.3.2 玩转图片 图片转场 说到图片，大家最先想到的特效是啥？我首先想到的是各种转场 https://gl-transitions.com/gallery 12345678910111213141516171819#iChannel0 &#x27;file://pictures/1.png&#x27;#iChannel1 &#x27;file://pictures/46.jpg&#x27;float SQRT_2 = 1.414213562373;float dots = 20.0;vec2 center = vec2(0, 0);vec4 transition(vec2 uv) &#123; bool nextImage = distance(fract(uv * dots), vec2(0.5, 0.5)) &lt; ( fract(iTime * 0.4) / distance(uv, center)); return nextImage ? texture2D(iChannel0, uv) : texture2D(iChannel1, uv);&#125;void main()&#123; vec2 uv = gl_FragCoord.xy / iResolution.xy; vec4 color = vec4(0.0); color = transition(uv); gl_FragColor = color;&#125; 制作精灵动画 ​ 这一部分是为了说明，对于一幅图片，我们可以只选择其中一部分进行采样；(ps: 文字渲染的一种方式是将所有文字信息离屏渲染到一张纹理上，使用时去查找对应的部分进行渲染） 1234567891011121314151617181920212223242526272829303132#iChannel0 &#x27;file://pictures/1.png&#x27;int col = 5;int row = 4;void main() &#123; vec2 uv = gl_FragCoord.xy / iResolution.xy; vec4 color = vec4(0.0); vec2 fRes = iResolution.xy / vec2(float(col), float(row)); vec2 nRes = iResolution.xy / fRes; uv = uv / nRes; float timeX = iTime * 1.5; float timeY = floor(timeX / float(col)); vec2 offset = vec2 (floor(timeX) / nRes.x, 1. - (floor(timeY) / nRes.y)); uv = fract(uv + offset); color = texture2D(iChannel0, uv); gl_FragColor = color; // 进阶：第三个是抖音上比较火的网格分割图片，配合音乐的卡点 // 来显示图片，从而产生比较有趣的效果 // 我们可以基于此的思想 来将我们的众多图片按照不同时间 // 绘制到画布上形成动画！！！ &#125; ​ 原图 运行代码图 抖音特效 1.3.3 图片操作 反转图片 ​ 下面这个图片看起来好像有点阴间的感觉，反转操作可用于通道中颜色较小的值反转成较大的值，然后用于处理，或者相反，是一种数据处理的思想（类似于将数据重新映射，类比于笛卡尔坐标到极坐标，或者从极坐标映射到笛卡尔坐标系），常用的颜色处理还有颜色空间的转换，如RGB颜色空间转换到HSV颜色空间，都是利用了这种思想 123456789101112131415// 导入你的图片，下面的路径是我的文件路径#iChannel0 &#x27;file://pictures/46.jpg&#x27;void main()&#123; vec2 uv = gl_FragCoord.xy / iResolution.xy; // 注意这里，这里我只取rgb通道的颜色，因为a通道不用反转 vec3 color = texture2D(iChannel0, uv).rgb; // 进行反转的操作 color = 1.0 - color; gl_FragColor = vec4(color, 1.0);&#125; ​ 原图 效果图 图片灰度化 ​ 记住这个数字 035911， 即0.3， 0.59， 0.11 (大概是这个比例，有的是0.299, 0.587, 0.114 或者其它，都是按照这个基准进行灰度化的，PS软件的灰度图就是按照这个比例进行灰度化的） 12345678910111213141516// 导入你的图片，下面的路径是我的文件路径#iChannel0 &#x27;file://pictures/46.jpg&#x27;void main()&#123; vec2 uv = gl_FragCoord.xy / iResolution.xy; // 注意这里，这里我只取rgb通道的颜色，因为a通道不用反转 vec3 color = texture2D(iChannel0, uv).rgb; // 进行灰度的处理 float grey = color.r * 0.3 + color.g * 0.59 + color.b * 0.11; color = vec3(grey); gl_FragColor = vec4(color, 1.0);&#125; ​ 原图 效果图 颜色的加减乘除 ​ 这一块对应于AE 或者PS中的 叠加方式，有Add, Substract, Multiply, Average, Difference等等，因为这一块没有发现比较好玩的效果，暂时不深入，一般常用的就是Add方式就可，即colorA + colorB的方式。 1.3.4 卷积，算子 模糊操作 主要用到的是**高斯模糊，**其它的还有均值模糊，径向模糊等等，各有各的用途，按照需求选择合适即可。 高品质后处理：十种图像模糊算法的总结与实现 边缘检测 ​ 边缘的表现形式如下图：通常是通过寻找图像的梯度来检测边界，有两种代表算法，sobel算子（基于一阶导数的）和laplacian算子（基于二阶导数）。 sobel 算子 对于不连续的函数，一阶导数可以写作： 或 所以有： 假设要处理的图像为I，在两个方向求导： 水平变化： 垂直变化： 结合以上两个结果求出： 统计极大值所在的位置，就是图像的边缘。 12345678910111213141516171819202122232425262728293031323334353637383940414243#iChannel0 &#x27;file://pictures/pixel.png&#x27;void mainImage( out vec4 fragColor, in vec2 fragCoord )&#123; vec2 uv = fragCoord.xy / iResolution.xy; vec3 col; /*** Sobel kernels ***/ // Note: GLSL&#x27;s mat3 is COLUMN-major -&gt; mat3[col][row] mat3 sobelX = mat3(-1.0, -2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0); mat3 sobelY = mat3(-1.0, 0.0, 1.0, -2.0, 0.0, 2.0, -1.0, 0.0, 1.0); float sumX = 0.0; // x-axis change float sumY = 0.0; // y-axis change for(int i = -1; i &lt;= 1; i++) &#123; for(int j = -1; j &lt;= 1; j++) &#123; // texture coordinates should be between 0.0 and 1.0 float x = (fragCoord.x + float(i))/iResolution.x; float y = (fragCoord.y + float(j))/iResolution.y; // Convolve kernels with image sumX += length(texture( iChannel0, vec2(x, y) ).xyz) * float(sobelX[1+i][1+j]); sumY += length(texture( iChannel0, vec2(x, y) ).xyz) * float(sobelY[1+i][1+j]); &#125; &#125; float g = abs(sumX) + abs(sumY); //g = sqrt((sumX*sumX) + (sumY*sumY)); if(g &gt; 1.0) col = vec3(1.0,1.0,1.0); else col = col * 0.0; fragColor.xyz = col;&#125; ​ 原图 运行算法图 2.laplacian算子 对于不连续函数的二阶导数是： 因此使用的卷积核是： 2. Shader 和 AI2.1 特效相关 瘦脸特效，大眼特效，头部晃动特效等等 ​ 这里会使用AI的方法提取人物的关键点，如下图中的左右太阳穴的关键点，下巴的关键点，人体头部的关键点等等，然后再加上图像处理的方法，就会产生很多有趣的效果！！！ 背景特效 ​ 这里就会用到AI中的人像分割技术，将人物抠出来，然后背景部分将其灰度化，人物部分保留原始的颜色即可。 2.2 DLSS ​ DLSS 2.0 - 重新定义AI渲染 ​ DLSS简单来说就是我们使用传统的图形学方法渲染一帧低清晰度的图片，然后使用AI的方法将其“复原”成高分辨率的图片，即图片的高清修复。因为在真实感方面，光线追踪技术渲染的真实感很好，但是在高分辨率下，计算量爆炸；有了DLSS后，我们可以使用光线追踪技术渲染低分辨率的图片，然后使用AI进行高清修复。 参考资料 浅谈生成艺术 the book of shaders shadertoy iq大神博客 https://www.shadertoy.com/view/Ms2SD1","categories":[{"name":"shader","slug":"shader","permalink":"https://flippy-bird.github.io/categories/shader/"}],"tags":[{"name":"shader","slug":"shader","permalink":"https://flippy-bird.github.io/tags/shader/"}]},{"title":"AR的前世今生","slug":"AR的前世今生","date":"2022-09-27T07:58:23.000Z","updated":"2025-12-11T05:45:30.591Z","comments":true,"path":"2022/09/27/AR的前世今生/","permalink":"https://flippy-bird.github.io/2022/09/27/AR%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/","excerpt":"","text":"1.概念区分什么是AR&#x2F;VR&#x2F;MR&#x2F;XR? 在前段时间，元宇宙大火的时候，你应该听过或者见过上面的几个词语。什么？元宇宙都没有听过，建议食用下面的资料了解一下,也是蛮有意思的东西。 聊聊这个本不存在的“元宇宙” 啥？全是文字，没事，那就看个视频吧，你也可以简单了解一下这篇文章的主题AR是个什么东西！ 2021年了，AR眼镜可以做什么？ AR 对现实的一种增强，设备对现实识别（形状、位置、动作、边缘）,从而将虚拟信息叠加在现实中。 VR 为用户提供一个虚拟的世界，不必考虑现实世界，是一种沉浸式的体验。如果喜欢看动漫的，**动漫《刀剑神域》里描述就是这样一个世界(PS: 我感觉这就是当前阶段元宇宙的最终形态)；在电影《头号玩家》**中，里面塑造的绿洲也是这样的一个虚拟世界。 MR 虚拟世界和现实世界的混合。 AR、VR、MR统称XR。VR的发展相较于AR的发展，更为成熟一些，有很多VR面对用户的产品，例如Pico 4，这段时间发布了它的新产品。在这里，我们主要聊一聊AR相关的内容。 2.AR历史发展及现状1992年波音公司研究员提出了AR这个概念，自此AR诞生了。 2.1 AR序幕的开启把时间拉回10年前的2012年，在一个慈善晚宴上，谷歌联合创始人谢尔盖·布林为了展示一把谷歌的技术实力，就把尚在原型阶段的谷歌智能眼镜Google Glass掏了出来，众人直呼“卧槽”，随后便引起了大众的广泛讨论和关注。正当大家做着钢铁侠梦的时候，也遇到了视频中小何同学遇到的各种使用问题；虽然Google Glasss更多意义上只是一个“戴在脸上的手机”，很多AR领域涉及的技术，受限于当时的技术和算力，诸如环境检测，用户交互技术等并不涉及，但是其展现的前景还是值得大家期待的。因此，可以说，Google Glass拉起了AR快速发展的序幕。 2.2 AR的持续发展 AR界的第一代黑科技 自从谷歌将Google Glass引入大众的视野，旁边的微软可坐不住了，论技术，咱可没输过谁，就算打不过，那不是最后还可以加入嘛。况且，你的那个Google Glass也太垃圾了吧，这么重，还这么贵，也就是你是第一人，否则不会有那么多人买账，让我来教教你怎么制作一个好的产品吧，是时候展现真正的技术了。于是，在2015年的时候，微软发布了Hololens，震惊了世界，它能检测外界环境，将虚拟物体和显示环境融合，并且它通过追踪用户手势来完成交互。HoloLens2 是真正意义上的第一款相对成熟的AR设备，它的出现，引领了AR的潮流，成为了业界的标杆和对比的对象。 2019年，微软发布了HoloLens2，解决了视野狭小的问题，并且大幅度提升了手势追踪的准确性。虽然HoloLens2 虽然相对成熟，但是成本居高不下，**官方指导建议零售价是3500美元。**另外，虽然它相对体积较小，但仍重达500g, 已知iPhone 12重152g, 请问你的头上戴了几台iPhone 12 🤣 AR界的第一代黑”概念” 凭借着下面这“一条在体育馆地板跃起的大鲸鱼”，Magic Leap 成功塑造了一个 AR 黑科技公司的形象，以及足够激动人心的未来——从移动计算迁移到空间计算。裸眼AR的概念太具有震撼力，致使Magic Leap在视频发布的短短三个月内，迅速获得16亿美元融资，最高估值达64亿美元。然而巧妇难为无米之炊，在关键技术上没有取得核心突破的Magic Leap在2017年推出的Magic Leap one，其表现与其吹牛的效果差得太离谱，消费者纷纷给出了差评，这也给这家公司贴上了“骗子”的标签。 在上面的视频被人戳破，是视频后期合成之后，这家公司在AR界没有惊起任何浪花，就在写这篇文稿的当天，我在其官网上发现，Magic Leap将发布Magic Leap 2，这回他能否力挽狂澜，拯救自己“骗子”的形象，还得看过硬的产品！ 国内AR的发展 国内的AR公司主要有酷派的Xview系列、亮亮视野、影目科技等，要说目前最火的，当属Nreal， 在今年的8月23日，Nreal推出了新品Nreal Air和Nreal X两款AR眼镜；发布首日，Nreal销售额突破了1200万。 在9月21日，国内最早成立的AR企业之一亮亮视野发布了一款量产的AR字幕眼镜，也是全球第一款重量小于80g的双目波导无线一体机AR眼镜：听语者。主打听障者沟通。 国内的AR产业也在快速发展中，苹果老早就说2022年要发布AR眼镜，从年头等到了年尾，毛都没有；或许，我们可以把目光转向国内，期待国内的厂商能够发布一款改变世界的产品，就像当时iphone的出现一样。 2.3 移动端AR比较流行的SDK目前移动端AR SDK有很多，下面列出一些比较有影响力的SDK 苹果的ARKit ： 2017年发布至今，被认为是性能最强，最具商业潜力的sdk。 谷歌的ARCore ： 同时支持Android 和iOS, 是Android比较常用的sdk，综合实力比不上ARKit 历史悠久的 ARToolKit： 第一个AR SDK，但是目前开源社区不是太活跃 商业化sdk Vuforia： 性能表现很不错，支持Android、iOS 2.4 发展现状目前AR技术还有很多痛点，主要集中在以下几个方面： 检测环境的计算量很大，实时性不好，例如当你拿着设备快速移动时，虚拟物体和现实物体的融合就会出现飘移的现象 因为计算量大和频繁使用摄像头，耗电发热； 穿戴式AR 显示技术不成熟，大部分设备在清晰度、视野、体验性上都有些不足 软件生态不成熟 3.AR领域的关键技术3.1 探知环境的技术（自我定位、检测3D物体、环境建模） 没错，听到这些词语，很自然想到了自动驾驶里面也会有这样一个环节，就是”理解“环境的技术。 一般来说，建立环境地图需要经历以下的流程： 用户抵达一个新场所，开启摄像头。 设备根据陀螺仪等传感器确定自己的高度、朝向，并以此为空间坐标系原点。 识别用户摄像头输入，进行“点阵云”建模。 用户到处移动，直至整个地图被扫描建模完成。 3.2 显示技术AR的另一个关键技术就是显示技术，主要分为三类： 视觉差显示技术 全息投影技术 光影成像技术 3.3 交互技术目前为止，除了传统的触摸，按键、语音等技术，AR大致有3个方向的虚拟交互技术： 动作捕捉： 主要是手部动捕捉，目前Hololens2在这一块上技术积累最雄厚，不需要任何外设，直接通过手势就可以流畅操控设备。 眼动追踪： 使用摄像头捕捉人眼或脸部的图像，然后用算法实现人脸和人眼的检测、定位与跟踪，从而估算用户的视线变化。 脑机接口： 通过识别大脑活动电信号来操控设备，马斯克旗下的Neuralink公司通过向大脑植入十分之一发丝粗细的神经线，来检测和传输大脑的信号。 4.结语​ 20年前，当人们使用QICQ打着字，和天南海北的陌生人分享彼此的故事时，不会想到，今天我们一张图片，一个个表情包，一段视频，便可以轻松地将我们的故事分享给陌生人。20年前，我们省吃俭用抠抠搜搜计算着我们的2G流量，发个消息还老转圈圈，到今天，4G已悄然开启了全民直播时代，而5G也已在全面布局。 ​ 或许像电影《头号玩家》里面的元宇宙场景还需要很长一段路要走，但至少我觉得AR、VR技术将会在不久的将来带给我们全新的体验，就让我们且走，且看，且体验吧！","categories":[],"tags":[{"name":"元宇宙","slug":"元宇宙","permalink":"https://flippy-bird.github.io/tags/%E5%85%83%E5%AE%87%E5%AE%99/"},{"name":"AR","slug":"AR","permalink":"https://flippy-bird.github.io/tags/AR/"}]},{"title":"数据对齐问题","slug":"数据对齐问题","date":"2021-11-17T14:59:59.000Z","updated":"2025-12-11T05:45:07.464Z","comments":true,"path":"2021/11/17/数据对齐问题/","permalink":"https://flippy-bird.github.io/2021/11/17/%E6%95%B0%E6%8D%AE%E5%AF%B9%E9%BD%90%E9%97%AE%E9%A2%98/","excerpt":"数据对齐问题","text":"数据对齐问题 现象我在使用OpenGL加载一个图片数据时,其中数据的宽高不是2的n次方，导致了解析的出来的图片出现了问题，如下图： 我加载纹理数据的代码如下： Solution 像数据在内存中很少以紧密包装的形式存在，在很多硬件平台上，出于性能考虑，图像的每一行应该都从某个特定对齐地址开始。在默认情况下，OpenGL采用4个字节的对齐方式。例如，有一张RGB图像，包含3个分量，每个分量占1个字节，如果图像宽度为199像素，那么每一行需要的字节数为597字节。但是如果硬件的体系结构是以4字节排列，那么图像的每一行末尾都会填充额外的3个空字节，从而使得每一行的内存地址偏移量为4的整数倍。尽管这样表面上看起来是浪费了内存空间，但是这种排列能够让大多数CPU更高效的获取数据块。另外许多未经压缩的图形格式也遵循这种惯例，如Windows中的.BMP文件。Targa(.TGA)是以1字节排列的。 在向OpenGL提交图像数据或从OpenGL中获取图像数据时，OpenGL需要知道对数据以何种方式包装和解包装操作。通过函数void glPixelStorei (GLenum pname, GLint param)，glPixelStoref (GLenum pname, GLfloat param)可以改变或者恢复像素的存储方式。例如需要改成紧密包装方式(即像素行的对齐方式，可选1.2.4.8)调用函数glPixelStorei(GL_UNPACK_ALIGNMENT, 1)。其参数都是以GL_UNPACK_和GL_PACK_为前缀方式成对出现，前着表示从内存中读取数据(对函数glReadPixels产生影响)，后者表示存储数据至内存中(对调用函数glTexImage2D等产生影响)。 OpenGL 数据处理(下) 解决这个问题的方法是在创建纹理的时候将纹理设置为1字节对齐即可，如下，即可解决问题： 1glPixelStorei(GL_UNPACK_ALIGNMENT, 1) // 这里的GL_UNPACK_ALIGNMENT是指上传数据 当我们要从fbo读取数据的时候，可能也存在这样的问题，同理，我们在读取纹理的时候设置下面的参数即可 1glPixelStorei(GL_PACK_ALIGNMENT, 1)","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"}]},{"title":"纹理贴图预乘问题","slug":"纹理贴图的预乘问题","date":"2021-11-17T14:59:59.000Z","updated":"2025-12-11T05:45:11.647Z","comments":true,"path":"2021/11/17/纹理贴图的预乘问题/","permalink":"https://flippy-bird.github.io/2021/11/17/%E7%BA%B9%E7%90%86%E8%B4%B4%E5%9B%BE%E7%9A%84%E9%A2%84%E4%B9%98%E9%97%AE%E9%A2%98/","excerpt":"纹理贴图预乘问题","text":"纹理贴图预乘问题 现象在一次opengl纹理贴图贴PNG图片的过程中，我遇到了下面的问题，结果如下图： ​ 可以发现，贴图的边界存在一些白色的点，非常影响最后的效果。一开始，我以为是没有开mimmap的原因，因为我发现我使用的贴图的精度很高(2560 * 2560),但是并不是，我已经开启mimmap，仍然有白点的存在。我想了很久，一直以为是锯齿或者其它原因，各种RenderDoc，matlab实验，仍没有解决问题，后面在矿哥的帮助下，一秒解决了问题，真大神呀。 Solution出现上面的问题不是锯齿的问题，而是alpha blend的问题，上面那张wolf图像的精度是2560 * 2560，进行贴图时会进行缩放，这时会产生一些问题，具体的文章解释见下面的文章解释 Alpha Blending: To Pre or Not To Pre [图片Alpha预乘的作用] 具体的处理代码 预乘之后问题就解决了，结果如下：","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"}]},{"title":"花屏问题(精度不够导致)","slug":"花屏问题(精度不够导致)","date":"2021-11-17T14:59:59.000Z","updated":"2025-12-11T05:45:01.592Z","comments":true,"path":"2021/11/17/花屏问题(精度不够导致)/","permalink":"https://flippy-bird.github.io/2021/11/17/%E8%8A%B1%E5%B1%8F%E9%97%AE%E9%A2%98(%E7%B2%BE%E5%BA%A6%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4)/","excerpt":"花屏问题","text":"花屏问题 现象 我在使用stbi_image去将一个图片数据转化为纹理图片，我的代码如下： 这里我一开始写的是char,结果输出图片的数据全是0，因为使用char,发生了数据的上溢，变成了0； 至于上面的那个花屏现象，是由于精度不够导致的。 Solution刚开始时，我写的是255(下图标记处），结果就出现了花屏的现象 改成255.0之后显示就正常了","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"}]},{"title":"RenderDoc使用","slug":"RenderDoc使用","date":"2021-11-17T14:54:16.000Z","updated":"2025-12-11T06:07:44.303Z","comments":true,"path":"2021/11/17/RenderDoc使用/","permalink":"https://flippy-bird.github.io/2021/11/17/RenderDoc%E4%BD%BF%E7%94%A8/","excerpt":"RenderDoc使用","text":"RenderDoc使用 绝对路径使用RenderDoc调试程序时，程序中涉及到的一些相对路径，可能读取不到，导致无法正常运行程序，因此需要改成绝对路径，如下： 包括读取图片时，那些路径也要设置为绝对路径 RenderDoc设置环境变量 有些程序可能会需要命令行的参数才能执行，并且可能会依赖一些动态库，如图，按照上图进行设置即可","categories":[{"name":"工具使用","slug":"工具使用","permalink":"https://flippy-bird.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"RenderDoc","slug":"RenderDoc","permalink":"https://flippy-bird.github.io/tags/RenderDoc/"}]},{"title":"颜色格式问题","slug":"颜色格式问题","date":"2021-11-17T14:49:59.000Z","updated":"2025-12-11T05:45:16.045Z","comments":true,"path":"2021/11/17/颜色格式问题/","permalink":"https://flippy-bird.github.io/2021/11/17/%E9%A2%9C%E8%89%B2%E6%A0%BC%E5%BC%8F%E9%97%AE%E9%A2%98/","excerpt":"颜色格式问题","text":"颜色格式问题 这个问题可能相对比较简单，但是这里需要注意的重点是，当发生颜色问题时，可以在这一方面想一想，会不会是颜色的顺序不对导致的，是RGBA，还是BRGA，亦或是YUV420等等，这些都会导致最后渲染出来的颜色不对，就像我之前在Metal中的遇到的颜色问题，可能就是这个原因导致的(见下面链接) 输出纹理为YUV和RGB 下面这张图片是截取于OpenGL的纹理采取那部分的代码，注意图片的格式为jpg，然后读取图片的格式为RGB 但是下面这张截图中，我需要加载的图片数据的格式是png，是4通道的（调试时可以从nrChannels参数看出），所以正确的方法如下： 如果格式没有注意的话，就会出现读取的数据不正确的情况","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/tags/OpenGL/"}]},{"title":"导入dll问题","slug":"导入dll问题","date":"2021-11-17T14:46:59.000Z","updated":"2025-12-11T05:44:58.580Z","comments":true,"path":"2021/11/17/导入dll问题/","permalink":"https://flippy-bird.github.io/2021/11/17/%E5%AF%BC%E5%85%A5dll%E9%97%AE%E9%A2%98/","excerpt":"导入dll问题","text":"导入dll问题 问题我在AE中导入dll时，导入失败，但是我确实加载了所有的dll库 Solution问题出在我加载的dll也有依赖关系，所以需要按照顺序来加载dll库如下 导入ffmpeg的dll时，在AE中一定要按照上面的顺序进行导入，因为后面的库会依赖前面的库，我之前在这里卡了很久，我当时想着逐个导入，然而我选择的第一个是avformat,这个库会依赖avutil，avcodec，因此代码运行到这儿的时候就会崩掉。 其它1.在解决dll相关问题时，可以使用depends软件查看库依赖，很好用 2.可以使用vs的一些命令行工具查看dll的架构，64 or 32","categories":[{"name":"C++","slug":"C","permalink":"https://flippy-bird.github.io/categories/C/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"}]},{"title":"Metal渲染到纹理","slug":"Metal渲染到纹理","date":"2021-09-04T05:54:42.000Z","updated":"2025-12-11T06:07:14.993Z","comments":true,"path":"2021/09/04/Metal渲染到纹理/","permalink":"https://flippy-bird.github.io/2021/09/04/Metal%E6%B8%B2%E6%9F%93%E5%88%B0%E7%BA%B9%E7%90%86/","excerpt":"渲染到纹理","text":"渲染到纹理 滤镜链 Metal - 5 滤镜链（渲染到纹理） Metal的标准坐标系NDC、帧缓存坐标系FrameBuffer Coordinate (也叫Viewport Coorninate)以及纹理坐标系（Texture Coordinate)的原点不一致，还会分别对他们进行介绍和解析。 在Metal中要渲染到纹理有如下步骤： 1.创建空纹理123456789101112+ (nullable id&lt;MTLTexture&gt;)createEmptyTexture: (id&lt;MTLDevice&gt;)device WithWidth: (size_t)width withHeight: (size_t)height usage: (MTLTextureUsage)usage &#123; MTLTextureDescriptor *texDescriptor = [MTLTextureDescriptor texture2DDescriptorWithPixelFormat: MTLPixelFormatRGBA8Unorm width: width height: height mipmapped: false]; texDescriptor.usage = usage; id&lt;MTLTexture&gt; texture = [device newTextureWithDescriptor: texDescriptor]; return texture;&#125; usage 纹理的用处，是 MTLTextureUsage 枚举，有如下枚举值： MTLTextureUsageUnknown 未知用处（运行时设置），会损耗性能 MTLTextureUsageShaderRead 该纹理将被读取 MTLTextureUsageShaderWrite 该纹理将被写入 MTLTextureUsageRenderTarget 该纹理将作为渲染目标 MTLTextureUsagePixelFormatView 在 PixelFormatView 被使用（暂不介绍） 回到 demo 中，这个中间 buffer 是 当次渲染的渲染目标 ，也将 作为下一次渲染的输入被读取（采样），因此 usage 是 MTLTextureUsageShaderRead | MTLTextureUsageRenderTarget。 完整调用： 1234_grayResultTexutre = [MetalUtils createEmptyTexture: _device WithWidth: CGImageGetWidth(cgImage) withHeight: CGImageGetHeight(cgImage) usage: MTLTextureUsageShaderRead | MTLTextureUsageRenderTarget]; 2.空纹理关联到渲染目标以往为了要将渲染结果展示，我们的渲染目标是与 Layer 关联起来的： 1RenderTargetDesc.colorAttachments[0].texture = currentDrawable.texture; 但是这次我们需要渲染到纹理上，因此要把 渲染目标和要渲染到的纹理 关联起来： 1_grayRenderTargetDesc.colorAttachments[0].texture = _grayResultTexutre; 3.提交指令，执行渲染指令是被 ”装“ 到 Encoder 上的，因此渲染过程也大同小异，但是由于 不需要展示渲染结果（即不需要上屏 swap buffer），所以不需要 presentDrawable。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647- (void)render_gray &#123; // 将本次 Command Encoder 和 渲染的目标（MTLTexture）关联起来 _grayRenderTargetDesc.colorAttachments[0].texture = _grayResultTexutre; id&lt;MTLCommandBuffer&gt; commandBuffer = [_queue commandBuffer]; commandBuffer.label = @&quot;Gray Command Buffer&quot;; id&lt;MTLRenderCommandEncoder&gt; encoder = [commandBuffer renderCommandEncoderWithDescriptor: _grayRenderTargetDesc]; encoder.label = @&quot;Gray Command Encoder&quot;; [encoder setViewport: (MTLViewport) &#123; .originX = 0, .originY = 0, .width = _sourceTexutre.width, .height = _sourceTexutre.height, .znear = 0, .zfar = 1 &#125;]; [encoder setRenderPipelineState: _grayRenderPipelineState]; [encoder setVertexBytes: grayVertices length: sizeof(grayVertices) atIndex: 0]; [encoder setVertexBytes: texCoor length: sizeof(texCoor) atIndex: 1]; [encoder setFragmentTexture: _sourceTexutre atIndex: 0]; [encoder setFragmentBytes: &amp;_grayIntensity length: sizeof(float) atIndex: 0]; [encoder drawIndexedPrimitives: MTLPrimitiveTypeTriangleStrip indexCount: 6 indexType: MTLIndexTypeUInt32 indexBuffer: _indexBuffer indexBufferOffset: 0]; [encoder endEncoding]; [commandBuffer commit];&#125; 注意，Command Buffer 并不需要 presentDrawable:。","categories":[{"name":"iOS新手村","slug":"iOS新手村","permalink":"https://flippy-bird.github.io/categories/iOS%E6%96%B0%E6%89%8B%E6%9D%91/"}],"tags":[{"name":"Metal","slug":"Metal","permalink":"https://flippy-bird.github.io/tags/Metal/"}]},{"title":"Metal中加载MTLLibrary","slug":"Metal中加载MTLLibrary","date":"2021-09-04T05:54:16.000Z","updated":"2025-12-11T06:07:23.772Z","comments":true,"path":"2021/09/04/Metal中加载MTLLibrary/","permalink":"https://flippy-bird.github.io/2021/09/04/Metal%E4%B8%AD%E5%8A%A0%E8%BD%BDMTLLibrary/","excerpt":"Metal 中加载MTLLibrary","text":"Metal 中加载MTLLibrary 一般情形下，我们加载MTLLibrary会使用如下代码： 1id&lt;MTLLibrary&gt; defaultLibrary = [self.mtkView.device newDefaultLibrary] 确实这样是正确的，没有问题的，但是如果我们是开发一个静态库，.Metal 文件放置在你的静态库工程文件中，在测试时使用上面的函数就会找不到这个Metal文件，当然，你把Metal文件复制到你的开发工程中，可以正常运行，但是这样的话，Metal文件就暴露出来了，而且我们给其他人提供静态库时，不可能顺带还把Metal文件给他，因此需要换一种方法加载Metal文件 在苹果的官方论坛上，提供了一种方法一种方法 123NSError *error = nil;NSString *libPath = [[NSBundle mainBundle] pathForResource:@&quot;MySecretMetalLib&quot; ofType:@&quot;metallib&quot;];id&lt;MTLLibrary&gt; library = [device newLibraryWithFile:libPath error:&amp;error]; 当然，如果我们查看device创建library的方法文档的话，也会找到下面的方法，即将metal文件转化成字符串，然后传入，类似于OpenGL中传入shader文件。方法如下： 1id&lt;MTLLibrary&gt; defaultLibrary = [m_metalRendererDevice newLibraryWithSource:shaderSource options: nil error:nil]; 对应的shaderSource文件为： 当然我们也可以手动添加双引号将Metal文件转化为字符串，但是个人觉得太麻烦了，然后就学习了别人的这种字符串化写法，当然如果是C++的话，可以直接使用R();当然，开始的时候还遇到了其它问题，注意到上面图中的红色部分，一开始，我没有添加，后面添加了就可以正常读取Metal文件中后面的函数了。 另外，字符串化里面好像不能添加如下的引用（不太确定，但是我的metal文件确实没有编译成功，可能和metal文件的编译方式有关系，先记录在这儿吧，后面解决坑了再回来填坑。 1#import &quot;ShaderTypes.h&quot; //直接将结构体写进字符串里面就行，","categories":[{"name":"iOS新手村","slug":"iOS新手村","permalink":"https://flippy-bird.github.io/categories/iOS%E6%96%B0%E6%89%8B%E6%9D%91/"}],"tags":[{"name":"Metal","slug":"Metal","permalink":"https://flippy-bird.github.io/tags/Metal/"}]},{"title":"输出纹理为YUV和RGB","slug":"输出纹理为YUV和RGB","date":"2021-09-04T05:53:23.000Z","updated":"2025-12-11T05:45:04.530Z","comments":true,"path":"2021/09/04/输出纹理为YUV和RGB/","permalink":"https://flippy-bird.github.io/2021/09/04/%E8%BE%93%E5%87%BA%E7%BA%B9%E7%90%86%E4%B8%BAYUV%E5%92%8CRGB/","excerpt":"输出纹理为YUV 和RGB","text":"输出纹理为YUV 和RGB 写这篇博客，是因为我在使用OpenGL ES渲染从视频获取的纹理时(使用YUV的方式)，出现了颜色偏差的问题，但是我仔细看了我的代码，采样坐标，参数设置等都没有问题，然后我也学习了别人的相关代码，发现使用的方式都是一样的，因此被这个问题卡主了，于是只好换一种方式了，因此借鉴了下面这篇文章的设置方法，将视频输出数据直接设置为RGB，解决了颜色偏差的问题 AVPlayer初体验之视频解纹理 1.YUV纹理由于视频的编码格式基本都是YUV420，然后苹果的demo代码中通过AVPlayerItemVideoOutput获取Y-Pannel和 UV-Pannel 两张纹理，最后在Shader中对两种纹理组合处理。 设置AVPlayerItemVideoOutput的部分代码 12NSDictionary *pixBuffAttributes = @&#123;(id)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange)&#125;;self.videoOutput = [[AVPlayerItemVideoOutput alloc] initWithPixelBufferAttributes:pixBuffAttributes]; 输出纹理的部分代码 123456//Y-PlaneglActiveTexture(GL_TEXTURE0);err = CVOpenGLESTextureCacheCreateTextureFromImage(kCFAllocatorDefault, _videoTextureCache, pixelBuffer, NULL, GL_TEXTURE_2D, GL_RED_EXT, frameWidth, frameHeight, GL_RED_EXT, GL_UNSIGNED_BYTE, 0, &amp;_lumaTexture);//UV-planeglActiveTexture(GL_TEXTURE1);err = CVOpenGLESTextureCacheCreateTextureFromImage(kCFAllocatorDefault, _videoTextureCache, pixelBuffer, NULL, GL_TEXTURE_2D, GL_RG_EXT, frameWidth / 2, frameHeight / 2, GL_RG_EXT, GL_UNSIGNED_BYTE, 1, &amp;_chromaTexture); 其中的kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange是CoreVideo中指定的Pixel Format Identifiers 类型，在OpenGLES2环境下其对应的参数是GL_RED_EXT和GL_RG_EXT。 2.RGB纹理首先要明白一点，上图中明确说明，BGRA的输出格式是420v的两倍多带宽(More than 2x bandwidth)，并且在该图来源,WWDC的这个视频的27:00位置明确说明420v的输出格式效率会明显高于BGRA的输出格式(It does come across if you can avoid using BGRA and doing your work in YUV, it’s more efficient from bandwidth standpoint),但是反过来，对于OpenGL来说，两张纹理的性能又会低于一张纹理。而且直接使用使用BGRA毕竟会方便很多，因为输出的直接就是一张纹理。但是现在毕竟都iOS11时代了，所以影响可以忽略不计。 设置AVPlayerItemVideoOutput的代码 12NSDictionary *pixBuffAttributes = @&#123;(id)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_32BGRA)&#125;;self.videoOutput = [[AVPlayerItemVideoOutput alloc] initWithPixelBufferAttributes:pixBuffAttributes]; 输出纹理的代码 1CVReturn textureRet = CVOpenGLESTextureCacheCreateTextureFromImage(kCFAllocatorDefault, self.videoTextureCache, pixelBuffer, nil, GL_TEXTURE_2D, GL_RGBA, width, height, GL_BGRA, GL_UNSIGNED_BYTE, 0, &amp;_textureOutput); BGRA对应的输出格式是kCVPixelFormatType_32BGRA,其对应的从Buffer读纹理的参数是GL_RGBA和GL_BGRA。 2021.9.3 后面想了一下，我是输出到一个CALayer上的，CALayer上也有默认的颜色显示方式，应该是这一项不匹配导致的，因为当时的bug是颜色偏蓝，偏红(我试着改变了输出的RGB值时出现的现象)，可能是这个原因，因为当时没有考虑到这一点，后面如果遇到类似问题，试着查一下显示Layer的显示方式。","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"}]},{"title":"shader noise","slug":"shader-noise","date":"2021-09-04T05:00:34.000Z","updated":"2025-12-11T06:07:49.804Z","comments":true,"path":"2021/09/04/shader-noise/","permalink":"https://flippy-bird.github.io/2021/09/04/shader-noise/","excerpt":"Noise噪声","text":"Noise噪声 什么是噪声噪声 &#x3D; 随机 + 连续 在图形学中，我们使用噪声就是为了把一些随机变量来引入到程序中。从程序角度来说，噪声很好理解，我们希望给定一个输入，程序可以给出一个输出： 123value_type noise(value_type p) &#123; //简单理解为程序语言中的random即可 ...&#125; 它的输入和输出类型的维数可以是不同的组合，例如输入二维输出一维，输入二维输出二维等。我们今天就是想讨论一下上面函数中的实现部分是长什么样的。 噪声的分类根据wiki，由程序产生噪声的方法大致可以分为两类： Perlin噪声、Simplex噪声和Value噪声在性能上大致满足：Perlin噪声(O(2^n)) &lt; Value噪声&lt; Simplex噪声(O(n^2))，Simplex噪声性能最好,效果也最好。 Perlin Noise实现概括来说，Perlin噪声的实现需要三个步骤： 定义一个晶格结构，每个晶格的顶点有一个“伪随机”的梯度向量（其实就是个向量啦）。对于二维的Perlin噪声来说，晶格结构就是一个平面网格，三维的就是一个立方体网格。 输入一个点（二维的话就是二维坐标，三维就是三维坐标，n维的就是n个坐标），我们找到和它相邻的那些晶格顶点（二维下有4个，三维下有8个，n维下有2的n次方个），计算该点到各个晶格顶点的距离向量，再分别与顶点上的梯度向量做点乘，得到2的n次方个点乘结果。 使用缓和曲线（ease curves）来计算它们的权重和。在原始的Perlin噪声实现中，缓和曲线是s(t)&#x3D;3t^2−2t^3，在2002年的论文6中，Perlin改进为s(t)&#x3D;6t^5−15t^4+10t^3，这里简单解释一下，为什么不直接使用s(t)&#x3D;t，即线性插值。直接使用的线性插值的话，它的一阶导在晶格顶点处（即t &#x3D; 0或t &#x3D; 1）不为0，会造成明显的不连续性。s(t)&#x3D;3t^2−2t^3，在一阶导满足连续性，s(t)&#x3D;6t^5−15t^4+10t^3，在二阶导上仍然满足连续性。我们可以用下面的图来表示上面的第一步和第二步： Perlin噪声的实现主要代码如下： 1234567891011121314151617181920vec2 hash22(vec2 p)&#123; p = vec2( dot(p,vec2(127.1,311.7)), dot(p,vec2(269.5,183.3))); return -1.0 + 2.0 * fract(sin(p)*43758.5453123);&#125;float perlin_noise(vec2 p)&#123; vec2 pi = floor(p); vec2 pf = p - pi; vec2 w = pf * pf * (3.0 - 2.0 * pf); return mix(mix(dot(hash22(pi + vec2(0.0, 0.0)), pf - vec2(0.0, 0.0)), dot(hash22(pi + vec2(1.0, 0.0)), pf - vec2(1.0, 0.0)), w.x), mix(dot(hash22(pi + vec2(0.0, 1.0)), pf - vec2(0.0, 1.0)), dot(hash22(pi + vec2(1.0, 1.0)), pf - vec2(1.0, 1.0)), w.x), w.y);&#125; 这里的实现实际是简化版的，我们在算梯度的时候直接取随机值，而没有归一化到单位圆内。 Value Noise它把原来的梯度替换成了一个简单的伪随机值，我们也不需要进行点乘操作，而直接把晶格顶点处的随机值按权重相加即可。如下图，即只需要将蓝色矩形中四个顶点的随机值按权重相加。 实现和Perlin噪声一样，它也是一种基于晶格的噪声，也需要三个步骤： 定义一个晶格结构，每个晶格的顶点有一个“伪随机”的值（Value）。对于二维的Value噪声来说，晶格结构就是一个平面网格，三维的就是一个立方体网格。 输入一个点（二维的话就是二维坐标，三维就是三维坐标，n维的就是n个坐标），我们找到和它相邻的那些晶格顶点（二维下有4个，三维下有8个，n维下有2 个），得到这些顶点的伪随机值。 使用缓和曲线（ease curves）来计算它们的权重和。同样，缓和曲线可以是s(t) &#x3D; 3t^2 - 2t^2,也可以是s(t)&#x3D;6t^5−15t^4+10t^3（如果二阶导不连续对效果影响较大时）。 Value噪声比Perlin噪声的实现更加简单，并且需要的乘法和加法操作也更少，它只需要得到晶格顶点的随机值再把它们按权重相加即可。 主要代码1234567891011float value_noise(vec2 p)&#123; vec2 pi = floor(p); vec2 pf = p - pi; vec2 w = pf * pf * (3.0 - 2.0 * pf); return mix(mix(hash21(pi + vec2(0.0, 0.0)), hash21(pi + vec2(1.0, 0.0)), w.x), mix(hash21(pi + vec2(0.0, 1.0)), hash21(pi + vec2(1.0, 1.0)), w.x), w.y);&#125; Simplex NoiseSimplex噪声的计算复杂度为O(n^2^)，优于Perlin噪声的O(2n)。而且在效果上，Simplex噪声也克服了经典的Perlin噪声在某些视觉问题。 实现 和perlin实现的区别是将上面的矩形换成了一个三角形，所以现在存在一个问题：如何找到上面图形的三个顶点，解决方案如下图： 将等边三角形倾斜即可转化为矩形，找到顶点后，再做逆向操作即可。 主要代码1234567891011121314151617float simplex_noise(vec2 p)&#123; const float K1 = 0.366025404; // (sqrt(3)-1)/2; const float K2 = 0.211324865; // (3-sqrt(3))/6; vec2 i = floor(p + (p.x + p.y) * K1); vec2 a = p - (i - (i.x + i.y) * K2); vec2 o = (a.x &lt; a.y) ? vec2(0.0, 1.0) : vec2(1.0, 0.0); vec2 b = a - o + K2; vec2 c = a - 1.0 + 2.0 * K2; vec3 h = max(0.5 - vec3(dot(a, a), dot(b, b), dot(c, c)), 0.0); vec3 n = h * h * h * h * vec3(dot(a, hash22(i)), dot(b, hash22(i + o)), dot(c, hash22(i + 1.0))); return dot(vec3(70.0, 70.0, 70.0), n);&#125; Wavelet Noise当使用一个3D噪声去绘制2D纹理表面时，容易出现走样和细节丢失的情形 Wavelet Noise正是为了解决这个问题 实现 主要经过了4个步骤： 产生一个噪声图R 降采样 上采样 将原图减去上采样的纹理图得到结果图 Worley NoiseWorley噪声属于一种细胞噪声，就是噪声值是由随机的特征点向外扩散，最终看起来像是有一个个晶胞一样的效果。也叫网格噪声，是基于距离场 这种细胞噪声可以应用于模拟皮革，水面等等。（Worley噪声是Voronoi噪声的改进版） 实现把空间分割成网格（cells），每个网格对应一个特征点。另外，为避免网格交界区域的偏差，我们需要计算像素点到相邻网格中的特征点的距离。这就是 Steven Worley 的论文中的主要思想。最后，每个像素点只需要计算到九个特征点的距离：他所在的网格的特征点和相邻的八个网格的特征点。 示例代码12345678910111213141516171819202122232425262728293031323334353637383940vec2 r(vec2 n)&#123; return vec2(r(n.x*23.62-300.0+n.y*34.35),r(n.x*45.13+256.0+n.y*38.89)); &#125;float Worley2D(vec2 n,float s)&#123; n /= s; float dis = 1.0; for(int x = -1;x&lt;=1;x++) &#123; for(int y = -1;y&lt;=1;y++) &#123; vec2 p = floor(n)+vec2(x,y); p = r(p)+vec2(x,y)-fract(n); dis = min(dis, dot(p, p)); &#125; &#125; return 1.0 - sqrt(dis); &#125;float WorleyFBM(vec2 uv)&#123; float amplitude = 0.5; float gain = 0.5; float lacunarity = 2.0; float value = 0.0; const int STEPS = 4; for(int i = 0; i &lt; STEPS; i++) &#123; value += Worley2D(uv, 2.0) * amplitude; amplitude *= gain; uv *= lacunarity; &#125; return value;&#125; FBM单独一个Perlin噪声虽然也有一定用处，但是效果往往很无趣。因此，Perlin指出可以使用不同的函数组合来得到更有意思的结果，这些函数组合通常就是指通过分形叠加（fractal sum）。 fbm 分形噪声 noise的叠加公式如下：$$noise(p) + 1&#x2F;2 noise(2P) + 1&#x2F;4 noise(4p) + …$$ 12345678910111213//fbm 叠加分形噪声float noise_sum(vec2 p)&#123; float f = 0.0; p = p * 4.0; f += 1.0000 * noise(p); p = 2.0 * p; f += 0.5000 * noise(p); p = 2.0 * p; f += 0.2500 * noise(p); p = 2.0 * p; f += 0.1250 * noise(p); p = 2.0 * p; f += 0.0625 * noise(p); p = 2.0 * p; return f;&#125; 上面叠加了5层，并把初始化采样距离设置为4，这都是可以自定义的。这种噪声可以用来模拟石头、山脉这类物体。 对噪声返回值进行了取绝对值操作。它使用的公式如下： $$|noise(p)| + 1&#x2F;2|noise(2p)| + 1&#x2F;4|noise(4p)|+….$$ 它对应的代码如下： 123456789101112float noise_sum_abs(vec2 p)&#123; float f = 0.0; p = p * 7.0; f += 1.0000 * abs(noise(p)); p = 2.0 * p; f += 0.5000 * abs(noise(p)); p = 2.0 * p; f += 0.2500 * abs(noise(p)); p = 2.0 * p; f += 0.1250 * abs(noise(p)); p = 2.0 * p; f += 0.0625 * abs(noise(p)); p = 2.0 * p; return f;&#125; 由于进行了绝对值操作，因此会在0值变化处出现不连续性，形成一些尖锐的效果。通过合适的颜色叠加，**我们可以用这种噪声来模拟火焰、云朵这些物体。**Perlin把这个公式称为turbulence（湍流？），因为它看起来挺像的。 在之前turbulnece公式的基础上使用了一个关于表面x分量的正选函数： $$sin(x+|noise(p) + 1&#x2F;2|noise(2p)+ 1&#x2F;4|noise(4p)|+…)$$ 这个公式可以让表面沿着x方向形成一个条纹状的结构。Perlin使用这个公式模拟了一些大理石材质。我们的代码如下： 12345678910111213float noise_sum_abs_sin(vec2 p)&#123; float f = 0.0; p = p * 7.0; f += 1.0000 * abs(noise(p)); p = 2.0 * p; f += 0.5000 * abs(noise(p)); p = 2.0 * p; f += 0.2500 * abs(noise(p)); p = 2.0 * p; f += 0.1250 * abs(noise(p)); p = 2.0 * p; f += 0.0625 * abs(noise(p)); p = 2.0 * p; f = sin(f + p.x/32.0); return f;&#125; 多层叠加，每层noise添加位移和旋转 中级Shader教程07 熔岩Lava 通过FBM构造基本形态，在FBM添加点变化：1.每一层的移动速度不一样 2.每层的旋转不一样 相关代码 1234567891011121314float fbm ( in vec2 _st) &#123; float v = 0.0; float a = 0.5; vec2 shift = vec2(100.0); // Rotate to reduce axial bias mat2 rot = mat2(cos(0.5), sin(0.5), -sin(0.5), cos(0.50)); for (int i = 0; i &lt; NUM_OCTAVES; ++i) &#123; v += a * noise(_st); _st = rot * _st * 2.0 + shift; //***********************************注意这里乘以了一个矩阵，并且加上了一个偏移量 a *= 0.5; &#125; return v;&#125; 域翘曲 [domain warping - 2002] f(p) &#x3D; fbm( p + fbm( p + fbm( p ) ) ) 可平埔的噪声目前公认比较好的一种做法，就是在2n维上生成n维可平铺的噪声。 这种方法是思想是，由于我们想要每个维度都是无缝的，也就是当该维度的值从0变成1的过程中，0和1之间比较是平滑过渡的，这让我们想起了“圆”，绕圆一周就是对该维度的采样过程，这样就可以保证无缝了。因此，对于二维噪声中的x轴，我们会在四维空间下的xz平面上的一个圆上进行采样，而二维噪声的y轴，则会在四维空间下的yw平面上的一个圆上进行采样。这个转化过程很简单，我们只需要使用三角函数sin和cos即可把二维采样坐标转化到单位圆上。同样，三维空间的也是类似的，我们会在六维空间下计算。这种方法不仅适用于Perlin噪声，像Worley噪声这种也同样是适合的。 【图形学】谈谈噪声 Curl Noise 图形学中常见噪声生成算法综述 noise 的应用 How to Use Perlin Noise in Your Games Perlin noise can be used to blend between two textures, as shown in following. You should use Perlin noise with very high contrast to prevent textures from looking fuzzy. The following code snippet shows how to blend two images using Perlin noise. 云 使用噪音模拟云的效果 2D动态云彩 生成云的shadertoy代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970const float cloudscale = 1.1;const float speed = 0.03;const float clouddark = 0.5;const float cloudlight = 0.3;const float cloudcover = 0.2;const float cloudalpha = 8.0;const float skytint = 0.5;const vec3 skycolour1 = vec3(0.2, 0.4, 0.6);const vec3 skycolour2 = vec3(0.4, 0.7, 1.0);const mat2 m = mat2( 1.6, 1.2, -1.2, 1.6 );vec2 hash( vec2 p ) &#123; p = vec2(dot(p,vec2(127.1,311.7)), dot(p,vec2(269.5,183.3))); return -1.0 + 2.0*fract(sin(p)*43758.5453123);&#125;float noise( in vec2 p ) &#123; const float K1 = 0.366025404; // (sqrt(3)-1)/2; const float K2 = 0.211324865; // (3-sqrt(3))/6; vec2 i = floor(p + (p.x+p.y)*K1); vec2 a = p - i + (i.x+i.y)*K2; vec2 o = (a.x&gt;a.y) ? vec2(1.0,0.0) : vec2(0.0,1.0); //vec2 of = 0.5 + 0.5*vec2(sign(a.x-a.y), sign(a.y-a.x)); vec2 b = a - o + K2; vec2 c = a - 1.0 + 2.0*K2; vec3 h = max(0.5-vec3(dot(a,a), dot(b,b), dot(c,c) ), 0.0 ); vec3 n = h*h*h*h*vec3( dot(a,hash(i+0.0)), dot(b,hash(i+o)), dot(c,hash(i+1.0))); return dot(n, vec3(70.0)); &#125;float fbm(vec2 n) &#123; float total = 0.0, amplitude = 0.1; for (int i = 0; i &lt; 7; i++) &#123; total += noise(n) * amplitude; n = m * n; amplitude *= 0.4; &#125; return total;&#125;// -----------------------------------------------void mainImage( out vec4 fragColor, in vec2 fragCoord ) &#123; vec2 p = fragCoord.xy / iResolution.xy; vec2 uv = p*vec2(iResolution.x/iResolution.y,1.0); float time = iTime * speed; float q = fbm(uv * cloudscale * 0.5); //ridged noise shape float r = 0.0; //noise shape float f = 0.0; // uv = p*vec2(iResolution.x/iResolution.y,1.0); uv *= cloudscale; uv -= q - time; float weight = 0.7; for (int i=0; i&lt;8; i++)&#123; f += weight*noise( uv ); uv = m*uv + time; weight *= 0.6; &#125; f *= r + f; vec3 skycolour = mix(skycolour2, skycolour1, p.y); vec3 cloudcolour = vec3(1.1, 1.1, 0.9) * clouddark; f = cloudcover + cloudalpha*f; vec3 result = mix(skycolour, clamp(skytint * skycolour + cloudcolour, 0.0, 1.0), clamp(f, 0.0, 1.0)); fragColor = vec4( result, 1.0 );&#125; 运行上述代码的效果如下图： 山脉使用噪声作为高度图 水面使用噪声纹理作为高度图，不断修改水面的法线方向，使用和时间相关的变量对噪声纹理采样，得到水流动的效果； 其它noise的其它应用如生成细胞形态，皮革纹理，烟雾，大理石，布料，道路等，基本思想都是基于噪声贴图，使用噪声图作为基本纹理进行处理，如color mapping，height mapping, normal mapping等 noise 的相关库 libnoise 参考资料 WebGL进阶——走进图形噪声 2.https://www.shadertoy.com/view/ldscWj 3.【图形学】谈谈噪声 使用笔、和代码”生成“火焰 5.[一篇文章搞懂柏林噪声算法] 6.几种常见的程序化噪声纹理 7.Unity Shader - Noise 噪点图 - 实现简单山脉 8.Real-Time Procedural Effects 9.图形学中常见噪声生成算法综述 10.如何使用噪声生成复杂的纹理？","categories":[{"name":"算法","slug":"算法","permalink":"https://flippy-bird.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"shader","slug":"shader","permalink":"https://flippy-bird.github.io/tags/shader/"}]},{"title":"C++基础","slug":"C-基础","date":"2021-08-22T03:38:59.000Z","updated":"2025-12-11T05:45:36.907Z","comments":true,"path":"2021/08/22/C-基础/","permalink":"https://flippy-bird.github.io/2021/08/22/C-%E5%9F%BA%E7%A1%80/","excerpt":"C++那些事","text":"C++那些事 const那些事const含义常类型是指使用类型修饰符const说明的类型，常类型的变量或对象的值是不能被更新的。 const作用1.可以定义常量 2.类型检查 3.防止修改，起保护作用，增加程序健壮性 4.可以节省空间，避免不必要的内存分配 const对象默认为文件局部变量 注意：非const变量默认为extern。要使const变量能够在其它文件中访问，必须在文件中显示地指定它为extern。 未被const修饰的变量在不同文件的访问 12345678910111213// file1.cppint ext //**********************************这里没有extern// file2.cpp#include&lt;iostream&gt;/** * by 光城 * compile: g++ -o file file2.cpp file1.cpp * execute: ./file */extern int ext;int main()&#123; std::cout&lt;&lt;(ext+10)&lt;&lt;std::endl;&#125; const常量在不同文件的访问 12345678910111213//extern_file1.cppextern const int ext=12; //********************************这里加了extern//extern_file2.cpp#include&lt;iostream&gt;/** * by 光城 * compile: g++ -o file const_file2.cpp const_file1.cpp * execute: ./file */extern const int ext;int main()&#123; std::cout&lt;&lt;ext&lt;&lt;std::endl;&#125; *小结：可以发现未被const修饰的变量不需要extern显式声明！而const常量需要显式声明extern，并且需要做初始化！因为常量在定义后就不能被修改，所以定义时必须初始化。* 指针和const与指针相关的const有四种： 1234const char * a; //指向const对象的指针或者说指向常量的指针。char const * a; //同上char * const a; //指向类型对象的const指针。或者说常指针、const指针。const char * const a; //指向const对象的const指针。 小结：如果const位于*的左侧，则const就是用来修饰指针所指向的变量，即指针指向为常量；如果const位于*的右侧，const就是修饰指针本身，即指针本身是常量。 1.指向常量的指针 另外一个重点是：允许把非const对象的地址赋给指向const对象的指针。 将非const对象的地址赋给const对象的指针: 123const int *ptr;int val = 3;ptr = &amp;val; //ok 小结：对于指向常量的指针，不能通过指针来修改对象的值。也不能使用void*指针保存const对象的地址，必须使用const void*类型的指针保存const对象的地址。允许把非const对象的地址赋值给const对象的指针，如果要修改指针所指向的对象值，必须通过其他方式修改，不能直接通过当前指针直接修改。 2.常指针 **const指针必须进行初始化，**且const指针的值不能修改。 12345678910#include&lt;iostream&gt;using namespace std;int main()&#123; int num=0; int * const ptr=&amp;num; //const指针必须初始化！且const指针的值不能修改 int * t = &amp;num; *t = 1; cout&lt;&lt;*ptr&lt;&lt;endl;&#125; static那些事当与不同类型一起使用时，Static关键字具有不同的含义。我们可以使用static关键字： 1.静态变量：函数中的变量，类中的变量 2.静态类的成员：类对象和类中的函数 静态变量 函数中的静态变量 当变量声明为static时，空间将在程序的生命周期内分配。即使多次调用该函数，静态变量的空间也只分配一次，前一次调用中的变量值通过下一次函数调用传递。这对于在C &#x2F; C ++或需要存储先前函数状态的任何其他应用程序非常有用。 12345678910111213141516171819202122#include &lt;iostream&gt; #include &lt;string&gt; using namespace std; void demo() &#123; // static variable static int count = 0; cout &lt;&lt; count &lt;&lt; &quot; &quot;; // value is updated and // will be carried to next // function calls count++; &#125; int main() &#123; for (int i=0; i&lt;5; i++) demo(); return 0; &#125; 输出为： 10 1 2 3 4 类中的静态变量 由于声明为static的变量只被初始化一次，因为它们在单独的静态存储中分配了空间，因此类中的静态变量**由对象共享。**对于不同的对象，不能有相同静态变量的多个副本。也是因为这个原因，静态变量不能使用构造函数初始化。 类中的静态变量应由用户使用类外的类名和范围解析运算符显式初始化，如下所示： 12345678910111213141516171819202122#include&lt;iostream&gt; using namespace std; class Apple &#123; public: static int i; Apple() &#123; // Do nothing &#125;; &#125;; int Apple::i = 1; //******************************************在这里进行初始化int main() &#123; Apple obj; // prints value of i cout &lt;&lt; obj.i; &#125; 静态成员 类对象为静态 就像变量一样，对象也在声明为static时具有范围，直到程序的生命周期。 类中的静态函数 就像类中的静态数据成员或静态变量一样，静态成员函数也不依赖于类的对象。***我们被允许使用对象和’.’来调用静态成员函数。***但建议使用类名和范围解析运算符调用静态成员。 允许静态成员函数仅访问静态数据成员或其他静态成员函数，它们无法访问类的非静态数据成员或成员函数。 this指针那些事this指针的用处 一个对象的this指针并不是对象本身的一部分，不会影响sizeof(对象)的结果。 this作用域是在类内部，当在类的非静态成员函数中访问类的非静态成员的时候，编译器会自动将对象本身的地址作为一个隐含参数传递给函数。也就是说，**即使你没有写上this指针，编译器在编译的时候也是加上this的，**它作为非静态成员函数的隐含形参，对各成员的访问均通过this进行。 this指针的使用 在类的非静态成员函数中返回类对象本身的时候，直接使用 return *this。 当参数与成员变量名相同时，如this-&gt;n &#x3D; n （不能写成n &#x3D; n)。 123456789101112class Person&#123; int get_age() const&#123; //*****************************注意这里的const和总结里的解析 return this-&gt;age; &#125; Person&amp; add_age(int a)&#123; age+=a; return *this; &#125; &#125; 总结： this在成员函数的开始执行前构造，在成员的执行结束后清除。上述的get_age函数会被解析成get_age(const A * const this),add_age函数会被解析成add_age(A* const this,int a)。在C++中类和结构是只有一个区别的：类的成员默认是private，而结构是public。this是类的指针，如果换成结构，那this就是结构的指针了。 inline那些事类中内联头文件中声明方法 1234567891011121314151617class A&#123;public: void f1(int x); /** * @brief 类中定义了的函数是隐式内联函数,声明要想成为内联函数，必须在实现处(定义处)加inline关键字。 * * @param x * @param y */ void Foo(int x,int y) ///&lt; 定义即隐式内联函数！ //***********************这里 &#123; &#125;; void f1(int x); ///&lt; 声明后，要想成为内联函数，必须在定义处加inline关键字。 //***********************这里 &#125;; 实现文件中定义内联函数： inline要起作用,inline要与函数定义放在一起,inline是一种“用于实现的关键字,而不是用于声明的关键字” 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &quot;inline.h&quot;using namespace std;/** * @brief inline要起作用,inline要与函数定义放在一起,inline是一种“用于实现的关键字,而不是用于声明的关键字” * * @param x * @param y * * @return */int Foo(int x,int y); // 函数声明inline int Foo(int x,int y) // 函数定义&#123; return x+y;&#125;// 定义处加inline关键字，推荐这种写法！inline void A::f1(int x)&#123;&#125;int main()&#123; cout&lt;&lt;Foo(1,2)&lt;&lt;endl;&#125;/** * 编译器对 inline 函数的处理步骤 * 将 inline 函数体复制到 inline 函数调用点处； * 为所用 inline 函数中的局部变量分配内存空间； * 将 inline 函数的的输入参数和返回值映射到调用方法的局部变量空间中； * 如果 inline 函数有多个返回点，将其转变为 inline 函数代码块末尾的分支（使用 GOTO）。 */ 内联能提高函数效率，但并不是所有的函数都定义成内联函数！内联是以代码膨胀(复制)为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。 以下情况不适合用内联： 如果函数体内的代码比较长，使得内联将导致内存消耗代价比较高。 如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。 虚函数(virtual)可以是内联函数吗？ 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt; using namespace std;class Base&#123;public: inline virtual void who() &#123; cout &lt;&lt; &quot;I am Base\\n&quot;; &#125; virtual ~Base() &#123;&#125;&#125;;class Derived : public Base&#123;public: inline void who() // 不写inline时隐式内联 &#123; cout &lt;&lt; &quot;I am Derived\\n&quot;; &#125;&#125;;int main()&#123; // 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，编译期间就能确定了，所以它可以是内联的，但最终是否内联取决于编译器。 Base b; b.who(); // 此处的虚函数是通过指针调用的，呈现多态性，需要在运行时期间才能确定，所以不能为内联。 Base *ptr = new Derived(); ptr-&gt;who(); // 因为Base有虚析构函数（virtual ~Base() &#123;&#125;），所以 delete 时，会先调用派生类（Derived）析构函数，再调用基类（Base）析构函数，防止内存泄漏。 delete ptr; ptr = nullptr; system(&quot;pause&quot;); return 0;&#125; sizeof 那些事 空类的大小为1字节 一个类中，虚函数本身、成员函数（包括静态与非静态）和静态数据成员都是不占用类对象的存储空间。 对于包含虚函数的类，不管有多少个虚函数，只有一个虚指针,vptr的大小。 普通继承，派生类继承了所有基类的函数与成员，要按照字节对齐来计算大小 虚函数继承，不管是单继承还是多继承，都是继承了基类的vptr。(32位操作系统4字节，64位操作系统 8字节)！ 虚继承,继承基类的vptr。 原则1空类的大小为1字节 123456789101112131415/** * @file blackclass.cpp * @brief 空类的大小为1字节 * @author 光城 * @version v1 * @date 2019-07-21 */#include&lt;iostream&gt;using namespace std;class A&#123;&#125;;int main()&#123; cout&lt;&lt;sizeof(A)&lt;&lt;endl; return 0;&#125; 原则2静态数据成员被编译器放在程序的一个global data members中，它是类的一个数据成员，但不影响类的大小。 12345678910111213141516171819202122232425262728/** * @file static.cpp * @brief 静态数据成员 * 静态数据成员被编译器放在程序的一个global data members中，它是类的一个数据成员，但不影响类的大小。不管这个类产生了多少个实例，还是派生了多少新的类，静态数据成员只有一个实例。静态数据成员，一旦被声明，就已经存在。 * @author 光城 * @version v1 * @date 2019-07-21 */#include&lt;iostream&gt;using namespace std;class A&#123; public: char b; virtual void fun() &#123;&#125;; static int c; static int d; static int f;&#125;;int main()&#123; /** * @brief 16 字节对齐、静态变量不影响类的大小、vptr指针=8 */ cout&lt;&lt;sizeof(A)&lt;&lt;endl; return 0;&#125; 原则3对于包含虚函数的类，不管有多少个虚函数，只有一个虚指针,vptr的大小。 1234567891011121314151617181920/** * @file morevir.cpp * @brief 对于包含虚函数的类，不管有多少个虚函数，只有一个虚指针,vptr的大小。 * @author 光城 * @version v1 * @date 2019-07-21 */#include&lt;iostream&gt;using namespace std;class A&#123; virtual void fun(); virtual void fun1(); virtual void fun2(); virtual void fun3();&#125;;int main()&#123; cout&lt;&lt;sizeof(A)&lt;&lt;endl; // 8 return 0;&#125; 原则4和51234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @file geninhe.cpp * @brief 1.普通单继承,继承就是基类+派生类自身的大小(注意字节对齐) * 注意：类的数据成员按其声明顺序加入内存，无访问权限无关，只看声明顺序。 * 2.虚单继承，派生类继承基类vptr * @author 光城 * @version v1 * @date 2019-07-21 */#include&lt;iostream&gt;using namespace std;class A&#123; public: char a; int b;&#125;;/** * @brief 此时B按照顺序： * char a * int b * short a * long b * 根据字节对齐4+4=8+8+8=24 //************************这里存在疑问，我觉得是16 */class B:A&#123; public: short a; long b;&#125;;class C&#123; A a; char c;&#125;;class A1&#123; virtual void fun()&#123;&#125;&#125;;class C1:public A&#123;&#125;;int main()&#123; cout&lt;&lt;sizeof(A)&lt;&lt;endl; // 8 cout&lt;&lt;sizeof(B)&lt;&lt;endl; // 24 cout&lt;&lt;sizeof(C)&lt;&lt;endl; // 12 /** * @brief 对于虚单函数继承，派生类也继承了基类的vptr，所以是8字节 */ cout&lt;&lt;sizeof(C1)&lt;&lt;endl; // 8 return 0;&#125;C++ 原则6虚继承 123456789101112131415161718192021222324252627282930313233/** * @file virnhe.cpp * @brief 虚继承 * @author 光城 * @version v1 * @date 2019-07-21 */#include&lt;iostream&gt;using namespace std;class A&#123; virtual void fun() &#123;&#125;&#125;;class B&#123; virtual void fun2() &#123;&#125;&#125;;class C : virtual public A, virtual public B&#123; public: virtual void fun3() &#123;&#125;&#125;;int main()&#123; /** * @brief 8 8 16 派生类虚继承多个虚函数，会继承所有虚函数的vptr */ cout&lt;&lt;sizeof(A)&lt;&lt;&quot; &quot;&lt;&lt;sizeof(B)&lt;&lt;&quot; &quot;&lt;&lt;sizeof(C); return 0;&#125; vptr_vtable那些事基础理论为了实现虚函数，C ++使用一种称为虚拟表的特殊形式的后期绑定。该虚拟表是用于解决在动态&#x2F;后期绑定方式的函数调用函数的查找表。 首先，每个使用虚函数的类（或者从使用虚函数的类派生）都有自己的虚拟表。该表只是编译器在编译时设置的静态数组。虚拟表包含可由类的对象调用的每个虚函数的一个条目。此表中的每个条目只是一个函数指针，指向该类可访问的派生函数。 其次，编译器还会添加一个隐藏指向基类的指针，我们称之为vptr。vptr在创建类实例时自动设置，以便指向该类的虚拟表。与this指针不同，this指针实际上是编译器用来解析自引用的函数参数，vptr是一个真正的指针。因此，它使每个类对象的分配大一个指针的大小。这也意味着vptr由派生类继承，这很重要。 实现与内部结构下面我们来看自动与手动操纵vptr来获取地址与调用虚函数！ 代码调用图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * @file vptr1.cpp * @brief C++虚函数vptr和vtable * 编译：g++ -g -o vptr vptr1.cpp -std=c++11 * @author 光城 * @version v1 * @date 2019-07-20 */#include &lt;iostream&gt;#include &lt;stdio.h&gt;using namespace std;/** * @brief 函数指针 */typedef void (*Fun)(); //**************************这里不是很理解/** * @brief 基类 */class Base&#123; public: Base()&#123;&#125;; virtual void fun1() &#123; cout &lt;&lt; &quot;Base::fun1()&quot; &lt;&lt; endl; &#125; virtual void fun2() &#123; cout &lt;&lt; &quot;Base::fun2()&quot; &lt;&lt; endl; &#125; virtual void fun3()&#123;&#125; ~Base()&#123;&#125;;&#125;;/** * @brief 派生类 */class Derived: public Base&#123; public: Derived()&#123;&#125;; void fun1() &#123; cout &lt;&lt; &quot;Derived::fun1()&quot; &lt;&lt; endl; &#125; void fun2() &#123; cout &lt;&lt; &quot;DerivedClass::fun2()&quot; &lt;&lt; endl; &#125; ~Derived()&#123;&#125;;&#125;;/** * @brief 获取vptr地址与func地址,vptr指向的是一块内存，这块内存存放的是虚函数地址，这块内存就是我们所说的虚表 * * @param obj * @param offset * * @return */Fun getAddr(void* obj,unsigned int offset)&#123; cout&lt;&lt;&quot;=======================&quot;&lt;&lt;endl; void* vptr_addr = (void *)*(unsigned long *)obj; //64位操作系统，占8字节，通过*(unsigned long *)obj取出前8字节，即vptr指针 printf(&quot;vptr_addr:%p\\n&quot;,vptr_addr); /** * @brief 通过vptr指针访问virtual table，因为虚表中每个元素(虚函数指针)在64位编译器下是8个字节，因此通过*(unsigned long *)vptr_addr取出前8字节， * 后面加上偏移量就是每个函数的地址！ */ void* func_addr = (void *)*((unsigned long *)vptr_addr+offset); printf(&quot;func_addr:%p\\n&quot;,func_addr); return (Fun)func_addr;&#125;int main(void)&#123; Base ptr; Derived d; Base *pt = new Derived(); // 基类指针指向派生类实例 Base &amp;pp = ptr; // 基类引用指向基类实例 Base &amp;p = d; // 基类引用指向派生类实例 cout&lt;&lt;&quot;基类对象直接调用&quot;&lt;&lt;endl; ptr.fun1(); cout&lt;&lt;&quot;基类对象调用基类实例&quot;&lt;&lt;endl; pp.fun1(); cout&lt;&lt;&quot;基类指针指向派生类实例并调用虚函数&quot;&lt;&lt;endl; pt-&gt;fun1(); cout&lt;&lt;&quot;基类引用指向派生类实例并调用虚函数&quot;&lt;&lt;endl; p.fun1(); // 手动查找vptr 和 vtable Fun f1 = getAddr(pt, 0); (*f1)(); Fun f2 = getAddr(pt, 1); (*f2)(); delete pt; return 0;&#125; virtual那些事虚函数中默认参数默认参数是静态绑定的，虚函数是动态绑定的。 默认参数的使用需要看指针或者引用本身的类型，而不是对象的类型。 可以不可以 静态函数可以声明为虚函数吗？ 静态函数不可以声明为虚函数，同时也不能被const 和 volatile关键字修饰 static成员函数不属于任何类对象或类实例，所以即使给此函数加上virutal也是没有任何意义 虚函数依靠vptr和vtable来处理。vptr是一个指针，在类的构造函数中创建生成，并且只能用this指针来访问它，静态成员函数没有this指针，所以无法访问vptr。 构造函数可以为虚函数吗？ 构造函数不可以声明为虚函数。同时除了inline|explicit之外，构造函数不允许使用其它任何关键字。 为什么构造函数不可以为虚函数？ 不可以也没有必要。 尽管虚函数表vtable是在编译阶段就已经建立的，但指向虚函数表的指针vptr是在运行阶段实例化对象时才产生的。 如果类含有虚函数，编译器会在构造函数中添加代码来创建vptr。 问题来了，如果构造函数是虚的，那么它需要vptr来访问vtable，可这个时候vptr还没产生。 因此，构造函数不可以为虚函数。 我们之所以使用虚函数，是因为需要在信息不全的情况下进行多态运行。而构造函数是用来初始化实例的，实例的类型必须是明确的。 因此，构造函数没有必要被声明为虚函数。 虚函数可以为私有函数吗？ 123456789101112131415161718192021222324252627282930313233/** * @file virtual_function.cpp * @brief 虚函数可以被私有化，但有一些细节需要注意。 * 基类指针指向继承类对象，则调用继承类对象的函数； * int main()必须声明为Base类的友元，否则编译失败。 编译器报错： ptr无法访问私有函数。 * 当然，把基类声明为public， 继承类为private，该问题就不存在了。----&gt; 见另外一个例子！ * @author 光城 * @version v1 * @date 2019-07-24 */#include&lt;iostream&gt; using namespace std; class Derived; class Base &#123; private: virtual void fun() &#123; cout &lt;&lt; &quot;Base Fun&quot;; &#125; friend int main(); &#125;; class Derived: public Base &#123; public: void fun() &#123; cout &lt;&lt; &quot;Derived Fun&quot;; &#125; &#125;; int main() &#123; Base *ptr = new Derived; ptr-&gt;fun(); return 0; &#125; RTTI与dynamic_castRTTI（Run-Time Type Identification)，通过运行时类型信息程序能够使用***基类的指针或引用***来检查这些指针或引用所指的对象的实际派生类型。 在面向对象程序设计中，有时我们需要在运行时查询一个对象是否能作为某种多态类型使用。与Java的instanceof，以及C#的as、is运算符类似，C++提供了dynamic_cast函数用于动态转型。相比C风格的强制类型转换和C++ reinterpret_cast，dynamic_cast提供了类型安全检查，是一种基于能力查询(Capability Query)的转换，所以在多态类型间进行转换更提倡采用dynamic_cast。 12345678910111213141516171819202122232425262728293031323334/** * @file rtti.cpp * @brief 在面向对象程序设计中，有时我们需要在运行时查询一个对象是否能作为某种多态类型使用。与Java的instanceof，以及C#的as、is运算符类似，C++提供了dynamic_cast函数用于动态转型。相比C风格的强制类型转换和C++ reinterpret_cast，dynamic_cast提供了类型安全检查，是一种基于能力查询(Capability Query)的转换，所以在多态类型间进行转换更提倡采用dynamic_cast * @author 光城 * @version v1 * @date 2019-07-24 */// CPP program to illustrate // // Run Time Type Identification #include&lt;iostream&gt;#include&lt;typeinfo&gt;using namespace std; class B &#123; virtual void fun() &#123;&#125; &#125;; class D: public B &#123; &#125;; int main() &#123; B *b = new D; // 向上转型 B &amp;obj = *b; D *d = dynamic_cast&lt;D*&gt;(b); // 向下转型 if(d != NULL) cout &lt;&lt; &quot;works&quot;&lt;&lt;endl; else cout &lt;&lt; &quot;cannot cast B* to D*&quot;; try &#123; D&amp; dobj = dynamic_cast&lt;D&amp;&gt;(obj); cout &lt;&lt; &quot;works&quot;&lt;&lt;endl; &#125; catch (bad_cast bc) &#123; // ERROR cout&lt;&lt;bc.what()&lt;&lt;endl; &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233// 在使用时需要注意：被转换对象obj的类型T1必须是多态类型，即T1必须公有继承自其它类，或者T1拥有虚函数（继承或自定义）。若T1为非多态类型，使用dynamic_cast会报编译错误。// A为非多态类型 class A&#123;&#125;;//B为多态类型class B&#123; public: virtual ~B()&#123;&#125;&#125;;//D为多态类型class D: public A&#123;&#125;;//E为非多态类型class E : private A&#123;&#125;;//F为多态类型class F : private B&#123;&#125; volatile 那些事volatile提醒编译器它后面所定义的变量随时都有可能改变，因此编译后的程序每次需要存储或读取这个变量的时候，都会直接从变量地址中读取数据。如果没有volatile关键字，则编译器可能优化读取和存储，可能暂时使用寄存器中的值，如果这个变量由别的程序更新了的话，将出现不一致的现象。 volatile使用 volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用volatile告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是 volatile volatile被 volatile 修饰的变量，在对其进行读写操作时，会引发一些可观测的副作用。而这些可观测的副作用，是由程序之外的因素决定的。 volatile应用 并行设备的硬件寄存器（如状态寄存器）。 假设要对一个设备进行初始化，此设备的某一个寄存器为0xff800000。 123456789int *output = (unsigned int *)0xff800000; //定义一个IO端口； int init(void) &#123; int i; for(i=0;i&lt; 10;i++) &#123; *output = i; &#125; &#125; 经过编译器优化后，编译器认为前面循环半天都是废话，对最后的结果毫无影响，因为最终只是将output这个指针赋值为 9，所以编译器最后给你编译编译的代码结果相当于： 1234int init(void) &#123; *output = 9; &#125; 如果你对此外部设备进行初始化的过程是必须是像上面代码一样顺序的对其赋值，显然优化过程并不能达到目的。反之如果你不是对此端口反复写操作，而是反复读操作，其结果是一样的，编译器在优化后，也许你的代码对此地址的读操作只做了一次。然而从代码角度看是没有任何问题的。这时候就该使用volatile通知编译器这个变量是一个不稳定的，在遇到此变量时候不要优化。 2.一个中断服务子程序中访问到的变量； 123456789101112131415static int i=0;int main()&#123; while(1) &#123; if(i) dosomething(); &#125;&#125;/* Interrupt service routine */void IRS()&#123; i=1;&#125; 上面示例程序的本意是产生中断时，由中断服务子程序IRS响应中断，变更程序变量i，使在main函数中调用dosomething函数，但是，由于编译器判断在main函数里面没有修改过i，因此可能只执行一次对从i到某寄存器的读操作，然后每次if判断都只使用这个寄存器里面的“i副本”，导致dosomething永远不会被调用。如果将变量i加上volatile修饰，则编译器保证对变量i的读写操作都不会被优化，从而保证了变量i被外部程序更改后能及时在原程序中得到感知。 3.多线程应用中被多个任务共享的变量。 当多个线程共享某一个变量时，该变量的值会被某一个线程更改，应该用 volatile 声明。作用是防止编译器优化把变量从内存装入CPU寄存器中，当一个线程更改变量后，未及时同步到其它线程中导致程序出错。volatile的意思是让编译器每次操作该变量时一定要从内存中真正取出，而不是使用已经存在寄存器中的值。 12345678910111213volatile bool bStop=false; //bStop 为共享全局变量 //第一个线程void threadFunc1()&#123; ... while(!bStop)&#123;...&#125;&#125;//第二个线程终止上面的线程循环void threadFunc2()&#123; ... bStop = true;&#125; 要想通过第二个线程终止第一个线程循环，如果bStop不使用volatile定义，那么这个循环将是一个死循环，因为bStop已经读取到了寄存器中，寄存器中bStop的值永远不会变成FALSE，加上volatile，程序在执行时，每次均从内存中读出bStop的值，就不会死循环了。 是否了解volatile的应用场景是区分C&#x2F;C++程序员和嵌入式开发程序员的有效办法，搞嵌入式的家伙们经常同硬件、中断、RTOS等等打交道，这些都要求用到volatile变量，不懂得volatile将会带来程序设计的灾难。 volatile常见问题下面的问题可以看一下面试者是不是直正了解volatile。 一个参数既可以是const还可以是volatile吗？为什么？ 可以。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。 const修饰的变量在程序里面是不能改变的，但是可以被程序外的东西修改，就象上面说的外部端口的值，如果仅仅使用const，有可能complier会优化掉这些变量，加上volatile就万无一失了。 一个指针可以是volatile吗？为什么？ 可以。尽管这并不常见。一个例子是当一个中断服务子程序修该一个指向一个buffer的指针时。 下面的函数有什么错误？ 1234int square(volatile int *ptr) &#123; return *ptr * *ptr; &#125; 这段代码有点变态，其目的是用来返回指针ptr指向值的平方，但是，由于ptr指向一个volatile型参数，编译器将产生类似下面的代码： 1234567int square(volatile int *ptr) &#123; int a,b; a = *ptr; b = *ptr; return a * b; &#125; 由于*ptr的值可能被意想不到地改变，因此a和b可能是不同的。结果，这段代码可能返回的不是你所期望的平方值！正确的代码如下： 12345long square(volatile int *ptr) &#123; int a=*ptr; return a * a; &#125; assert那些事第一个断言案例断言，是宏，而非函数。assert 宏的原型定义在 （C）、（C++）中，其作用是如果它的条件返回错误，则终止程序执行。可以通过定义 NDEBUG 来关闭 assert，但是需要在源代码的开头，include 之前。 1void assert(int expression); 断言与正常错误处理断言主要用于检查逻辑上不可能的情况。例如，它们可用于检查代码在开始运行之前所期望的状态，或者在运行完成后检查状态。与正常的错误处理不同，断言通常在运行时被禁用。 忽略断言： 在代码开头加上： 1#define NDEBUG // 加上这行，则 assert 不可用 extern “C”那些事C++与C编译区别在C++中常在头文件见到extern “C”修饰函数，那有什么作用呢？ 是用于C++链接在C语言模块中定义的函数。 C++虽然兼容C，但C++文件中函数编译后生成的符号与C语言生成的不同。因为C++支持函数重载，C++函数编译后生成的符号带有函数参数类型的信息，而C则没有。 例如int add(int a, int b)函数经过C++编译器生成.o文件后，add会变成形如add_int_int之类的, 而C的话则会是形如_add, 就是说：相同的函数，在C和C++中，编译后生成的符号不同。 这就导致一个问题：如果C++中使用C语言实现的函数，在编译链接的时候，会出错，提示找不到对应的符号。此时extern &quot;C&quot;就起作用了：告诉链接器去寻找_add这类的C语言符号，而不是经过C++修饰的符号。 C++调用C函数C++调用C函数的例子: 引用C的头文件时，需要加extern &quot;C&quot; 123456789101112131415161718192021//add.h#ifndef ADD_H#define ADD_Hint add(int x,int y);#endif//add.c#include &quot;add.h&quot;int add(int x,int y) &#123; return x+y;&#125;//add.cpp#include &lt;iostream&gt;#include &quot;add.h&quot;using namespace std;int main() &#123; add(2,3); return 0;&#125; 编译： 12//Generate add.o filegcc -c add.c 链接： 1g++ add.cpp add.o -o main 没有添加extern “C” 报错： 123456789&gt; g++ add.cpp add.o -o main add.o：在函数‘main’中：add.cpp:(.text+0x0): `main&#x27;被多次定义/tmp/ccH65yQF.o:add.cpp:(.text+0x0)：第一次在此定义/tmp/ccH65yQF.o：在函数‘main’中：add.cpp:(.text+0xf)：对‘add(int, int)’未定义的引用add.o：在函数‘main’中：add.cpp:(.text+0xf)：对‘add(int, int)’未定义的引用collect2: error: ld returned 1 exit status 添加extern “C”后： 123456789#include &lt;iostream&gt;using namespace std;extern &quot;C&quot; &#123; #include &quot;add.h&quot;&#125;int main() &#123; add(2,3); return 0;&#125; 编译的时候一定要注意，先通过gcc生成中间文件add.o。 1gcc -c add.c 然后编译： 1g++ add.cpp add.o -o main C中调用C++函数extern &quot;C&quot;在C中是语法错误，需要放在C++头文件中。 123456789101112131415161718192021// add.h#ifndef ADD_H#define ADD_Hextern &quot;C&quot; &#123; //***********************************放在C++文件中 int add(int x,int y);&#125;#endif// add.cpp#include &quot;add.h&quot;int add(int x,int y) &#123; return x+y;&#125;// add.cextern int add(int x,int y); //********************************************这里加externint main() &#123; add(2,3); return 0;&#125; 总结综上，总结出使用方法，在C语言的头文件中，对其外部函数只能指定为extern类型，C语言中不支持extern “C”声明，在.c文件中包含了extern “C”时会出现编译语法错误。所以使用extern “C”全部都放在于cpp程序相关文件或其头文件中。 C++调用C函数： 123456789101112//xx.hextern int add(...)//xx.cint add()&#123;&#125;//xx.cppextern &quot;C&quot; &#123; #include &quot;xx.h&quot;&#125; C调用C++函数 12345678910//xx.hextern &quot;C&quot;&#123; int add();&#125;//xx.cppint add()&#123;&#125;//xx.cextern int add(); struct那些事C和C++中的Struct区别 struct 和class区别总的来说，struct 更适合看成是一个数据结构的实现体，class 更适合看成是一个对象的实现体。 区别: 最本质的一个区别就是默认的访问控制 默认的继承访问权限。struct 是 public 的，class 是 private 的。 struct 作为数据结构的实现体，它默认的数据访问控制是 public 的，而 class 作为对象的实现体，它默认的成员变量访问控制是 private 的。 UNION那些事联合（union）是一种节省空间的特殊的类，一个 union 可以有多个数据成员，但是在任意时刻只有一个数据成员可以有值。当某个成员被赋值后其他成员变为未定义状态。联合有如下特点： 默认访问控制符为 public 可以含有构造函数、析构函数 不能含有引用类型的成员 不能继承自其他类，不能作为基类 不能含有虚函数 匿名 union 在定义所在作用域可直接访问 union 成员 匿名 union 不能包含 protected 成员或 private 成员 全局匿名联合必须是静态（static）的 C实现C++的面向对象特性C++实现案例C++中的多态:在C++中会维护一张虚函数表，根据赋值兼容规则，我们知道父类的指针或者引用是可以指向子类对象的。 如果一个父类的指针或者引用调用父类的虚函数则该父类的指针会在自己的虚函数表中查找自己的函数地址，如果该父类对象的指针或者引用指向的是子类的对象，而且该子类已经重写了父类的虚函数，则该指针会调用子类的已经重写的虚函数。 C实现 封装 C语言中是没有class类这个概念的，但是有struct结构体，我们可以考虑使用struct来模拟； 使用函数指针把属性与方法封装到结构体中。 2.继承 结构体嵌套 3.多态 类与子类方法的函数指针不同 在C语言的结构体内部是没有成员函数的，如果实现这个父结构体和子结构体共有的函数呢？我们可以考虑使用函数指针来模拟。但是这样处理存在一个缺陷就是：父子各自的函数指针之间指向的不是类似C++中维护的虚函数表而是一块物理内存，如果模拟的函数过多的话就会不容易维护了。 模拟多态，必须保持函数指针变量对齐(在内容上完全一致，而且变量对齐上也完全一致)。否则父类指针指向子类对象，运行崩溃！ explicit那些事 explicit 修饰构造函数时，可以防止隐式转换和复制初始化 explicit 修饰转换函数时，可以防止隐式转换，但按语境转换除外 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;struct A&#123; A(int) &#123; &#125; operator bool() const &#123; return true; &#125;&#125;;struct B&#123; explicit B(int) &#123;&#125; explicit operator bool() const &#123; return true; &#125;&#125;;void doA(A a) &#123;&#125;void doB(B b) &#123;&#125;int main()&#123; A a1(1); // OK：直接初始化 A a2 = 1; // OK：复制初始化 A a3&#123; 1 &#125;; // OK：直接列表初始化 A a4 = &#123; 1 &#125;; // OK：复制列表初始化 A a5 = (A)1; // OK：允许 static_cast 的显式转换 doA(1); // OK：允许从 int 到 A 的隐式转换 if (a1); // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a6(a1); // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a7 = a1; // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a8 = static_cast&lt;bool&gt;(a1); // OK ：static_cast 进行直接初始化 B b1(1); // OK：直接初始化// B b2 = 1; // 错误：被 explicit 修饰构造函数的对象不可以复制初始化 B b3&#123; 1 &#125;; // OK：直接列表初始化// B b4 = &#123; 1 &#125;; // 错误：被 explicit 修饰构造函数的对象不可以复制列表初始化 B b5 = (B)1; // OK：允许 static_cast 的显式转换// doB(1); // 错误：被 explicit 修饰构造函数的对象不可以从 int 到 B 的隐式转换 if (b1); // OK：被 explicit 修饰转换函数 B::operator bool() 的对象可以从 B 到 bool 的按语境转换 bool b6(b1); // OK：被 explicit 修饰转换函数 B::operator bool() 的对象可以从 B 到 bool 的按语境转换// bool b7 = b1; // 错误：被 explicit 修饰转换函数 B::operator bool() 的对象不可以隐式转换 bool b8 = static_cast&lt;bool&gt;(b1); // OK：static_cast 进行直接初始化 return 0;&#125; friend 那些事概述友元提供了一种 普通函数或者类成员函数 访问另一个类中的私有或保护成员 的机制。也就是说有两种形式的友元： 友元函数：普通函数对一个访问某个类中的私有或保护成员。 友元类：类A中的成员函数访问类B中的私有或保护成员 优点：提高了程序的运行效率。 缺点：破坏了类的封装性和数据的透明性。 总结： - 能访问私有成员 - 破坏封装性 - 友元关系不可传递 - 友元关系的单向性 - 友元声明的形式及数量不受限制 友元函数在类声明的任何区域中声明，而定义则在类的外部。 1friend &lt;类型&gt;&lt;友元函数名&gt;(&lt;参数表&gt;); 注意，友元函数只是一个普通函数，并不是该类的类成员函数，它可以在任何地方调用，友元函数中通过对象名来访问该类的私有或保护成员。 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;class A&#123;public: A(int _a):a(_a)&#123;&#125;; friend int geta(A &amp;ca); ///&lt; 友元函数private: int a;&#125;;int geta(A &amp;ca) &#123; return ca.a; //*********************************访问到了私有属性&#125;int main()&#123; A a(3); cout&lt;&lt;geta(a)&lt;&lt;endl; return 0;&#125; 友元类友元类的声明在该类的声明中，而实现在该类外。 1friend class &lt;友元类名&gt;; 类B是类A的友元，那么类B可以直接访问A的私有成员。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class A&#123;public: A(int _a):a(_a)&#123;&#125;; friend class B;private: int a;&#125;;class B&#123;public: int getb(A ca) &#123; return ca.a; &#125;;&#125;;int main() &#123; A a(3); B b; cout&lt;&lt;b.getb(a)&lt;&lt;endl; return 0;&#125; 注意 友元关系没有继承性 假如类B是类A的友元，类C继承于类A，那么友元类B是没办法直接访问类C的私有或保护成员。 友元关系没有传递性 假如类B是类A的友元，类C是类B的友元，那么友元类C是没办法直接访问类A的私有或保护成员，也就是不存在“友元的友元”这种关系。 using 那些事基本使用局部与全局using，具体操作与使用见下面案例： 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#define isNs1 1//#define isGlobal 2using namespace std;void func() &#123; cout&lt;&lt;&quot;::func&quot;&lt;&lt;endl;&#125;namespace ns1 &#123; void func() &#123; cout&lt;&lt;&quot;ns1::func&quot;&lt;&lt;endl; &#125;&#125;namespace ns2 &#123;#ifdef isNs1 using ns1::func; /// ns1中的函数#elif isGlobal using ::func; /// 全局中的函数#else void func() &#123; cout&lt;&lt;&quot;other::func&quot;&lt;&lt;endl; &#125;#endif&#125;int main() &#123; /** * 这就是为什么在c++中使用了cmath而不是math.h头文件 */ ns2::func(); // 会根据当前环境定义宏的不同来调用不同命名空间下的func()函数 return 0;&#125; 改变访问性123456789101112class Base&#123;public: std::size_t size() const &#123; return n; &#125;protected: std::size_t n;&#125;;class Derived : private Base &#123;public: using Base::size;protected: using Base::n;&#125;; 类Derived私有继承了Base，对于它来说成员变量n和成员函数size都是私有的，如果使用了using语句，可以改变他们的可访问性，如上述例子中，size可以按public的权限访问，n可以按protected的权限访问。 函数重载在继承过程中，派生类可以覆盖重载函数的0个或多个实例，一旦定义了一个重载版本，那么其他的重载版本都会变为不可见。 如果对于基类的重载函数，我们需要在派生类中修改一个，又要让其他的保持可见，必须要重载所有版本，这样十分的繁琐。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class Base&#123; public: void f()&#123; cout&lt;&lt;&quot;f()&quot;&lt;&lt;endl; &#125; void f(int n)&#123; cout&lt;&lt;&quot;Base::f(int)&quot;&lt;&lt;endl; &#125;&#125;;class Derived : private Base &#123; public: using Base::f; void f(int n)&#123; cout&lt;&lt;&quot;Derived::f(int)&quot;&lt;&lt;endl; &#125;&#125;;int main()&#123; Base b; Derived d; d.f(); d.f(1); return 0;&#125; 如上代码中，在派生类中使用using声明语句指定一个名字而不指定形参列表，所以一条基类成员函数的using声明语句就可以把该函数的所有重载实例添加到派生类的作用域中。此时，派生类只需要定义其特有的函数就行了，而无需为继承而来的其他函数重新定义。 取代typedefC中常用typedef A B这样的语法，将B定义为A类型，也就是给A类型一个别名B 对应typedef A B，使用using B&#x3D;A可以进行同样的操作。 12typedef vector&lt;int&gt; V1; using V2 = vector&lt;int&gt;; ::那些事 全局作用域符（::name）：用于类型名称（类、类成员、成员函数、变量等）前，表示作用域为全局命名空间 类作用域符（class::name）：用于表示指定类型的作用域范围是具体某个类的 命名空间作用域符（namespace::name）:用于表示指定类型的作用域范围是具体某个命名空间的 enum那些事传统行为枚举有如下问题： 作用域不受限,会容易引起命名冲突。例如下面无法编译通过的： 12345678910#include &lt;iostream&gt;using namespace std;enum Color &#123;RED,BLUE&#125;;enum Feeling &#123;EXCITED,BLUE&#125;;int main() &#123; return 0;&#125; 会隐式转换为int 用来表征枚举变量的实际类型不能明确指定，从而无法支持枚举类型的前向声明。 经典做法解决作用域不受限带来的命名冲突问题的一个简单方法是，给枚举变量命名时加前缀，如上面例子改成 COLOR_BLUE 以及 FEELING_BLUE。 一般说来，为了一致性我们会把所有常量统一加上前缀。但是这样定义枚举变量的代码就显得累赘。C 程序中可能不得不这样做。不过 C++ 程序员恐怕都不喜欢这种方法。替代方案是命名空间: 123456789namespace Color &#123; enum Type &#123; RED=15, YELLOW, BLUE &#125;;&#125;; 这样之后就可以用 Color::Type c = Color::RED; 来定义新的枚举变量了。如果 using namespace Color 后，前缀还可以省去，使得代码简化。不过，因为命名空间是可以随后被扩充内容的，所以它提供的作用域封闭性不高。在大项目中，还是有可能不同人给不同的东西起同样的枚举类型名。 更“有效”的办法是用一个类或结构体来限定其作用域，例如：定义新变量的方法和上面命名空间的相同。不过这样就不用担心类在别处被修改内容。这里用结构体而非类，一是因为本身希望这些常量可以公开访问，二是因为它只包含数据没有成员函数。 123456789struct Color1&#123; enum Type &#123; RED=102, YELLOW, BLUE &#125;;&#125;; C++11的枚举类上面的做法解决了第一个问题，但对于后两个仍无能为力。庆幸的是，C++11 标准中引入了“枚举类”(enum class)，可以较好地解决上述问题。 新的enum的作用域不在是全局的 不能隐式转换成其他类型 123456789101112/** * @brief C++11的枚举类 * 下面等价于enum class Color2:int */enum class Color2&#123; RED=2, YELLOW, BLUE&#125;;r2 c2 = Color2::RED;cout &lt;&lt; static_cast&lt;int&gt;(c2) &lt;&lt; endl; //必须转！ 可以指定用特定的类型来存储enum 123456789enum class Color3:char; // 前向声明// 定义enum class Color3:char &#123; RED=&#x27;r&#x27;, BLUE&#125;;char c3 = static_cast&lt;char&gt;(Color3::RED); 类中的枚举类型有时我们希望某些常量只在类中有效。 由于#define 定义的宏常量是全局的，不能达到目的，于是想到实用const 修饰数据成员来实现。而const 数据成员的确是存在的，但其含义却不是我们所期望的。 const 数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的，因为类可以创建多个对象，不同的对象其 const 数据成员的值可以不同。 不能在类声明中初始化 const 数据成员。以下用法是错误的，因为类的对象未被创建时，编译器不知道 SIZE 的值是什么。(c++11标准前) 12345class A &#123; const int SIZE = 100; // 错误，企图在类声明中初始化 const 数据成员 int array[SIZE]; // 错误，未知的 SIZE &#125;; 正确应该在类的构造函数的初始化列表中进行： 1234567891011class A &#123; A(int size); // 构造函数 const int SIZE ; &#125;; A::A(int size) : SIZE(size) // 构造函数的定义&#123; &#125; A a(100); // 对象 a 的 SIZE 值为 100 A b(200); // 对象 b 的 SIZE 值为 200 怎样才能建立在整个类中都恒定的常量呢？ 别指望 const 数据成员了，应该用类中的枚举常量来实现。例如: 12345678class Person&#123;public: typedef enum &#123; BOY = 0, GIRL &#125;SexType;&#125;;//访问的时候通过，Person::BOY或者Person::GIRL来进行访问。 枚举常量不会占用对象的存储空间，它们在编译时被全部求值。 枚举常量的缺点是：它的隐含数据类型是整数，其最大值有限，且不能表示浮点。 decltype基本使用decltype的语法是： 1decltype (expression) 这里的括号是必不可少的,decltype的作用是“查询表达式的类型”，因此，上面语句的效果是，返回 expression 表达式的类型。注意，decltype 仅仅“查询”表达式的类型，并不会对表达式进行“求值”。 推导出表达式类型 12int i = 4;decltype(i) a; //推导结果为int。a的类型为int。 与using&#x2F;typedef合用，用于定义类型。 123456789using size_t = decltype(sizeof(0));//sizeof(a)的返回值为size_t类型using ptrdiff_t = decltype((int*)0 - (int*)0);using nullptr_t = decltype(nullptr);vector&lt;int &gt;vec;typedef decltype(vec.begin()) vectype;for (vectype i = vec.begin; i != vec.end(); i++)&#123;//...&#125; 这样和auto一样，也提高了代码的可读性。 重用匿名类型 在C++中，我们有时候会遇上一些匿名类型，如: 12345struct &#123; int d ; doubel b;&#125;anon_s; 而借助decltype，我们可以重新使用这个匿名的结构体： 1decltype(anon_s) as ;//定义了一个上面匿名的结构体 泛型编程中结合auto，用于追踪函数的返回值类型 这也是decltype最大的用途了。 12345template &lt;typename T&gt;auto multiply(T x, T y)-&gt;decltype(x*y)&#123; return x*y;&#125; 判别规则对于decltype(e)而言，其判别结果受以下条件的影响： 如果e是一个没有带括号的标记符表达式或者类成员访问表达式，那么的decltype（e）就是e所命名的实体的类型。此外，如果e是一个被重载的函数，则会导致编译错误。 否则 ，假设e的类型是T，如果e是一个将亡值，那么decltype（e）为T&amp;&amp; 否则，假设e的类型是T，如果e是一个左值，那么decltype（e）为T&amp;。 否则，假设e的类型是T，则decltype（e）为T。 引用和指针那些事引用和指针 引用必须初始化，而指针可以不初始化。 引用不能为空，而指针可以为空。 由于引用不能为空，所以我们在使用引用的时候不需要测试其合法性，而在使用指针的时候需要首先判断指针是否为空指针，否则可能会引起程序崩溃。 1234567891011void test_p(int* p)&#123; if(p != null_ptr) //对p所指对象赋值时需先判断p是否为空指针 *p = 3; return;&#125;void test_r(int&amp; r)&#123; r = 3; //由于引用不能为空，所以此处无需判断r的有效性就可以对r直接赋值 return;&#125; 引用 左值引用 常规引用，一般表示对象的身份。 右值引用 右值引用就是必须绑定到右值（一个临时对象、将要销毁的对象）的引用，一般表示对象的值。右值引用可实现转移语义（Move Sementics）和精确传递（Perfect Forwarding），它的主要目的有两个方面： 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。 能够更简洁明确地定义泛型函数。 指针与引用的性能差距指针与引用之间有没有性能差距呢？这种问题就需要进入汇编层面去看一下。我们先写一个test1函数，参数传递使用指针： 12345void test1(int* p)&#123; *p = 3; //此处应该首先判断p是否为空，为了测试的需要，此处我们没加。 return;&#125; 该代码段对应的汇编代码如下： 1234567891011(gdb) disassemble Dump of assembler code for function test1(int*): 0x0000000000400886 &lt;+0&gt;: push %rbp 0x0000000000400887 &lt;+1&gt;: mov %rsp,%rbp 0x000000000040088a &lt;+4&gt;: mov %rdi,-0x8(%rbp)=&gt; 0x000000000040088e &lt;+8&gt;: mov -0x8(%rbp),%rax 0x0000000000400892 &lt;+12&gt;: movl $0x3,(%rax) 0x0000000000400898 &lt;+18&gt;: nop 0x0000000000400899 &lt;+19&gt;: pop %rbp 0x000000000040089a &lt;+20&gt;: retq End of assembler dump. 上述代码1、2行是参数调用保存现场操作；第3行是参数传递，函数调用第一个参数一般放在rdi寄存器，此行代码把rdi寄存器值（指针p的值）写入栈中；第4行是把栈中p的值写入rax寄存器；第5行是把立即数3写入到rax寄存器值所指向的内存中，此处要注意(%rax)两边的括号，这个括号并并不是可有可无的，(%rax)和%rax完全是两种意义，(%rax)代表rax寄存器中值所代表地址部分的内存，即相当于C++代码中的*p，而%rax代表rax寄存器，相当于C++代码中的p值，所以汇编这里使用了(%rax)而不是%rax。 我们再写出参数传递使用引用的C++代码段test2： 12345void test2(int&amp; r)&#123; r = 3; //赋值前无需判断reference是否为空 return;&#125; 这段代码对应的汇编代码如下： 1234567891011(gdb) disassemble Dump of assembler code for function test2(int&amp;): 0x000000000040089b &lt;+0&gt;: push %rbp 0x000000000040089c &lt;+1&gt;: mov %rsp,%rbp 0x000000000040089f &lt;+4&gt;: mov %rdi,-0x8(%rbp)=&gt; 0x00000000004008a3 &lt;+8&gt;: mov -0x8(%rbp),%rax 0x00000000004008a7 &lt;+12&gt;: movl $0x3,(%rax) 0x00000000004008ad &lt;+18&gt;: nop 0x00000000004008ae &lt;+19&gt;: pop %rbp 0x00000000004008af &lt;+20&gt;: retq End of assembler dump. 我们发现test2对应的汇编代码和test1对应的汇编代码完全相同，这说明C++编译器在编译程序的时候将指针和引用编译成了完全一样的机器码。**所以C++中的引用只是C++对指针操作的一个“语法糖”，在底层实现时C++编译器实现这两种操作的方法完全相同。** 总结C++中引入了引用操作，在对引用的使用加了更多限制条件的情况下，保证了引用使用的安全性和便捷性，还可以保持代码的优雅性。在适合的情况使用适合的操作，引用的使用可以一定程度避免“指针满天飞”的情况，对于提升程序稳定性也有一定的积极意义。最后，指针与引用底层实现都是一样的，不用担心两者的性能差距。 宏那些事宏中包含特殊符号分为几种：#，##，\\ 1.字符串化操作符(#)在一个宏中的参数前面使用一个#,预处理器会把这个参数转换为一个字符数组，换言之就是：#是“字符串化”的意思，出现在宏定义中的#是把跟在后面的参数转换成一个字符串。 注意：其只能用于有传入参数的宏定义中，且必须置于宏定义体中的参数名前。 1234567891011121314151617181920#define exp(s) printf(&quot;test s is:%s\\n&quot;,s)#define exp1(s) printf(&quot;test s is:%s\\n&quot;,#s)#define exp2(s) #s int main() &#123; exp(&quot;hello&quot;); //**********************************这里传入的是字符串 exp1(hello); //**********************************这里传入的是个什么。。。 string str = exp2( bac ); cout&lt;&lt;str&lt;&lt;&quot; &quot;&lt;&lt;str.size()&lt;&lt;endl; /** * 忽略传入参数名前面和后面的空格。 */ string str1 = exp2( asda bac ); /** * 当传入参数名间存在空格时，编译器将会自动连接各个子字符串， * 用每个子字符串之间以一个空格连接，忽略剩余空格。 */ cout&lt;&lt;str1&lt;&lt;&quot; &quot;&lt;&lt;str1.size()&lt;&lt;endl; return 0;&#125; 2.符号连接操作符（##）“##”是一种分隔连接方式，它的作用是先分隔，然后进行强制连接。将宏定义的多个形参转换成一个实际参数名。 注意事项： 当用##连接形参时，##前后的空格可有可无。 连接后的实际参数名，必须为实际存在的参数名或是编译器已知的宏定义。 如果##后的参数本身也是一个宏的话，##会阻止这个宏的展开。 1234567891011#define expA(s) printf(&quot;前缀加上后的字符串为:%s\\n&quot;,gc_##s) //gc_s必须存在// 注意事项2#define expB(s) printf(&quot;前缀加上后的字符串为:%s\\n&quot;,gc_ ## s) //gc_s必须存在// 注意事项1#define gc_hello1 &quot;I am gc_hello1&quot;int main() &#123; // 注意事项1 const char * gc_hello = &quot;I am gc_hello&quot;; expA(hello); expB(hello1);&#125; 3.续行操作符(\\)当定义的宏不能用一行表达完整时，可以用”\\”表示下一行继续此宏的定义。 注意 \\ 前留空格。 123456#define MAX(a,b) ((a)&gt;(b) ? (a) \\ :(b)) int main() &#123; int max_val = MAX(3,6); cout&lt;&lt;max_val&lt;&lt;endl;&#125; do {…}while(0)的使用1.避免语义曲解123#define fun() f1();f2();if(a&gt;0) fun() 这个宏被展开后就是： 123if(a&gt;0) f1(); f2(); 本意是a&gt;0执行f1 f2，而实际是f2每次都会执行，所以就错误了。 为了解决这种问题，在写代码的时候，通常可以采用{}块。 123456789#define fun() &#123;f1();f2();&#125;if(a&gt;0) fun();// 宏展开if(a&gt;0)&#123; f1(); f2();&#125;; 但是会发现上述宏展开后多了一个分号，实际语法不太对。(虽然编译运行没问题，正常没分号)。 2.避免由宏引起的警告内核中由于不同架构的限制，很多时候会用到空宏，。在编译的时候，这些空宏会给出warning，为了避免这样的warning，我们可以使用do{…}while(0)来定义空宏： 1#define EMPTYMICRO do&#123;&#125;while(0)","categories":[{"name":"C++","slug":"C","permalink":"https://flippy-bird.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://flippy-bird.github.io/tags/C/"}]},{"title":"来自hexo博客的hello world","slug":"hello-world","date":"2021-01-13T02:14:50.000Z","updated":"2025-12-11T06:09:42.268Z","comments":true,"path":"2021/01/13/hello-world/","permalink":"https://flippy-bird.github.io/2021/01/13/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"基础知识","slug":"基础知识","permalink":"https://flippy-bird.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"工具使用","slug":"工具使用","permalink":"https://flippy-bird.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"name":"Agent开源项目学习","slug":"Agent开源项目学习","permalink":"https://flippy-bird.github.io/categories/Agent%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/"},{"name":"RAG框架学习","slug":"RAG框架学习","permalink":"https://flippy-bird.github.io/categories/RAG%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"},{"name":"shader","slug":"shader","permalink":"https://flippy-bird.github.io/categories/shader/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/categories/OpenGL/"},{"name":"C++","slug":"C","permalink":"https://flippy-bird.github.io/categories/C/"},{"name":"iOS新手村","slug":"iOS新手村","permalink":"https://flippy-bird.github.io/categories/iOS%E6%96%B0%E6%89%8B%E6%9D%91/"},{"name":"算法","slug":"算法","permalink":"https://flippy-bird.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://flippy-bird.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"vibe coding","slug":"vibe-coding","permalink":"https://flippy-bird.github.io/tags/vibe-coding/"},{"name":"LLM","slug":"LLM","permalink":"https://flippy-bird.github.io/tags/LLM/"},{"name":"Agent","slug":"Agent","permalink":"https://flippy-bird.github.io/tags/Agent/"},{"name":"端侧","slug":"端侧","permalink":"https://flippy-bird.github.io/tags/%E7%AB%AF%E4%BE%A7/"},{"name":"plan","slug":"plan","permalink":"https://flippy-bird.github.io/tags/plan/"},{"name":"memory","slug":"memory","permalink":"https://flippy-bird.github.io/tags/memory/"},{"name":"Rag","slug":"Rag","permalink":"https://flippy-bird.github.io/tags/Rag/"},{"name":"MCP","slug":"MCP","permalink":"https://flippy-bird.github.io/tags/MCP/"},{"name":"langgraph","slug":"langgraph","permalink":"https://flippy-bird.github.io/tags/langgraph/"},{"name":"shader","slug":"shader","permalink":"https://flippy-bird.github.io/tags/shader/"},{"name":"元宇宙","slug":"元宇宙","permalink":"https://flippy-bird.github.io/tags/%E5%85%83%E5%AE%87%E5%AE%99/"},{"name":"AR","slug":"AR","permalink":"https://flippy-bird.github.io/tags/AR/"},{"name":"bug","slug":"bug","permalink":"https://flippy-bird.github.io/tags/bug/"},{"name":"RenderDoc","slug":"RenderDoc","permalink":"https://flippy-bird.github.io/tags/RenderDoc/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://flippy-bird.github.io/tags/OpenGL/"},{"name":"Metal","slug":"Metal","permalink":"https://flippy-bird.github.io/tags/Metal/"},{"name":"C++","slug":"C","permalink":"https://flippy-bird.github.io/tags/C/"}]}